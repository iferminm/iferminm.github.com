{"pages":[{"text":"Es bien sabido por todos que en Linux y en el Open Source en general, uno es libre de elegir todas y cada una de las partes del sistema que va a configurar para su computadora personal o de trabajo, la línea de comandos no es excepción. Por defecto, viene configurado BASH en todos los sistemas linux, sin embargo, es posible cambiarlo sin ningún tipo de problemas, en mi caso, luego de investigar un poquito, elegí una combinación que me ha resultado bastante bien durante las últimas dos semanas: ZSH + un plugin llamado oh my zsh . Acá las razones por las cuales decidí migrar y por qué me ha parecido tan genial: YOLO Siempre digo que quiero probar herramientas nuevas, pero nunca pongo manos a la obra, en los últimos meses me he propuesto a organizarme y crear hábitos, utilizando distintos hacks, que me permitan llevar a cabo todo lo que me pasa por la mente sin descuidar cosas importantes como la familia y el trabajo. Así que, quise probar ZSH a ver qué tal, ¿qué mejor momento que ahora? No es un cambio muy traumático BASH nace en 1989, ZSH nace en 1990, mantiene compatibilidad con todos los comandos de BASH y agrega nuevas funcionalidades que vamos a ver en las razones siguientes :-). El autocompletado de ZSH ZSH tiene una capacidad increíble de autocompletar, no sólo te muestra las posibles opciones, cosa que también hace BASH , sino que te permite seleccionarla de manera interactiva, cosa que BASH no hace de manera natural. Además, no sólo completa rutas y comandos básicos del sistema operativo, también tiene autocompletado para git, cosa que me resulta muy útil porque es una herramienta que uso todos los días en la oficina y para proyectos personales, este autocompletado incluye una pequeña descripción de lo que hace cada comando de git. Completación de rutas No, no es lo mismo que la anterior, este es algo mucho más potente que no vi nunca en BASH supongamos que soy perezoso para escribir, y quiero ir a /home/israelord/Work , que es la ruta donde tengo todos mis proyectos, tanto de la oficina como freelance. Se que ese es el único patrón que coincide, simplemente escribo /h/i/W y al presionar tab, me autocompleta la ruta. En caso que haya ambigüedad, como por ejemplo, si quiero ir a /usr/local/bin , al escribir /u/l/b , hay dos opciones para la l , bajo el directorio /user : lib o local . En este caso, me permitirá seleccionar la opción correcta de manera interactiva, tal como en el ejemplo anterior, antes de terminar el autocompletado. Puedo resolver esto simplemente escribiendo /u/lo/b y me generará la ruta correcta de una vez, simplemente debo completar más la parte de la ruta que genera el conflicto para que sea única, aunque la selección interactiva no me disgusta para nada. Cambios de directorio Sí, ya se, para eso está cd , pero este es un caso de uso de cd que no vi en BASH , supongamos que estoy en la ruta del ejemplo anterior /usr/local/bin , pero en realidad quería ir a /usr/local/sbin . En vez de hacer como en BASH cd ../sbin , puedo hacer cd bin sbin y me lleva allí. Funciona igual con sub rutas, puedo hacer cd local/sbin games y me lleva a /usr/games , por ejemplo. Esto es especialmente útil cuando tengo proyectos con la misma estructura, por ejemplo, estoy en /home/israelord/proyecto1/auth/views/ , simplemente con hacer cd proyecto1 proyecto2 , me lleva a /home/israelord/proyecto1/auth/views/ . No más cd ../../../../ Autocorrector No mucho que decir, si me equivoco y escribo gut, me corrige y escribe git, por ejemplo, si hay más de un posible patrón, me muestra la selección interactiva que vimos antes. Renombrado de archivos en batch Supongamos que tengo 700 fotos que y los nombres son cosas como IMG_2193192873198723.jpg, quiero renombrarlas a algo más manejable, como \"foto_1.jpg\", \"foto_2.jpg\" y así. Bueno, simplemente escribo zmv '(*).jpg' 'foto_$1.jpg' Y listo!. Oh My ZSH Es un plugin que extiende ZSH y, además, tiene varios addons, por ahora sólo estoy usando el de git porque tiene muchísimos alias útiles para las tareas de día a día con git que les dejaré de tarea revisar, pero la diferencia es abismal respeto a lo que escribirías normalmente, por ejemplo: En vez de git push origin master con Oh my zsh simplemente escribo ggpush ;-) Instalando ZSH normalmente está instalado, simplemente hay que modificar nuestro usuario para que sea el terminal por defecto chsh -s /bin/zsh Para instalar el plugin Oh my ZSH , basta con ejecutar curl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh O, si preferimos usar wget wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O - | sh","tags":"Blog","loc":"http://localhost:8000/migre-a-zsh.html","title":"Migré a ZSH"},{"text":"Desde hace varios años soy un usuario de vim, para todo. Desde escribir código en Python o cualquier lenguaje de programación, pasando por documentos HTML o CSS e incluso mi tesis la escribí usando vim. Recientemente he estado en una onda de probar nuevas cosas, lenguajes, herramientas e incluso editores para programar, hasta he estado considerando la posibilidad de comprarme una MacBook . Hace ya varios meses me enteré de que GitHub está trabajando en el desarrollo de un editor para programadores , cuando leí la noticia no había una versión para Linux, únicamente para Mac, cosa que me irritó un poco (bueno, bastante). A inicios de Noviembre me enteré de que ya había un release para linux, así que lo bajé y me propuse pasar al menos una semana probándolo, usándolo para todo lo que uso vim normalmente, he acá mis conclusiones al respecto. Me gusta * Gestor de paquetes propio * Muchísimos plugins para extenderlo * Funciona como editor de código de una vez, no hay que configurar nada * Los plugins se escriben en javascript, así que no es necesario aprender un lenguaje raro para hacer uno * Integración genial con git, muestra en el árbol de directorios todo lo que has modificado o agregado No me gusta * Demasiado lento para cargar * Modo vim no está 100% soportado * Atajos de teclado poco intuitivos * Para muchas cosas es necesario usar el mouse y ese cambio de contexto me distrae un poco * No hay actualizaciones automáticas para Linux. Conclusión Es muy parecido a sublime text, vale la pena probarlo, no me veo migrando 100% a atom en un futuro cercano o a mediano plazo pero es un proyecto interesante que pienso seguir a ver con qué features me sorprende la gente de github. Hasta luego. :wq!","tags":"Blog","loc":"http://localhost:8000/mi-experiencia-con-atom.html","title":"Mi experiencia con ATOM"},{"text":"Luego de algún tiempo desarrollando software, sea para web o escritorio, uno realmente termina de entender aquello que nos decían en Algoritmos y Programación I de Divide y vencerás , quizás en la Universidad uno no lo aplica mucho, tienes 8 proyectos y 14 parciales en una semana y tienes que salir de todo lo más rápido posible, entonces terminas escribiendo muchísimo terrible, quien sea inocente, que lance la primera piedra. Incluso a veces en el trabajo por la presión de los deadlines uno termina tomando atajos para hacer la cosa funcionar y dejar un comentario de estos que empiezan con TODO o FIXME para arreglarlo luego o advertir al resto del equipo que ese bloque de código debe ser arreglado o podría causar problemas más adelante. Lo primero que uno tiende a hacer es separar todo en funciones, tratar de que cada función que se escribe haga una y sólo una cosa, sin efectos colaterales, por ejemplo: def write_to_file ( f , text ): f . write ( text ) f . close () Esta función, claramente, no hace una cosa, hace dos, escribe un texto al archivo y luego lo cierra, esto es poco intuitivo, cualquiera llamaría la función dos veces y, la segunda, seguramente ocurre una excepción, lo ideal sería: Renombrar la función a write_to_file_and_close() o... Mucho mejor, simplemente cerrar el archivo en otra parte. ¿Ven?, divide y vencerás , nada difícil ¿no? Luego, conocemos las clases, los objetos y los paquetes (no, no esa clase de paquetes, no sean mal pensados), entonces, empezamos encapsular entidades en clases, cuyos objetos actuarán sobre los datos que maneja el programa y cada clase tendrá una y sólo una tarea específica, esta tarea la cumplirá porque todos y cada uno de los métodos que escribimos para ella están relacionados entre sí y están diseñados para trabajar en conjunto para lograr ese objetivo, es decir, tienen alta cohesión . Al mismo tiempo, estas clases, la agrupamos en paquetes o módulos , cada uno de estos, cumple también una tarea específica que no afecta el trabajo de los demás, es decir, tienen bajo acoplamiento , tenemos, normalmente, un módulo para acceso a datos, un módulo para la lógica compleja del programa y otro para interactuar con la Capa 8 de la red , es decir, el usuario. Hasta ahora, vamos bien, todo dividido en módulos y así arquitectamos nuestros sistemas por un largo tiempo, todo lo nuevo que hacemos, lo encapsulamos en un módulo aparte que se puede importar, y vio Dios que era bueno , entonces nos permitió seguirlo haciendo así. Construyendo un elefante Si trabajamos mucho tiempo iterando sobre el mismo sistema, la tendencia natural es que este crezca, entonces, la cantidad de módulos irá creciendo cada vez más, así como también los recursos que consume y, si todo sale bien, también crecerá el tráfico que tenemos que manejar, entonces, poco a poco sólo un gran servidor se irá quedando corto, ¿cuál es la solución natural?, escalar de manera horizontal y agregar más servidores corriendo detrás de un balanceador de carga, pero recordemos que estamos corriendo un sistema enorme con muchos módulos cargados en memoria, se necesita un servidor grande (y probablemente caro) para levantar algo tan pesado. Más allá de eso, empezamos a preguntarnos, ¿qué tanto se usa cada módulo?, por ejemplo, tenemos un módulo de registro de usuarios pero, no todos los usuarios que van a nuestra página, por ejemplo, necesitan registrarse, sin embargo, ese módulo está cargado N veces, donde N es la cantidad de servidores que tengamos sosteniendo nuestro monolito que, además, seguramente seguirá creciendo cada vez más. Eso por un lado, por otro lado, por otro lado, cada vez que vamos a liberar un feature nuevo, resolver un bug o simplemente cambiar un texto en una plantilla, tenemos que hacer deploy de un sistema pesado en N servidores, algo que puede tardar bastante tiempo y quizás causar downtime de algunos minutos, quizás perdiendo potenciales usuarios. Además, poco a poco hacer cambios en un codebase tan grande, se vuelve doloroso, es difícil de modificar, difícil de probar, difícil de escalar y, por lo tanto, difícil de mantener. ¿Trabajo de hormigas?, ventajas ¿Qué pasaría si cada módulo lo convertimos en un proyecto aparte?, sí, con su propio servidor y todo, tendríamos varios servicios que hacen una sola cosa y, simplemente, tendríamos que escribir clientes para esos servicios y utilizarlos cuando sea necesario y en el orden que sea necesario, ¿qué ventajas tiene esto? Por un lado, usamos servidores más pequeños y si, por ejemplo, los usuarios están subiendo muchas fotos, simplemente escalamos el \"servicio de gestión de fotos\" y listo, es decir, agregamos un nuevo servidor y eso debería soportar más tráfico. No creamos una instancia nueva de un servidor enorme con, además, partes del sistema que no está siendo usadas o que no están recibiendo tanto tráfico. Por otro lado, es más fácil conseguir errores, si falla el servicio de pagos, sabemos que algo está mal con ese servicio pues, la única manera de que algo llegue allí es a través de la interfaz HTTP que este servicio expone. También agregar features nuevos se convierte en una tarea fácil, no hay que modificar un proyecto enorme sino quizás agregar un servicio nuevo e integrarlo. Resolver bugs se convierte también en una tarea más fácil pues ya sabemos dónde está fallando y, a la hora de hacer un release, si hay downtime es sólo un servicio y los usuarios prefieren un En este momento no es posible completar tu solicitud, intenta en unos minutos que un En este momento estamos en mantenimiento, regresa luego , al menos pueden seguir usando las otras partes del sistema, ¿no?. Finalmente, permite que la plataforma sea políglota, es decir, si tienes todo hecho en Ruby on Rails, por ejemplo, pero quieres tener el motor de búsqueda con tecnologías de Web Semántica y, la mejor herramienta que conseguiste fue integrar Jena con Pellet como motor de inferencia y todo eso está en Java , simplemente es un servicio más que expondrá unas interfaces para que el resto pueda usarlo, así que realmente no importa en qué esté escrito. No todo es perfecto Como todo en software, no hay balas de plata para matar problemas, cada solución tiene también sus contra, algunos de los que he podido ver son los siguientes: Un request del usuario puede derivar en 50 o 60 requests internos a servicios, por lo que la velocidad de respuesta se aprecia, hay que tener en caché lo que se pueda e invalidar ese caché oportunamente para actualizarlo cuando sea necesario. Cuando el equipo es muy grande, no todos los desarrolladores conocen todos los servicios, siempre hay unos que saben más que otros y otros que saben mucho de algunos y nada de otros, es difícil mantener homogeneidad en el conocimiento acerca de todo el stack. Si un servicio no responde por alguna razón y las interfaces de los servicios son HTTP, ese request se pierde, por lo tanto no tendremos esos datos en el servicio que corresponda, así que si nuestro enfoque es optimista, el servicio que envió el request está contando con que todo salió bien, hay que pensar entonces en algún método que permita reintentar o, si falla la solicitud, tener un método de fallback para estos casos, quizás una cola para que el otro servicio empiece a procesar cuando se despierte o, quizás, cambiar las llamadas HTTP por colas compartidas. Las complicaciones de tener múltiples servidores tras un balanceador de carga se multiplican por el número de servicios que tengamos. Buenas prácticas Aplica todo lo que ya sabemos, pero hay que ser un poco más rigurosos. Documentación: además del código, hay que documentar la API que expone el servicio que escribimos. Tolerancia a fallos: además de servidores redundantes, es necesario tener un método de recuperación de datos en caso que falle algún servicio y algo no llegue a la base de datos. Pruebas: probar cada servicio es fácil, un set de pruebas unitarias hace el trabajo bastante bien, la cosa se pone un poco más difícil con la pruebas de integración, es necesario contar con los servicios con los que se va a interactuar a la hora de ejecutar estas pruebas. Deploy: se hace vital contar con un sistema de integración continua, de otra manera todo se nos puede salir de las manos y se vuelve poco mantenible. Monitoreo: es necesario monitorear todos los servicios para conocer dónde están los cuellos de botella y optimizar lo que sea necesario o tomar acciones para solventarlo. Además de saber cuándo un servicio está caído antes de que los usuarios empiecen a quejarse. Como todo, el nirvana no es solamente orientado a servicios, hay muchas otras maneras de arquitectar sistemas y todas son correctas dependiendo de las condiciones y el contexto que las rodean. Acá dejo una entrevista a uno de mis héroes personales sobre este tema, Werner Vogels, CEO de Amazon.","tags":"Blog","loc":"http://localhost:8000/cosas-que-he-aprendido-ventajas-de-soa.html","title":"Cosas que he aprendido: Ventajas de SOA"},{"text":"Bueno, no se si se habrán dado cuenta de un par de cambios por acá, sino, pues bueno, se los diré El primero de ellos es que decidí quitar mi CV de acá, no tiene sentido tenerlo junto con el blog, para eso tengo un perfil en LinkedIn y en la página de trabajos de StackOverflow , tener el CV publicado, además, en mi blog era otro lugar donde debía mantenerlo actualizado y, seamos sinceros, no soy famoso por lo que este blog deben visitarlo muy pocas personas y, generalmente, por casualidad, por no decir que por error. El segundo de los cambios es que ya no escribo sólo cosas técnicas o relacionadas con algo laboral, he decidido dedicar este pequeño espacio también a escribir reflexiones personales y, realmente, cualquier cosa que se me ocurra en general, sin dejar de lado el punto de vista medio nerd que me caracteriza Hay varios cambios que no son visibles en el blog, más que todo respecto a mi manera de ver las cosas y filosofía de vida, por ejemplo, he estado considerando seriamente comprarme una mac , cosa que hace poco más de un año era impensable, también he estado reconciliándome con temas y tecnologías que no eran de mi agrado para salir un poco de mi zona de confort, empezando por desarrollo de front end, es hora de enseriarme con eso. He estado probando otras herramientas para edición de código además de mi adorado vim , me han gustado bastante, sin embargo no creo que termine de migrar, a pesar de que las considero excelentes herramientas y ha sido interesante explorarlas, ya agregaré un par te posts al respecto. El otro cambio notable, es el tema, ya estuve un buen tiempo con el tema por defecto de Pelican y mi pana Carlos Gustavo Ruíz me pasó el link de este que tengo ahora, es open source y la verdad me agrada bastante. Se vienen un par de cambios más en los que estoy trabajando un par de subdominios interesantes acá y estoy también diseñando un nuevo tema para el blog, para tener algo hecho por mi y poner el práctica lo que aprenda de front, como ya dije, he estado jugando con bootstrap, jQuery, HTML5 y CSS3, saliendo de la zona de confort, veamos qué sale de todo esto.","tags":"Blog","loc":"http://localhost:8000/algunos-cambios-por-estos-lados.html","title":"Algunos cambios por estos lados"},{"text":"Bueno, no se si estoy intenso ya con el tema de las reflexiones pero esta será la última al menos por un buen tiempo, lo que ocurre es que hace poco conseguí un par de escritos que pensé que había perdido cuando formateé la computadora acá en Dubai apenas llegué. Esto lo escribí el Miércoles 7 de Mayo de 2014, justo el día que estaba emigrando. Acá... lo que escribí Siempre que viajo, tengo la mala costumbre de estar hasta la noche antes del vuelo haciendo maletas, esta vez no fue la excepción. Terminé de arreglar las cosas a las 2:00am con mi mamá, luego de eso me puse a ordenar un poco el closset pues es probable que mi prometida se quede en mi habitación hasta que, finalmente, nos casemos en diciembre. Al final terminé acostándome a las 5:00am. La mañana transcurrió sin mucha novedad, a las 11:00am ya estábamos bajando al aeropuerto y ya a las 13:00 estaba chequeado y sentado tomándome algo con mi familia, mi familia completa, la que me tocó (mi papá, mi mamá y mi hermano) y la que yo tuve la suerte de elegir (mi prometida y su familia). Por recomendación de la aerolínea, debía entrar al área de embarque a las 14:00, así que a esa hora nos dirigimos a la puerta que dirige a esa zona, las lágrimas no se hicieron esperar, abrazos y besos para decirnos \"hasta luego\" pues en diciembre estaré de vuelta. El camino al aeropuerto estuvo lleno de reflexiones, en una de las cuales planteé, ¿por qué tiene que ser así?, el ideal venezolano desde que tengo uso de razón siempre ha sido graduarse e irse del país, sea por trabajo o a estudiar un post grado, la cosa es, no debería ser así, ¿por qué no prosperar en tu propio país?, después de todo es tu casa, ¿no?. Pues la respuesta es muy sencilla, también, desde que tengo uso de razón, la manera de sobresalir entre los demás, no es hacer las cosas bien necesariamente sino ser más vivo que el de al lado , la supervivencia del más vivo o, como se dice coloquialmente, la viveza criolla , ojo, no digo que todo el mundo sea así, pero una gran mayoría piensa así, entonces, el ideal de éxito pareciera ser \"quédate y trata de ser más vivo que los demás, o vete a un país donde todo el mundo sea honesto y haz las cosas como deben ser\", es decir, no te comas la luz, cruza la calle por el rayado, no botes basura en la calle, no orines en la calle ni enseñes a tu hijo a hacerlo, entre muchas otras cosas. La verdad es que la conversación estuvo muy amena, como siempre con mi familia, la cuestión es que tomará bastante tiempo antes de sentarnos en la misma mesa como hoy, a disfrutar de un buen café y hablar de cualquier cosa, pasará algo de tiempo antes de que podamos volver a abrazarnos como hoy mientras nos despedíamos, ahora que estoy emprendiendo camino a otras latitudes, entiendo cuando mi mamá me decía \"algún día dirás, ¿por qué no abracé más a mis padres?\", le doy toda la razón, nunca he sido muy cariñoso porque no me criaron así, pero justo mientras escribo este post estoy sobrevolando el océano atlántico camino a mi primera escala, el asiento a mi lado está vacío, como también estará vacío el asiento frente a mi en unas horas cuando me siente a almorzar y mañana cuando me siente a desayunar, y el día siguiente, y el siguiente... darse cuenta de esto te pega un poco y despierta la nostalgia y, lo peor, es que es la realidad de muchas personas que han decidido experimentar \"la triste alegría de emigrar\". Creo que la misma situación del país me recordó las razones por las que los jóvenes profesionales deciden irse a probar suerte en otras naciones: justo pasando el chequeo de migración, escucho un llamado de la aerolínea: \"pasajero de Lufthansa Israel Fermín, favor presentarse en la puerta de embarque número 12\", pensé que estaban abordando temprano así que me apuré a la puerta de embarque, allí me informan que una de mis maletas fue \"seleccionada para revisión\" y que debía bajar al área de equipaje para abrirla, vaciarla y examinar su contenido. Allí, un Guardia Nacional del Comando Antidrogas era el encargado de revisar mi maleta, a pesar de que traté de buscarle conversación no era muy hablador, pero tampoco me trató mal ni fue mal educado, simplemente hizo su trabajo, de manera muy ordenada (de verdad, no es sarcasmo) vació el contenido, revisó la manera y volvió a colocar todo en su lugar. Luego de eso, le pregunto al encargado de equipaje que me acompañó si de verdad consiguen mucho contrabando de esa manera, la respuesta fue afirmativa, no sólo eso, sino que \"es algo de todos los días\", de hecho, hace una semana \"aprehendieron a una familia completa\", sí, \"el señor, la esposa y dos niñas menores de edad\", según el señor la mayor tendría más o menos 5 años. Luego de la revisión de equipaje, el vuelo se retrazó unos minutos, dándome tiempo de comer algo antes del vuelo para amortiguar, entre los locales de comida, había una arepera que de verdad no se veía bien, quería irme por lo más económico, y lo siguiente más económico era Burger King, hago mi cola que cada vez se hacía más larga gracias a la lentitud del servicio y de la única cajera que se multiplexaba en tiempo entre la cocina y la caja. Finalmente, cuando voy a pedir, no hay tocineta, no hay aros de cebolla, no hay... bueno, ya estamos acostumbrados, al final pedí el combo de \"Dos hamburguesas con queso\" por el cual me quedan debiendo 5 bolívares porque, de nuevo, no hay cambio. En la cola para retirar el pedido, de nuevo, haciéndose cada vez más larga porque no repartían, informan que la máquina de refrescos está dañada y que no hay refrescos y que no entregarían los pedidos hasta que la arreglaran, allí solté mi tradicional \"coño de la madre, qué peo\" (perdonen si leen y no esperan malas palabras en un blog), al final, molesto, pido mis hamburguesas, mis papas o que me regresen mi plata, así que me dan mis hamburguesas (frías... además de pequeñas), al finalizar mi delicioso almuerzo (esto sí es sarcasmo), abordé el avión. Lo que más me impresionó del episodio de Burger King, no fue el hecho de que no hubiera nada, ni el mal servicio, sino que yo era el único que estaba molesto y que estaba reclamando algo, los demás estaban resignados a esperar quien sabe cuánto tiempo a que arreglaran la máquina de refrescos, les dieran hamburguesas heladas y, seguramente, un refresco que sabe a pura soda. Esa misma actitud de \"cállate que sino te van a joder\" es la que nos tiene con el agua hasta el cuello y, también, esa actitud de \"si puedo jodo al que me cae mal, me mire o me hable feo\" es la que sigue echándole agua a la piscina en la que, si seguimos como vamos, nos ahogaremos todos, mi pregunta es, ¿hasta cuándo vamos a vivir en la mierda?, ¿hasta cuando vamos a aceptar un \"no hay\" por respuesta?.","tags":"Blog","loc":"http://localhost:8000/reflexion-del-dia-que-me-fui-del-pais.html","title":"Reflexión del día que me fui del país"},{"text":"Revisando archivos viejos luego de que migré a Linux Mint , conseguí algo que escribí unos 3 días antes de emigrar, recuerdo haberme sentado en mi escritorio, aún sin poder creer que me iba de casa, que me iba de mi país, sintiéndome muy impotente de toda la situación que me había obligado a tomar esa decisión, como he dicho varias veces, a nadie le gusta estar lejos de sus seres queridos. Recuerdo que encendí la computadora, inicié vim y simplemente empecé a escribir, quiero compartir acá con ustedes lo que escribí esa noche antes de acostarme a dormir con la ansiedad del viaje que me esperaba. Esto fue lo que escribí La verdad, es que me describo como una persona poco emotiva, quizás un poco seca y poco sentimental. Varios de mis amigos se han ido, familiares, incluso, están haciendo vida ya fuera del país que lo tiene todo y al mismo tiempo no tiene nada y, en sus respectivas despedidas, estuve siempre tranquilo. Todo cambia cuando el protagonista de la despedida es uno, me jacto de siempre hacer valer la lógica por encima de los sentimientos al mejor estilo vulcano pero, ante ciertas situaciones, no hay manera de evitar que el lado humano aflore, ni Spock está excento de sucumbir ante sus emociones de vez en cuando. Mientras preparo las maletas, pongo a punto mi bolso de mano con todos los documentos que voy a necesitar durante el viaje de casi 24 horas, no puedo evitar, en mi cuarto, ver todos los adornos, cosas que me han regalado y, en mi mente, revivir esas anécdotas, ex-novias que me han dado cosas que aún conservo, buenos amigos que me han obsequiado otras y, lo más importante, las cosas que me ha dado mi prometida que siempre mantengo a la vista. Historias detrás de los objetos que permanecen en las repisas de mi habitación, inertes, testigos de cómo voy tomando algunas que quiero llevarme y metiéndolas en mi bolso mientras, otras, permanecerán allí, inmóviles, agarrando polvo esperando que nos veamos de nuevo algún día. Hablar del tema con mi familia, me afecta un poco, quizás bastante. Me voy a un lugar \"no-tan-cercano\", donde hay que tomar como mínimo dos aviones para poder llegar finalmente al destino, donde el pasaje es muy costoso como para darse el lujo de \"ir de vez en cuando a visitar\" y más aún con la situación actual de mi país. Veo a mi abuela con los ojos aguados, tratando de no llorar, mi tía de crianza, Carmen Carrillo, también conteniendo las lágrimas y deseándome buen viaje. Mi mamá, mi papá y mi prometida, tratando de aprovechar al máximo estos últimos días juntos, días en los que decidí poner de lado mis proyectos para dedicarme a estar con mi familia y terminar ciertas diligencias para el viaje. Días en los que me doy cuenta de los obstáculos y las trabas que ha colocado el gobierno para restringir aún más la salida de venezolanos a otras tierras, aún cuando sea sólo por placer, salir de Venezuela es un privilegio y un lujo que sólo algunos pueden darse mientras vemos a los familiares de quienes hoy detentan el poder conociendo todo el mundo y gozando de tantas comodidades que parece absurdo, no puede haber otra reacción más que incrementar mi alivio por salir y mi repulsión hacia quienes han causado tanto daño. Mi nombre es Israel Fermín Montilla, tengo, a la fecha, 27 años de edad, VENEZOLANO de nacimiento y de corazón y para el momento de escribir esto, faltan 3 días para irme del país, en búsqueda de un mejor futuro para mi, para mi prometida, que en diciembre será mi esposa, y para los hijos que planeamos tener, los nietos que queremos darle a nuestros padres. Lamentablemente, en la Venezuela actual hay pocas oportunidades de desarrollo, la posibilidad de independizarse, salir de la casa de los padres y tener uno su propia vivienda es casi, por no decir, totalmente, nula. He visto a mis amigos partir, quienes me conocen saben que he luchado hasta donde he podido, pero me apena confesar que me venció el cansancio, ¿qué pensaría mi abuelo hoy de mi?. En 3 días estaré viajando a un lugar donde seré un completo extraño, perdóname Venezuela, por dejarme vencer por el fantasma del cansancio y dejar de nadar contra la corriente para llegar a rescatarte, espero que todo mejore pronto y se que cuando decida volver, me recibirás con los brazos abiertos como buena madre. Familia, amigos, compañeros, conocidos… Hasta siempre!! -- Israel.","tags":"Blog","loc":"http://localhost:8000/algo-que-escribi-antes-de-emigrar.html","title":"Algo que escribí antes de emigrar"},{"text":"Bueno, sí, leyeron bien el título, luego de años me tocó trabajar de nuevo con php en la oficina, dejen el escándalo. Siendo sincero, las cosas parecieran haber mejorado mucho desde la última vez que hice (o traté de hacer) algo con php, era php 4.algo en aquel momento, jugaba con Symfony y fue una desgracia que no se la deseo ni a mi peor enemigo. Luego, más recientemente jugué con Yii , un framework para desarrollo web con php que me pareció bastante bueno y es una alternativa que le recomiendo a todo aquel que no tenga más remedio que desarrollar usando este lenguaje, algunos me dicen que pruebe Lavarel y seguramente me cambie a php, pero dudo mucho que algo me atrape tanto como Python , sin importar el framework, incluso Web2Py tiene muchas cosas rescatables. Bueno, manos a la obra: La historia: En la oficina están en una onda de intercambiar código con nuestros aliados comerciales o \"páginas hermanas\", el problema es que nosotros desarrollamos en Python + django y a veces bottle y todos los demás en php. Este proyecto en particular, fue desarrollado con un framework hecho en casa en php y es usado como una librería para autenticación utilizando servicios de 3eros, es decir, OAuth . Esto en un mundo ideal, donde todo lo programas con php y puedes simplemente hacer: use project\\module\\submodule\\file; y todo bien. El problema: Obviamente, no podemos importar código php en nuestro proyecto en Python , entonces, la solución fue simplemente, adaptar la librería provista por la otra gente para usarla como un servicio, la cosa salió bastante bien, pero al momento de poner todo en producción, nos dimos cuenta de algo. Se desplegaron dos instancias de este servicio detrás de un balanceador de carga, para autenticar usando OAuth , es necesario golpear más de una vez el servicio, entonces, estando dos (o más) instancias detrás de un balanceador de carga, no tienes manera de garantizar que quien atiende el primer request , es el mismo que atiende el segundo. A esto súmale que se guarda cierta información en la sesión para mantenerla durante todo el proceso de autenticación y php almacena las variables de sesión en un archivo local del servidor. La solución: Sin pensarlo mucho, la solución es tener algo que todas las instancias compartan para escribir la información relacionada a las sesiones, puede ser una base de datos MySQL , un sistema de archivos compartido con NFS , lo que sea, nosotros optamos por Redis porque es lo más rápido y fácil de configurar, responde rápido porque mantiene ciertas cosas en memoria y es difícil que pierda datos, puede pasar, pero igual es información transitoria que no nos interesa conservar. Implementación: Luego de investigar unos minutos, nos dimos cuenta de que no era nada del otro mundo, simplemente cambiar unos parámetros de configuración en los respectivos archivos php.ini , instalar un par de paquetes y listo. Instalación de paquetes: Descargamos php-redis sudo aptitude install php5-dev cd php_redis/ sudo phpize sudo ./configure sudo make sudo make install php.ini: Simplemente debemos modificar las siguientes líneas: extension=redis.so [Session] session.save_handler=redis session.save_path=\"tcp://localhost:6379\" El save_path debe tener la IP y el Puerto donde nuestra instancia de redis estará escuchando. Conclusión: Ciertamente las cosas han mejorado sólo un poco en php desde la última vez que lo usé para algo más que un proyecto de juguete. Sin embargo no me veo programando en php a menos que sea estrictamente necesario por las características o restricciones de un proyecto en particular. Respecto al servicio de autenticación, ya está en producción, pareciera estar funcionando bastante bien, sin embargo hay muchas cosas con las que no estamos contentos, seguramente terminemos cambiándolo por una versión 2.0, seguramente en Python y desarrollado por nosotros pero, al menos por ahora, funciona y hace el trabajo.","tags":"Blog","loc":"http://localhost:8000/usando-redis-como-backend-de-sesiones-en-php.html","title":"Usando Redis como backend de sesiones en php"},{"text":"Bueno, octubre fue un mes no muy activo en cuanto a películas, agregué unas nuevas al watchlist de las cuales vi algunas, pero no taché ninguna de las viejas. A ver, la cosa va así Listas de películas Lo más fácil es verlo por separado No vistas último lote The Blues Brothers (1980) The Shawshank Redemption (1994) The Godfather (1972) ./ The Godfather: Part II (1974) ./ The Godfather: Part III (1990) ./ The Good, the Bad and the Ugly (1966) 12 Angry Men (1957) Forrest Gump (1994) One Flew Over the Cuckoo's Nest (1975) Goodfellas (1990) The Matrix (1999) Seven Samurai (1954) City of God (2002) Se7en (1995) The Usual Suspects (1995) The Silence of the Lambs (1991) It's a Wonderful Life (1946) Once Upon a Time in the West (1968) Léon: The Professional (1994) The Raiders of the Lost Ark (1981) Casablanca (1942) Life Is Beautiful (1997) Nuevas no vistas The Monster (1994) ./ Startup.com (2001) ./ The Last Godfather (2010) To Rome with Love (2012) Code Rush (2000) Pirates of Silicon Valley (1999) Devil's Advocate (1997) Memento (2000) Requiem for a Dream (2000) Oldboy (2003) Oldboy (2013) Rear Window (1954) The Dark Knight Rises (2012) Saving Private Ryan (1998) Full Metal Jacket (1987) A Clockwork Orange (1971) American History X (1998) The Prestige (2006) Indiana Jones and the Last Crusade (1989) Batman Begins (2005) E-Dreams (2001) The Green Mile (1999) Spaceballs (1987) Johnny Stecchino (1991) Scarface (1983) Trainspotting (1996) The Machinist (2004) Snatch (2000) The Startup Kids (2012) Blues Brothers 2000 (1998) Inglourious Basterds (2009) The Sixth Sense (1999) Hackers are People Too (2008) Wall Street: Money Never Sleeps (2010) A Beautiful Mind (2001) The Social Network (2010) Capitalism: A Love Story (2009) Vistas en Octubre The Godfather (10/10): creo que de las películas que vi en octubre fue la mejor, es como un Breaking Bad pero con la mafia italiana y hecho película, de héroe de guerra a capo de la mafia. The Godfather: Part II (8/10): no me gustó tanto, cuenta la historia de cómo Vito Corleone llegó a donde estaba, mientras cuentan cómo su hijo, Michael Corleone quien se hace cargo del negocio familiar luego que el viejo muere, trata de expandir y hacer legal el dinero de su familia. La cosa es que entre tantos saltos entre el presente y el pasado a veces la película se vuelve un poco confusa. The Godfather: Part III (9/10): es bastante buena, aunque algo lenta, al final, una vez que estás en ese mundo, es imposible salir de él y es lo que se ve en la tercera parte. The Monster (9/10): es una película italiana, con Roberto Benigni, además, dirigida por él mismo. Es súper cómica, es sobre un asesino serial y maniático sexual que anda suelto y, por una serie de coincidencias, Loris , el personaje que interpreta Roberto Benigni, es el principal sospechoso. Startup.com (7/10): es un documental sobre uno de los primeros startups a finales de los 90, govworks.com, era una manera de pagar tus tickets de estacionamiento, multas, etc, vía internet, quebró en el 2000 y Startup.com cuenta la historia de cómo consiguieron financiamiento, los problemas internos que tuvieron y luego cómo llegaron al punto final. Listas de series: Viejas no vistas Star Trek (1966) Star Trek The Next Generation (1987) Star Trek Enterprise (2001) Star Trek Voyager (1995) Star Trek Continues (2013) The Borgias (2011) Nuevas no vistas Nerds 2.0.1: A Brief History of the Internet (1998) The Tudors (2007 - 2010) Orphan Black (2013 - ) Orange is the new Black (2013 - ) Vistas en Octubre Ninguna, sí, he estado flojo para ver series Reporte de libros Terminé de leer Effective Programming de Jeff Atwood, es genial, muy buena compilación de artículos sobre temas diversos del mundo del software relacionados o no a la programación. Ahora estoy leyendo Padre Rico, Padre Pobre , no tiene nada que ver con programación ni mucho menos es una novela, simplemente lo veo como una manera de organizar mis finanzas porque soy un desastre administrando mi propio dinero y, cuando estás viviendo solo, aprender a administrarte y masterizar ese arte es algo poco más que de vida o muerte.","tags":"Blog","loc":"http://localhost:8000/reporte-de-peliculas-libros-y-series-octubre-2014.html","title":"Reporte de películas, libros y series Octubre 2014"},{"text":"Voy ya para cinco meses viviendo fuera del país y empiezo a ver las cosas de otra manera, quizás estando en Venezuela todo estaba tan caótico que me impedía pensar \"fuera de la caja\", quizás llegó el momento en el que dejó de importarme y me enfoqué en mis asuntos y en ayudar en lo que estuviera en mis manos, lo que sí estoy seguro es que desde afuera y conociendo otra cultura veo las cosas desde otra perspectiva. Quizás uno ya ve todo como normal, pero, ciertamente no lo es, me pregunto, ¿por qué?, ¿qué está mal en latinoamética?, ¿seremos los latinos?, ¿será verdad que la culpa la tienen los españoles por mandar puros vagos, borrachos y piratas a conquistarnos?, no lo se, lo que sí se es que tengo demasiadas preguntas similares y dudo que pueda responderlas todas, pero bueno, acá vamos. Creo que todos sabemos que Venezuela tiene una de las reservas petroleras más grandes del mundo , ¿no?, no es secreto para nadie, estamos acampando, nos dieron ganas de ir al baño, cavamos una letrina y BOOM , conseguimos petróleo mágicamente, bueno, quizás exagero, pero estamos de primeros en la lista, seguidos de cerca por Arabia Saudita. No compararé Venezuela con Arabia Saudita por varias razones Están de segundos en el listado de países con más reservas de petróleo en el mundo, muy cerca de Venezuela. Son una de las cuatro monarquías absolutas en la actualidad, con todos los avances en esta era moderna, considero que estan atrasados en lo político y lo social, o eso es lo que mi mente occidental piensa. Hay muchas cosas básicas que no están permitidas o están realmente censuradas. Voy a comparar con los Emiratos Árabes Unidos (UAE) pues es una experiencia que puedo contar de primera mano pues, a la fecha, llevo casi 5 meses viviendo en Dubai. Empecemos por las reservas petroleras, Venezuela es el primero, UAE el séptimo, es decir, estamos, por mucho, encima de UAE en cuanto a reservas de petróleo. El petróleo, sigue siendo el principal combustible para casi todo , y sus derivados también están presentes en casi todo lo que vemos, así que parece ser un buen negocio. Venezuela inició su carrera independentista del imperio español el 19 de abril 1810, cuando se llevó a cabo el primer referendum de nuestra historia, aquel en el que el Capitán General Vicente Emparam va al balcón a preguntarle al pueblo si quieren que él siga gobernando, el Padre José Cortés de Madariaga, chileno de nacimiento, agitaba la mano por detrás del Capitán General, algunos dicen que estaba espantando una mosca, otros dicen que le hacía una señal negativa al pueblo, lo cierto es que el pueblo gritó un rotundo \"NO!\" y así empezó nuestra agitada carrera hacia la independencia, la cual sellamos el 24 de junio de 1821 con la victoria de nuestro ejército patriota, Forjador de Libertades[1], en Carabobo. O eso es lo que dicen los textos de historia que estudié en el liceo. Por su parte, UAE logró su independencia del Reino Unido en 1971 no he leído mucho de su historia aún, pero lo que sí se es que hasta principios de la década de los 90, esto era un desierto , y hablo de Dubai, en 13 años levantaron rascacielos, para 2008 o 2009, ya tenían incluso islas artificiales, hoy día el edificio más alto del mundo queda en Dubai ( Burj Khalifa ), los edificios 100% resicenciales más altos del mundo también ( 23 marina y Princess Tower ) e incluso uno de los hoteles más lujosos del mundo, contruido en una isla artificial ( Burj al Arab ). Ahora bien, todo esto fue a punta de petróleo, acá no hay bellezas ni muchos recursos naturales, sí, hay playas muy bonitas, pero ¿montañas?, ¿nieve?, ¿picos?, ¿sabana?, pues no, acá donde no hay rascacielos y edificios enormes, hay arena, no estoy seguro cómo obtenemos agua potable acá porque según me han dicho, son contadas las veces que llueve durante el año, así que no creo que haya embalses naturales como en Venezuela, ¿turismo? hoy claro que sí, hay maravillas arquitectónicas y de ingeniería, invirtieron sus ganancias petroleras en infraestructura, servicios y crecimiento. En Venezuela, ¿qué hemos hecho con el petróleo?, desde que estudiaba primaria, mi maestra de sociales siempre decía \"Venezuela es un país monoproductor de petróleo\" y eso mismo fue repetido por distintos profesores hasta que salí de bachillerato y luego durante la Universidad, en una que otra materia social (recuerden que estudié Ingeniería), también, el mismo cuento y las mismas palabras. Todo, lo que se hace en Venezuela, es también a punta de petróleo , entonces, por qué hay rascacielos, islas artificiales y autopistas de 16 canales en Dubai, mientras que en Venezuela aún hay que pasar por carreteras de tierra para llagar a algunos pueblos en los que llega señal celular de Movistar, pero no una línea telefónica de tierra de CANTV, y ni hablemos de internet de banda ancha. Mientras en un país se levantan rascacielos, en el otro tardan años para reparar una torre quemada de Parque Central. Y eso que Venezuela tiene más tiempo en el mercado petrolero que UAE, Venezuela es uno de los países fundadores de la OPEP (Organización de Paises Exportadores de Petróleo) en 1960, mientras que los Emiratos Árabes, ingresaron en 1967, y en un país las escuelas parecen universidades americanas (sí, las escuelas, colegios, liceos), y en el otro el sistema de educación pública y gratuita a veces sufre para iniciar el año escolar por falta de pupitres, goteras o fugas de agua en los baños. No comprendo, además, cómo en un país es normal ver tasas de homicidios de 60 o 70 por semana, mientras que en el otro le roban el bolso a un amigo en la playa (ayer) con la ropa, el celular y las llaves del apartamento y todo el mundo está impresionado por la noticia. Cómo UAE teniendo mucho menos petróleo que Venezuela, está en el lugar 28 entre las economías más estables del mundo , mientras que Venezuela aparece de cuarto si contamos de forma regresiva. Esas son todas las preguntas que me hago, cualquiera podría decirme \"el desarrollo de un país no se mide por la cantidad de rascacielos que tenga\", es cierto, vamos a verlo por calidad de vida, en Venezuela, ejerciendo mi profesión, mudarme de casa de mis padres, así fuera a una habitación, era un sueño. Acá, puedo alquilar algo decente tranquilo, hacer mercado y darme uno que otro gusto de vez en cuando, y en una posición \"de menor jerarquía\" en la cadena alimenticia, en Caracas, era Lead developer / CTO de un startup de telefonía en la nube, acá soy Jr. Software Engineer . No vamos a verlo por cantidad de rascacielos, vamos a verlo por cantidad de recursos naturales, en Venezuela tenemos Petróleo, Gas, Carbón, Aluminio (Bauxita, creo), Oro, Níquel, Cobre, Hierro, incluso creo que Diamantes y, además Energía Hidroeléctrica según recuerdo de las clases de Geografía del Prof. Tito Calderón. No vamos a verlo en cantidad de rascacielos, vamos a verlo en posibilidades de hacer turismo, y digo turismo natural: tenemos la Isla de Margarita, donde tengo entendido que se puede hacer surf, wind surf y kite surf y además, las playas más impresionantes que he visto se encuentran contenidas en los más de 4mil Kilómetros de costa venezolana, los ríos en la sabana, donde se puede hacer Kayak extremo, la Gran Sabana, los asentamientos indígenas en Amazonas y Delta Amacuro, la caída de agua más alta del mundo, el Salto Ángel, la Cueva del Guácharo, tenemos sabana, desierto, playa y montaña, todo en un mismo país de poco menás de 900 mil kilómetros cuadrados, ¿no tan grande eh? y además suelos fértiles por todos lados. Cómo es posible que un país, mi país, teniendo todo eso esté en las condiciones que está, que toda la población joven y profesional está emigrando, literalmente dejando el pelero . Dicen que nadie es profeta en su tierra, mi teoría es que Arturo Uslar Pietri es el hombre que ha estado más claro en la vida cuando escribió su artículo \"Sembrar el Petróleo\", mi teoría es que en algún momento oculto de la historia, se vino de paseo al medio oriente y, como el suelo es pura arena y es muy difícil hacer crecer plantas, hicieron crecer edificios. ¿Alguien me puede explicar? [1] Hoy, Follador de libertades","tags":"Blog","loc":"http://localhost:8000/algo-hemos-hecho-mal-en-venezuela-que.html","title":"Algo hemos hecho mal en Venezuela, ¿qué?"},{"text":"Llevo ya un par de meses considerando la posibilidad, sí, YO, Israel Fermín Montilla llevo un par de meses considerando la posibilidad de comprarme una MacBook . No, no me hackearon github y subieron este artículo, tampoco estoy sufriendo de algún tipo de enfermedad mental, mucho menos considero que he aprendido todo lo que hay que aprender de Linux, tampoco me fastidié de Linux, simplemente estoy considerando la posibilidad. En Venezuela era impensable e incomprable, pero acá, es algo que puedo hacer, podría fácilmente adquirir una MacBook Pro retina display, instalar homebrew y usarla también como máquina de desarrollo, ¿por qué no probar algo diferente? Siempre he sido un crítico de Apple y de todo lo que representa, siempre he dicho que es una fábrica de juguetes y que el único juguete que sirve es el iPod Classic, porque es fácil de usar, cumple su cometido muy bien y le cabe una cantidad grosera de música, el mío es de 160GB y tengo todos mis discos allí metidos y aún le cabe más música. También siempre me he burlado de los fanáticos de Apple , les digo iSheeps porque, básicamente, así se comportan. Yo no soy una oveja, creo que soy mejor que eso, pero luego, pensando al respecto, tener una Mac, no me hace iSheep , comprar todo lo que tenga la manzana mordida y ciegamente decir que es superior aunque técnicamente sea falso sí, al fin y al cabo, como Ingeniero y como programador, siento que debería aunque sea probar para definir si es bueno o malo. Algunas de las ventajas que veo respecto de tener una Mac son: Software que funciona: no es que Linux no funcione es sólo que a veces requiere de algunos pasos adicionales de configuración para que funcione como debe ser, en Mac simplemente instalas y ya, igual que en Windows. Sistema operativo estable: no es que Linux no sea estable, es que Windows, la otra alternativa en cuanto a sistemas operativos \"mainstream\", no lo es tanto, acá Linux y Mac, parecieran estar a la par pues ambos son sistemas Un*x (o eso es lo que nos hacen creer). Compatibilidad: bueno, no es que en Linux haya problemas con drivers ¿verdad?, uno siempre logra hacer funcionar las cosas, a veces cuesta un poco más de tiempo, pero no hablemos de drivers y software técnico, la mayoría de los entornos de desarrollo y servidores de base de datos, storage no-sql, etc funcionan perfecto en Linux, hablemos de software para uso diario, Skype , el plugin de Hangouts para Chrome , estemos claros que LibreOffice apesta, hay muchas alternativas para producir documentos, incluso de mayor calidad que con Word , PowerPoint o incluso KeyNote , está LaTex, por ejemplo, y hay miles de librerías para producir presentaciones excelentes usando HTML, y JavaScript, pero muchas veces uno simplemente quiere hacer algo rápido, sin necesidad de escribir mucho código. Skype, por ejemplo, es imposible de instalar en Debian , el paquete está corrupto, el de Ubuntu y Linux Mint funciona perfecto, lo mismo que con los plugins de HangOuts , incluso el plugin de Flash Player me ha dado problemas en Ubuntu luego de un tiempo. Software de grabación: todos saben que toco guitarra, me gustaría empezar a grabar las cosas que compongo, Audacity apesta y Ubuntu Studio a veces me deja mal. He visto mucha gente trabajar con Garage Band y hacer cosas geniales. Esas son algunas de las razones que consigo como para una eventual migración, según tengo entendido, son geniales como máquinas personales y para realizar trabajos multimedia, bueno, me consta porque mi hermano es diseñador gráfico y todo lo hace allí, igual en varios estudios de grabación (claro, ellos usan Pro Tools ). Mi mayor preocupación al respecto es la ausencia de un gestor de paquetes nativo, no puedo simplemente hacer aptitude install y que todo funcione de maravilla. Todos los usuarios Mac en la oficina me dicen que homebrew hace el trabajo bastante bien, incluso, mi pana de PyVE Wil Álvarez me dice que es algo que vale la pena probar y que está súper feliz programando en su MacBook . Simplemente lo estoy considerando, necesito leer más al respecto, quizás jugar un par de días con una a ver qué decido hacer. Mientras... les dejo un video con los 66 comerciales de Mac vs PC .","tags":"Blog","loc":"http://localhost:8000/y-si-me-compro-una-mac.html","title":"¿Y si me compro una Mac?"},{"text":"Bueno, ya dije que estoy solo en otro país, pero no dije a dónde me fui, emigré a los Emiratos Árabes Unidos, estoy viviendo en Dubai y llevo ya casi cinco meses por estos lados. Al principio salía, hay muchos bares, pero ya me fastidié de eso, se gasta mucha plata y al final no te deja nada en la cabeza más que el ratón[1] al día siguiente, desde el mes pasado decidí que voy a empezar a ver películas y series, escuchar música nueva y a retomar el hábito de la lectura en mis ratos libres, como ya estoy trabajando en proyectos personales, me viene bien distraerme de vez en cuando. La cosa es que acá casi todos los canales están en árabe o, cuando no, doblados el hindi y subtitulados en árabe, así que es imposible entender algo, cuando estaba en el hotel en el que me puso la compañía cuando llegué, tuve suerte de vez en cuando con algunas películas que conseguía en inglés, pero no era lo común, en general acá veo poco o nada de TV, así que opté por reconciliarme con mi viejo amigo FrostWire desarrollado por el pana Gubatrón (AKA, Ángel León) para descargar películas, series y música para entretenerme, soy de los que descarga un montón y luego, si me gusta, la compro original en línea o en alguna tienda, hay películas, series y álbumes que vale la pena tener originales y es una manera de retribuirle al artista por un buen rato disfrutando de su arte. Como buen geek , necesito siempre alguna herramienta que me ayude a monitorear las cosas que hago, antes de mudarme, estaba trabajando en un programa para organizar mi colección de discos (tengo bastantes en casa, y por casa me refiero a Caracas), para este caso, ¿qué mejor herramienta que IMDB ?, me registré y procedí a ver las películas con mejor puntaje y a agregarlas a mi watchlist , igual algunas series, acá va mi conteo: Películas American Psycho (2000) ./ Psycho (1960) ./ The Shining (1980) Pulp Fiction (1994) ./ The Blues Brothers (1980) The Shawshank Redemption (1994) The Godfather (1972) The Godfather: Part II (1974) The Godfather: Part III (1990) The Good, the Bad and the Ugly (1966) The Good, the Bad and the Ugly (1966) 12 Angry Men (1957) Forrest Gump (1994) One Flew Over the Cuckoo's Nest (1975) Goodfellas (1990) The Matrix (1999) Seven Samurai (1954) City of God (2002) Se7en (1995) The Usual Suspects (1995) The Silence of the Lambs (1991) It's a Wonderful Life (1946) Once Upon a Time in the West (1968) Léon: The Professional (1994) The Raiders of the Lost Ark (1981) Casablanca (1942) Life Is Beautiful (1997) Hay algunas que ya he visto pero hace mucho tiempo y no recuerdo, por ejemplo, Indiana Jones, La Vida es Bella y The Matrix, es justo volverlas a ver. American Psycho (7/10): me gustó, pero no me pareció excelente, tengo que leer el libro a ver que tal, al final no se si el pana estaba soñando o si de verdad mató a ese gentío, para mi, estaba soñando y todo lo imaginaba, todos siempre imaginamos cosas de ese estilo... ¿o soy sólo yo? ¿huh? mejor no sigo. Psycho (10/10): de verdad me pareció excelente, y más después de ver Bates Motel simplemente brillante, me mantuvo a la expectativa durante una hora y algo que es lo que dura, es una película vieja (la vi en blanco y negro), pero es realmente buena, Hitchcock no me ha dejado mal, esta es la cuarta película de él que veo y las 4 han sido geniales. Las otras tres fueron: The man who knew too much , I confess y The 39 steps . Pulp Fiction (8/10): ¿qué puedo decir?, Quentin Tarantino es de mis favoritos, siendo sincero, fue todo lo que esperaba, me gustan mucho las películas que empiezan con una serie de historias que al inicio no tienen sentido, pero que al final entiendes qué pasó y cómo todas se van entrelazando, sin embargo, creo que tiene demasiadas escenas de relleno. Series: Bates Motel (2013) ./ The Blacklist (2013) Star Trek (1966) Star Trek The Next Generation (1987) Star Trek Enterprise (2001) Star Trek Voyager (1995) Star Trek Continues (2013) The Borgias (2011) De acá he visto casi toda Star Trek original o TOS como la llaman los Trekers , pero la tengo algo abandonada. Las últimas series que vi y me gustaron fueron Breaking Bad que me mantuvo enviciado durante todo Diciembre de 2013 y House of Cards que las dos temporadas las vi como en dos o tres semanas, luego de eso no había vuelto a ver series. Bates Motel (9/10): al principio no parece tan buena, pero como al 3er o 4to episodio te atrapa (como House of Cards ), es un poco como Breaking Bad , no es que las esté poniendo al mismo nivel, pero el personaje principal, Norman Bates , parece ser una buena persona, tranquilo, no daña ni a una mosca (como Walter White , la diferencia es que cuando Normal hace algo malo, pareciera no estar consciente de sus acciones, aunque puede llegar a recordar algunas cosas, si ya viste Psycho , muchas cosas tendrán sentido, sino, ve primero Bates Motel que cuenta toda la historia previa a la película. No se cuál veré ahora, seguiré agregando series y películas al Watchlist . Libros: La última novela que leí fue Drácula, de Bram Stoker, es el primer y último libro de vampiros que creo que leeré en mi vida, no porque no me haya gustado, sino porque de verdad dudo mucho que haya alguno mejor, es brutal, te mantiene en suspenso y es tan descriptivo con las escenas que asusta en algunos momentos. Actualmente estoy leyendo: Effective Programming, more than just writing code - Jeff Atwood Está bastante bien, es una recopilación de artículos de su blog y toca varios temas, desde programación y algoritmos, pasando por gestión de equipos y trabajo remoto y hasta algo de psicología del programador. Algunos son injustificadamente largos, otros son largos pero interesantes y la mayoría con cortos e interesantes o divertidos, dependiendo del tema. Aún no tengo una lista de libros por leer pero apenas la tenga, la colocaré por acá. Se aceptan recomendaciones en los comentarios de este post. Música: Lo último que he estado escuchando y, descubrí que me gusta, es bachata y merengue, pero no cualquiera, he estado pegado con Juan Luis Guerra , me parece que es un genio, la manera como escribe, las composiciones, los arreglos (sobre todo los bajos y los metales), todo tiene sentido y es arrechísimo[2], claro, tiene que serlo, se graduó en Berklee . Debe ser que como estoy lejos de mi país, toda la sangre latina se me subió a la cabeza, he estado escuchando mucho Rubén Blades , Héctor Lavoe y Willie Colón . A mi me parece algo normal, porque me recuerda a casa en cierta manera, pero acá parece ser algo súper exótico, lo cual me parece cool. He estado escuchando también mucho Jazz , sobre todo Vital Information y John Scotfield , y un poco a Alan Holdsworth , también se aceptan recomendaciones en comentarios a este post. Quiero escuchar cosas diferentes, algo de Ska , o fusiones raras, llevo mucho tiempo escuchando Blues y rock de los 60 y 70. Bueno, además de trabajo, ando en esto. jeje, nos leemos luego. [1] Venezolanismo para \"resaca\". [2] Venezolanismo para algo que es extremadamente bueno. También se usa para indicar molestia.","tags":"Blog","loc":"http://localhost:8000/en-mi-watchlist.html","title":"En mi watchlist"},{"text":"Wow, la semana pasado publiqué la segunda parte del artículo sobre cómo desarrollar aplicaciones web sobre Heroku y me di cuenta de que el primero lo publiqué hace ya poco más de un año, además esa fue la última vez que escribí en el blog. Creo que es justo que les cuente un poco lo que ha pasado en un año de ausencia por estos lados. Quienes me conocen, ya saben que emigré, las razones son varias y bien sabidas por todos, el hecho de si quería emigrar o no, pues, la verdad no , nadie quiere estar lejos de casa y de sus seres queridos, cuando mucho uno espera estar al menos en la misma ciudad o en un estado vecino, nadie quiere irse a otro continente, solo, a hablar otro idioma y a tener choques con otra cultura, a tener que adaptarse y empezar de cero, hacer nuevos amigos, o tratar, pues seguramente en su mayoría serán inmigrantes también y llegado el momento regresarán a casa o se irán a otro país. Bueno, a pesar de todo estoy bastante contento, me siento tranquilo, me encanta mi nuevo trabajo, la tecnología hoy día acorta las distancias y trato de hablar con mi familia lo más que puedo vía whatsapp y, aunque no es lo mismo, pues ayuda a mantener el contacto, trato también de llamar de vez en cuando para que no se olviden de mi y tampoco sientan que uno se olvida de ellos. En lo personal, estoy bastante ansioso por que llegue diciembre, pues voy de visita a Venezuela, veré a mi familia y me casaré con mi prometida y novia de hace años ya, bueno, boda eclesiástica pues el civil ya fue. En lo profesional, estoy súper contento también, siento que aprendo bastante en mi nuevo trabajo, estoy rodeado de programadores excelentes y gente que es realmente buena en lo que hace, sea marketing, finanzas o ingeniería de software, aún no he conocido al primer compañero de trabajo que no sea un duro en su área. En mi lado geek, estoy feliz, al fin tengo tiempo para hacer contribuciones a proyectos open source, empezando por libturpial que cloné el repo hace como año y medio y hace poco fue que empecé realmente a ojearlo y hacer las primeras contribuciones para familiarizarme con el código, estoy trabajando en un par de proyectos personales, uno que podría ser material de startup y otro simplemente para probar otros frameworks y experimentar con algoritmos y, además, no tiene precio la sensación de freelancear porque quieres y el proyecto te parece interesante y no porque estás urgido por dinero, realmente, ahora siento que trabajar es un placer más que una obligación, es raro cuando debo quedarme horas extra para terminar, sólo la última semana (en ya casi 5 meses) por una campaña para ganar un mercado emergente que era casi de vida o muerte. Esta experiencia me ha hecho abrir un poco los ojos y darme cuenta de lo mucho que me falta por aprender en muchos aspectos, pero también me ha servido para crecer en muchos otros y, sobre todo, aprender a cocinar mi propia comida, sigo vivo, lo que quiere decir que no me ha salido tan mal.","tags":"Blog","loc":"http://localhost:8000/reapareciendo-luego-de-un-ano.html","title":"Reapareciendo luego de un año"},{"text":"En el artículo anterior, hablamos de IaaS y de PaaS y de cómo se diferencian concluimos que Heroku es PaaS, además, expusimos algunas de las limitaciones que nos impone la plataforma para desplegar nuestras aplicaciones y cómo trabajar alrededor de ellas para hacer funcionar todo. Muchas veces, quizás por inocentes o inexpertos, tendemos a hacer todo en la vista (y hablo de vistas de django ), por ejemplo, necesitamos enviar algo al servidor donde hosteamos las imágenes, simplemente hacemos ejecutamos ese request en la vista, necesitamos enviar un correo electrónico de confirmación, nada, lo enviamos en la vista, necesitamos procesar una imagen para reducir la calidad y que ocupe menos espacio en el servidor donde la vamos a hostear, dale... en la vista. Bueno, exagero un poco, quizás no en la vista, si somos estrictos con nuestro código, escribiremos una función que suba la foto al servidor, otra que envíe el correo y otra que procese la imagen para reducir el tamaño y llamaremos todo desde la vista. Este enfoque sigue estando errado y, a continuación, voy a explicar por qué. Todos venimos de hacer proyectos en la universidad, algunos más difíciles que otros, en algún proyecto, seguramente nos tocó realizar llamadas a alguna API REST , o enviar algún archivo a un servidor remoto, en todos los casos, estoy seguro de que todos hicimos lo mismo, una función que se ejecuta cuando enviamos el formulario y hace todo en línea: llamadas remotas, envío de archivos, envío de correos, etc. No es incorrecto, funciona, pero ¿cuánto tardó la página siguiente en cargar?, la pregunta más adecuada sería ¿cuánto tiempo tardó la función en redirigirme a la siguiente página?, calculemos unos 3 a 5 segundos por llamada remota y unos 2 a 3 segundos, total, alrededor de 15 segundos en redirigir, a eso hay que sumarle el tiempo de carga de la página siguiente. Particularmente, mi primer trabajo fue en el mundo de los ERP, es una historia totalmente distinta, si una persona manda a generar un reporte que tarda 4 horas en ejecutarse y para ello el programa se bloquea y no le permite hacer más nada, simplemente no tiene otra opción más que esperar las 4 horas sentado en su escritorio, ir a tomarse un café, bajar a fumar un cigarrillo hasta que esté listo. Cuando programas para web, debes tomar en cuenta que debes ser gentil con el usuario y no hacerlo esperar, tu página debe responder rápido, sino, hay muchas otras páginas que hacen lo mismo y el usuario simplemente tiene que regresar a la pestaña del navegador donde está su búsqueda en google y seleccionar otro resultado. Una buena rule of thumb a la hora de ejecutar operaciones pesadas, como todas las que incluyan llamadas remotas o procesamiento de imágenes, es realizarlas de manera asíncrona, para ello debemos valernos de algo que nos permita retrasar la ejecución de una tarea. Por un lado, necesitaremos algo que nos sirga para mantener una cola de tareas pendientes por ejecutar, por otro lado necesitamos algo que vaya leyendo esas tareas y ejecutándolas, la manera más simple de hacerlo en Python es con una librería llamada python-rq y usando Redis como backend de tareas, es muy fácil de configurar y súper sencilla de usar para la mayoría de proyectos pequeños a medianos funcionará bastante bien. Para proyectos a mayor escala, quizás lo mejor sea utilizar celery con RabbitMQ como broker de mensajes. Hay muchas herramientas que podemos usar como backend de mensajes: Redis, RabbitMQ, ZeroMQ, Kafka, HornetQ... es cuestión de evaluarlas y ver cuál se ajusta más al proyecto en cuestión en el cual estamos trabajando. Como todo en django , tenemos un paquete llamado django-rq que nos ayuda a organizar el código de una mejor manera y nos hace la vida más fácil, empecemos por descargar las librerías y paquetes necesarias: sudo aptitude install redis-server pip install django-rq django Si estamos en Heroku , no es necesario instalar redis , simplemente agregar los nuevos paquetes Python al requirements.txt para que sean instalados al hacer push Para poder agregar trabajos a las colas, debemos declararlas para que django-rq las reconozca, simplemente agregamos una nueva variable en nuestro settings.py . A continuación un ejemplo de configuración para django_rq , la cola default es un ejemplo para desarrollo, la cola high es un ejemplo de configuración para Heroku si estamos usando el add on de Redis To Go . RQ_QUEUES = { 'default' : { 'HOST' : 'localhost' , 'PORT' : 6379 , 'DB' : 0 , }, 'high' : { 'HOST' : os . getenv ( 'REDISTOGO_URL' ), 'PORT' : 6379 , 'DB' : 0 , } } Ahora, las funciones sumamente pesadas pueden ser encoladas en cualquiera de las dos colas que hemos declarado en settings.py . def funcion_sumamente_pesada ( argumento ): pass Lo que haremos en nuestra vista es, en vez de llamar a la función directamente, le diremos a django_rq que agregue el trabajo en la cola que consideremos conveniente. import django_rq from helpers import funcion_sumamente_pesada def view ( request ): #... queue = django_rq . get_queue ( 'high' ) # si no indicamos una cola, retorna la cola 'default' queue . enqueue ( funcion_sumamente_pesada , argumento ) También decorar las funciones que queremos encolar, esto hace que el código se vea un poco más limpio, pero el efecto es el mismo: from django_rq import job @job ( 'high' ) def funcion_sumamente_pesada ( argumentos ): pass Y luego, en la vista: def view ( request ): #... funcion_sumamente_pesada . delay ( argumento ) Lo que rq hace es tomar el objeto función , serializarlo usando pickle y guardar ese objeto serializado en redis. Ahora que tenemos el trabajo encolado, necesitamos algo para leerlo de redis, des-serializarlo y ejecutarlo. RQ, viene con un worker que podemos ejecutar en un dyno aparte (recuerden agregar la entrada correspondiente en el Procfile de Heroku), simplemente corremos el siguiente comando en el terminal para probar localmente: python manage.py rqworker high default En la consola, podemos ver cómo los trabajos se van ejecutando, incluso, si apagamos el worker y mandamos a encolar algunos trabajos, al ejecutar de nuevo el worker de rq podemos ver como los va leyendo de redis y los ejecuta. Consideraciones con objetos persistentes en base de datos Bueno, ya sabemos que rq hace un pickle de la función y sus argumentos y envía esa información a Redis para luego ser leído por el worker, hacer el unpickle y ejecutar el trabajo. A menudo, necesitamos hacer delay de un trabajo que actúa sobre objetos que persisten en la base de datos, nuestra primera tentación es simplemente pasar los objetos como argumentos al trabajo. Ahora, veamos, analicemos qué ocurrirá. Al encolar el trabajo tanto la función como sus argumentos serán serializados, estos argumentos son objetos que pueden ser modificados. Luego de encolar, supongamos que modifico uno de los atributos del objeto y lo guardo en la base de datos, luego, al ejecutarse mi trabajo la función también modifica otro atributo y guarda el objeto en la base de datos. Lo que va a ocurrir es que, como la referencia que fue serializada al momento de encolar está desactualizada, la modificación que se hizo luego de encolar no estará reflejada en el objeto luego de ejecutar el trabajo. La solución Simplemente no pasar objetos persistentes como argumentos, es mucho mejor simplemente dar los id de base de dato al trabajo y que dentro de la función se ejecute un query para traerlos, de esta manera evitamos conflictos y dolores de cabeza como el antes descrito. Espero que esto sea de ayuda, es buena práctica trabajar con colas para trabajos pesados en cualquier proyecto web, no sólo si estamos corriendo nuestra app en Heroku.","tags":"Blog","loc":"http://localhost:8000/heroku-django-sin-morir-en-el-intento-parte-2.html","title":"Heroku + Django sin morir en el intento (Parte 2)"},{"text":"Antes, para tener tu sistema web en línea, debías contratar un servicio de Servidor Dedicado o mínimo un VPS y administrarlo, si tenías más presupuesto, comprabas un servidor y lo acondicionabas o alquilabas un rack en algún centro de datos para tenerlo colocado allí. Ahora, con el boom de Infraestructura como Servicio (IaaS) y Plataforma como Servicio (PaaS), ya no es necesario tener servidores propios y, dependiendo del servicio, es decir, si es IaaS o PaaS , tampoco debes tener conocimientos de administración de servidores. IAAS vs PAAS En general, un proveedor de IaaS te da el hardware para que tú lo configures y ensambles el ambiente en el que va a correr tu aplicación, esto es instalar todos los paquetes de software necesarios par que el proyecto corra: servidor de base de datos, servidor web, intérpretes, bibliotecas, storages adicionales y un largo end of thinking capacity (etc). La ventaja de un proveedor de este tipo es que hacen que escalar tu infraestructura de manera horizontal es realmente fácil y no tienes que construir un centro de datos para albergar tu granja de servidores ni mucho menos configurar todo lo que eso implica, un ejemplo de servicios de este tipo es el Elastic Compute Cloud de Amazon Web Services (AWS EC-2). Por otra parte, un proveedor de PaaS , hace exactamente lo mismo, pero con un nivel más de abstracción, te proveen toda la infraestructura y el ambiente para que simplemente deposites tu código allí y pongas tu aplicación a correr con configuraciones mínimas y sin ser un experto en administración y configuración de servidores, de hecho, es transparente para ti toda la nube que hay por detrás. Heroku es un proveedor de este tipo de servicio que además cumple con el 12 factor app por lo que además hace que sea súper fácil ajustar tu código para correr allí y que tome los parámetros de configuración que define la plataforma sin mucho problema. Ahora, Heroku El modelo de trabajo en Heroku se basa en add-ons, que básicamente integran tu sistema con un DBMS, un sistema de alertas en caso de fallos o de monitoreo para ver el rendimiento, detectar cuellos de botella y tomar correctivos al respecto, todo esto con unos cuantos clicks (y una tarjeta de crédito), sin configurar absolutamente nada a nivel de servidores sino todo a nivel de aplicación. Todo esto suena como un sueño hecho realidad y, en muchos casos, lo es, pero nada es perfecto y Heroku , aunque facilita muchísimas cosas a nivel de despliegue, te complica muchas otras a nivel de desarrollo, esto puede ser bueno, te obliga a optimizar y a aprender, pero a veces, el esquema de plugins y addons puede volverse insostenible, sobre todo cuando debes pagar por varios y el presupuesto es limitado, además, desde el punto de vista de aplicación, Heroku impone varias limitaciones acerca de cómo debe comportarse, el tiempo en que debe responder, el tiempo que debe durar el deploy y cuánto debe pesar. Algunas limitaciones El app debe iniciar en 60 segundos o menos: si este tiempo se excede, el deploy falla. Heroku duerme dynos cada cierto tiempo: cada cierto tiempo Heroku reinicia los dynos, esto es un proceso totalmente aleatorio, por eso se recomienda tener al menos 2, si uno es reiniciado el otro sigue aceptando requests. Cuando esto ocurre, el proceso recibe un SIGTERM , al recibir la señal, se tienen 10 segundos de gracia para terminar lo que se estaba haciendo antes de recibir un SIGKILL y reiniciar. El app no puede pesar más de 300MB: de lo contrario, el deploy falla, es recomendable usar el .slugignore para excluir archivos que sólo se usan para desarrollo y que no hacen falta en producción, lo mismo con las librerías para testing, no deberían incluirse en el requirements.txt que va a producción. El app debe responder a los requests en 30 segundos: de lo contrario se levanta un error H12 (Worker Timeout) y la respectiva pantalla de Application Error . Heroku es stateless: esto quiere decir que no guarda estado, para conservar estado del app es necesario valerse de otras herramientas, como una base de datos, memcached, y servicios de almacenamiento externos. Algunos de los golpes Con esas limitaciones se puede vivir, pero hay que darle la vuelta para no desesperarse, hay algunas cosas que capaz son obvias, pero que uno no las ve sino hasta que empieza a trabajar y se consigue con un problema, basta con volver sobre las limitaciones antes expuestas y encontraremos una respuesta o al menos una posible razón. Ahora voy a empezar a listar los problemas que he tenido en RingTu y cómo los solucioné. Recuerden que estoy trabajando con Django , por lo que todo lo he resuelto utilizando herramientas para este framework. No es bueno para servir assets Cuando digo assets, me refiero a los archivos estáticos que dan forma a la interface web: css, js, imágenes, gradientes, ¿gifs animados?, tipografías y demás cosas bonitas que hacen los diseñadores por nosotros. Por defecto, nuestro dyno sirve todos estos archivos, además de servir nuestra aplicación, aceptando peticiones de nuestros clientes, procesándolas y decidiendo qué es lo que va a enviarse de vuelta. Servir los archivos estáticos o static assets resulta en requests adicionales que van a mantener ocupado nuestro dyno y esto nos cuesta tiempo y, si ya estamos pagando, dinero. Esos requests adicionales se podrían invertir en responder y procesar solicitudes nuevas y no en entregar archivos estáticos, además, la buena práctica con django es delegar la entrega de contenido estático a un servidor web como Apache o NGinx y así evitar procesamiento adicional a nivel de views (los controladores de django ). La solución acá es, simplemente, almacenar los archivos estáticos en otro lado , puede ser incluso un VPS con Apache o NGinx instalado, pero hay varios servicios que pueden hacerlo mejor y optimizar la entrega de contenidos como Cloudfile de Rackspace y, el que opté por usar, Simple Storage Service de Amazon . Si ya tus assets no cambian mucho, lo mejor es servirlos a través de una CDN (Content Delivery Nerwork o Red de Entrega de Contenidos), como Cloudfront , también de Amazon . Ahora, ¿Cómo se resuelve esto en django? , bueno, hay varias librerías que te permiten sincronizar los archivos estáticos con un servicio de almacenamiento remoto, la que decidí usar fue django-s3-folder-storage , una pequeña librería que se vale de otra más compleja (y completa, soporta múltiples servicios) llamada django-storages para organizar tu contenido en directorios dentro de un bucket de S3 , es necesario agregar parámetros de configuración en nuestro settings.py , sería algo como esto: AWS_QUERYSTRING_AUTH = False AWS_ACCESS_KEY_ID = os . getenv ( 'AWS_ACCESS_KEY_ID' ) AWS_SECRET_ACCESS_KEY = os . getenv ( 'AWS_SECRET_ACCESS_KEY' ) AWS_STORAGE_BUCKET_NAME = os . getenv ( 'AWS_STORAGE_BUCKET_NAME' ) # Expires 20 years in the future at 8PM GMT tenyrs = date . today () + timedelta ( days = 365 * 10 ) AWS_HEADERS = { 'Expires' : tenyrs . strftime ( '%a, %d %b %Y 20:00:00 GMT' ) } STATICFILES_STORAGE = 's3_folder_storage.s3.StaticStorage' STATIC_URL = 'http:// %s .s3.amazonaws.com/static/' % AWS_STORAGE_BUCKET_NAME STATIC_S3_PATH = 'static/' El parámetro de configuración AWS_QUERYSTRING_AUTH colocado en False es para que S3 no nos genere urls firmadas para los assets sino que nos permita acceso público permanente. Si lo dejamos en True , su valor por defecto, nos va a generar un url válido por 5min y, como son archivos estáticos, esta url no se va a refrescar nunca, así que nuestra página se verá bien , con todos sus estilos y efectos sólo mientras duren las urls vigentes. Los demás son simplemente parámetros de configuración de S3, deben recordar añadir las variables de configuración en Heroku . heroku config:add AWS_ACCESS_KEY_ID = EL_KEY_ID_DE_AWS_S3 heroku config:add AWS_SECRET_ACCESS_KEY = EL_SECRET_KEY_ID_DE_AWS_S3 heroku config:add AWS_STORAGE_BUCKET_NAME = EL_NOMBRE_DEL_BUCKET Recuerden también colocar s3_folder_storage entre los INSTALLED_APPS del proyecto y activar la opción de Heroku para que reconozca las variables de configuración en tiempo de compilación, de otra manera, el deploy fallará. heroku labs:enable user-env-compile Con esto, ya deberíamos poder sincronizar los assets a S3 heroku run python manage.py collectstatic Dependiendo de qué tantos archivos estáticos tengamos, va a tardar más o menos, va a enviar todo lo que esté en nuestro STATIC_ROOT al bucket S3 que configuramos anteriormente. No puedes utilizar el sistema de archivos Había dicho al principio que Heroku es stateless , es decir, no conserva el estado de tu aplicación. Entonces ellos implementaron algo llamado Ephemeral Filesystem , es decir, un sistema de archivos efímero , que se reinicia cada vez que los dynos son reiniciados por cualquier razón, sea un deploy o sea porque heroku los reinició. ¿Qué significa esto? , pues que no puedes escribir a disco como lo harías en cualquier servidor normal , si lo haces, debes saber que cuando tu app sea reiniciada, perderás todos los archivos, tiene un poco de sentido, cuando usas más de un dyno y escribes a disco, cuando el usuario quiera recuperar lo que subió, no tenemos manera de saber cuál dyno atendió aquella solicitud y no sabremos dónde buscar, así que, de una manera u otra, lo mejor es almacenar los archivos de nuestros usuarios en un lugar seguro y de donde podamos recuperarlos luego sin problemas. Nuevamente podemos utilizar AWS-S3 para ello, con algunas configuraciones adicionales, podemos hacer que por defecto nuestros media files , para usar la terminología de django , sean almacenados en nuestro bucket . Es necesario agregar las siguientes líneas a nuestro settings.py : MEDIA_ROOT = '' DEFAULT_FILE_STORAGE = 's3_folder_storage.s3.DefaultStorage' DEFAULT_S3_PATH = 'media/' MEDIA_URL = 'http:// %s .s3.amazonaws.com/media/' % AWS_STORAGE_BUCKET_NAME Con esto, todo lo que suban nuestros usuarios irá a la carpeta media/ de nuestro bucket. Hay que tener en cuenta que todo se está subiendo al mismo bucket y la política que se definió en principio para poder almacenar los archivos estáticos da acceso público a todo el contenido por defecto, por lo que hay que tomar previsiones de alguna manera para que no todo el mundo pueda ver los archivos de nuestros usuarios de manera directa. Acá expondré la estrategia que uso: Sobre-escritura del método save(): en los modelos que tengan un ImageField o un FileField , la idea de esto es sobreescribir la política de control de acceso particular para el archivo una ves que fue subido. Para esto utilizaremos una librería llamada boto que es un wrapper en Python para el API de AWS from django.db import models from django.conf import settings from django.contrib.auth.models import User class Video ( models . Model ) user = models . ForeignKey ( User ) video = models . FileField ( upload_to = 'user_videos/' ) def save ( self , * args , ** kwargs ): from boto.s3 import connection , key super ( VoiceMessage , self ) . save ( * args , ** kwargs ) conn = connection . S3Connection ( settings . AWS_ACCESS_KEY_ID , settings . AWS_SECRET_ACCESS_KEY ) bucket = conn . get_bucket ( settings . AWS_STORAGE_BUCKET_NAME ) k = key . Key ( bucket ) k . key = ' %s%s ' % ( settings . DEFAULTS3_PATH , self . video ) k . set_acl ( 'private' ) Con esto tenemos el archivo privado en S3 , ahora, necesitamos una manera de darle acceso al usuario que es propietario del archivo. Escribiendo una vista para acceder al archivo privado: la mejor manera que conseguí para darle acceso al usuario a su archivo fue escribiendo una vista de django que revisara que el usuario que origina el request es realmente el propietario del objeto y redirigirlo a la ubicación de su archivo en S3 . Escribiremos un pequeño helper, además, para encapsular la generación del URL, como es un archivo privado, el url debe ir firmado y sólo será válido por el tiempo que nosotros indiquemos, en este caso, lo haremos por una hora. En el helper colocamos lo siguiente: from django.conf import settings def get_s3_redirect_url ( filepath , ttl = 60 ): from boto.s3.connection import S3Connection conn = S3Connection ( settings . AWS_ACCESS_KEY_ID , settings . AWS_SECRET_ACCESS_KEY , is_secure = True ) return conn . generate_url ( ttl , 'GET' , bucket = config . AWS_STORAGE_BUCKET_NAME , key = filepath , force_http = True ) y en la vista: from django.http import HttpResponse , HttpResponseRedirect from django.contrib.auth.decorators import login_required from .models import Video @login_required def get_user_video ( request , video_id ): if request . method == 'GET' : from .helpers import get_s3_redirect_url user = request . user video = Video . objects . get ( id = video_id ) if user == video . user : filepath = ' %s%s ' % ( settinga . DEFAULT_S3_PATH , video . video ) url = get_s3_redirect_url ( filepath , ttl = 3600 ) return HttpResponseRedirect ( url ) return HttpResponse ( status = 403 ) Con esto generamos una url firmada y válida por 3600 segundos (una hora) si el usuario que origina la solicitud es el propietario del objeto que contiene el archivo (video) que se desea obtener, caso contrario retornamos 403 ya que la persona no tiene permisos para ver ese contenido.","tags":"Blog","loc":"http://localhost:8000/heroku-django-sin-morir-en-el-intento-parte-1.html","title":"Heroku + Django sin morir en el intento (Parte 1)"},{"text":"Primero que nada, me gustaría pedir disculpas (o permiso xD) si cometo algún error ortográfico en este artículo, se me olvidó pasar el aspell , el hecho es que, para ponerlos un poco en contexto, vengo de un rato un poco etílico. Bueno, para empezar, quienes me conocen y están pendientes de mi desarrollo como profesional, saben que ahora estoy en un puesto de líder de proyecto en un startup de telefonía en la nube. Además, quien me conozca sabe que los temas gerenciales siempre me han dado ladilla, como decimos acá en Venezuela. El tema es que siempre, desde que tengo personal a mi cargo, me he esforzado en hacerles entender que no trabajan para mi, sino conmigo , es decir, no soy su jefe, sino alguien que los debe ayudar a cumplir con sus obligaciones a tiempo y a quien le pueden preguntar en caso de alguna duda, en fin, alguien quien puede enseñarles, una especia de mentor o profesor o como quieran verlo. Para mi, la definición de un líder, debe ser alguien a quien respetas profesional y personalmente, alguien de quien consideras que puedes aprender y a quien no le molesta aprender de ti. Eso, para mi, es un líder. Luego, está otro tema, uno que se remonta a cuando estaba estudiando en la UCAB y discutía temas diversos con mi pana Gerardo Barcia , gran fanático de los temas que tienen que ver con Gerencia de Proyectos. Uno de los temas que siempre causó controversia fue el del papel del Ingeniero en un proyecto: gerente o ejecutor. Siempre abogué por el papel del Ingeniero como ejecutor de un proyecto, es decir si estudias supuestamente 5 años en una Universidad y te enseñan a programar y diversos conceptos de sistemas operativos y distribuidos, es para que los apliques en los sistemas que vas a implementar o en los proyectos que vayas a desarrollar, además, en el mundo de la informática se aplica mucho lo que yo llamo la cultura hacker , que es el hecho de respetar a alguien que sabe más que tú y que de verdad puedes comprobar que es así, es decir, alguien quien sabe de qué habla y de quien puedes aprender o, quizás no, quizás es simplemente alguien que está a tu mismo nivel pero que tiene las mismas ganas que tu de aprender y tiene la misma curiosidad científica por descubrir cosas y, quizás reinventar la rueda sólo para ver cómo funciona. Por otra parte, mi pana Gerardo siempre pensó que el rol del Ingeniero en un proyecto es el del Gerente. Decirle a los técnicos qué hacer y cómo hacerlo, estimar el tiempo que deberían tardarse, supervisarlos, ver que lo que hacen cumple y aceptarlo o rechazarlo y dar directrices de cómo y por dónde debe encaminarse el proyecto, es decir, el rol del gerente de proyectos o, quizás, consultor. ¿Quién tenía la razón? Pues creo que ambos, un Ingeniero en un proyecto debe cumplir ambos roles, sin embargo para poder liderar un equipo, siempre he dicho que debes tener experiencia suficiente como para poder decirle a alguien lo que debe hacer con total confianza, es decir, poder tener la habilidad, el conocimiento y la experiencia para conocer y prever imprevistos dentro del proceso y advertir a la persona acerca de con qué se podría encontrar . El punto es que a mi pana Gerardo, le ha tocado programar, y programar duro , al igual que a mi. Desarrollar sistemas en los que alguien nos dice qué hacer y cuáles son las necesidades y debemos escribir software que las cubra o que las automatice de la mejor manera posible y sin poder tomar muchas decisiones acerca del cómo implementar las cosas. Ahora a mi, aunque considero, quizás , no tener la experiencia necesaria, me toca liderar un equipo de programadores. Mi equipo me respeta profesionalmente y nos llevamos muy bien personalmente, de hecho, me parece que mi equipo está conformado por las mejores personas que alguien podría querer, todos le ponen muchísimas ganas e incluso han resuelto problemas en los que no tenía ni idea ni tiempo de revisar a fondo cómo solventarlos, obviamente, todos estamos aprendiendo, ellos porque aún están estudiando en la Universidad y el trabajo les sirve de experiencia y yo porque es mi primer trabajo al frente de un equipo. Como persona a cargo de un equipo, he metido la pata y mucho , desde estimando tareas que toman más de lo que pensé, porque en realidad no eran una tarea sino muchas que eran necesarias para cumplir un objetivo, causando que quizás la persona se frustrara porque se tardó mucho haciéndola, hasta viendo dependencias entre tareas que eran obvias y asignándolas de manera errada con prioridades distintas y retrasando algunas entregas, sí, lo se, terrible . Pero el colmo, y lo que me hace escribir este artículo es que ocurrió algo en una reunión que me hizo cuestionarme a mi mismo como líder de proyecto y como Ingeniero a cargo de un proyecto: Hace más o menos un mes y medio, se discutió el flujo de un proceso y cómo debía ser implementado yo dije que debía ser de X forma y el CEO dijo que debía ser de Y forma, al final, se hizo de la forma Y , pero el tiempo demostró que la forma X era la correcta, entonces, tiempo y esfuerzo quizás perdidos. No me duele mi tiempo y mi esfuerzo, sino el de mi equipo porque fue mi culpa que las cosas no se hicieran bien desde el principio, no se, capaz me faltó liderazgo o capacidad de algo en el momento de la primera discusión, no lo se, el punto es que, reflexionando, capaz producto de las bebidas espirituosas de hoy, he empezado a pensar que quizás no estoy listo para asumir responsabilidades de este calibre aún, quizás sea algo de actitud o quizás sea algo de aptitud. Ustedes, ¿qué piensan?.","tags":"Blog","loc":"http://localhost:8000/ahora-soy-lead-developer-y-no-tengo-mucha-idea-anecdotas-y-reflexion.html","title":"Ahora soy lead developer y no tengo mucha idea: anécdotas y reflexión"},{"text":"Como todos saben, y algunos me chalequean por eso, en la primera mitad de 2013 cambié de trabajo dos veces, estaba algo aburrido en Metamax y decidí aceptar una oportunidad en 4geeks, junto con una serie de proyectos para una empresa en el extranjero que pintaban bastante bien, una vez que terminé los proyectos de la otra empresa, terminé enamorándome del proyecto que desarrollaba desde 4geeks y uniéndome al startup a tiempo completo. La historia en 4geeks es muy graciosa, un tal Saúl Lustgarten llevaba tiempo escribiendo en todas las listas de correo donde estoy pidiendo un desarrollador Python, incluso me contactó personalmente varias veces vía email y a través de LinkedIn para desarrollar su startup , una central telefónica en la nube llamada RingTu , el tema era que no me resultaba atractivo, así que en ese momento acepté la oferta de 4geeks. El primer día en 4geeks, me informan acerca del proyecto que iba a desarrollar, \"vas a hacer uno de los startups de Wayra, es una central telefónica en la nube\" y yo \"¿RingTu?\", \"sí ese mismo\", vaya, al parecer hasta se las arregló para que desde 4geeks desarrollara su startup, jajajajajajaja. Básicamente lo que debía hacer era unos wrappers para unos servicios web que ellos consumen, ese era sólo el inicio del proyecto, pensé que sería divertido, ya había hecho wrappers para otros servicios web, y en Python es muy fácil hacer clientes para servicios web, sin importar si hablan JSON o XML o algún protocolo propio, la cosa se puso esotérica cuando vi que todos los URL de los servicios con los que iba a trabajar terminaban en .wsdl. ¿SOAP?, con el boom de REST ¿quién usa SOAP?, en fin, ¿qué tan difícil puede ser?, en Java es realmente fácil escribir clientes y servicios web usando SOAP y en Python no debe ser la excepción, hay librerías para todo, dejé de hacerme preguntas acerca del sentido de la vida, el universo y todo lo demás y puse manos a la obra a investigar alguna buena librería que me facilitara el trabajo. Luego de unos minutos leyendo en StackOverflow , vi que al parecer suds era la mejor opción, no se veía tan abandonada y, comparada a las demás opciones, tenía una documentación decente. Lo primero es, obviamente, instalarla: pip install suds Recuerden que siempre es buena práctica trabajar con virtualenvs y, además, es muy buena opción el hecho de utilizar virtualenvwrapper para gestionarlos. Una vez que tenemos suds ya instalado, es sólo cuestión de empezar a utilizarla, para hacer clientes, que es de lo que hablaré en este post, sólo nos interesa la clase definida en suds.client.Client . Si repasamos un poco de teoría acerca de los servicios web sobre el protocolo SOAP, veremos que se convirtió en la capa subyacente para servicios complejos basados en WSDL, que es una manera de especificar los objetos y métodos que expone un servicio web y a los que el cliente puede tener acceso. WSDL es un acrónimo que significa Web Service Description Language . Toda la definición de servicios web SOAP se hace en un documento WSDL, que no es mas que un XML donde se define todo lo que este servicio expone para ser consumido por sus clientes. De igual manera, el pase de mensajes (soap messages) entre el cliente y el servidor, se hace en formato XML. A continuación un ejemplo de documento WSDL: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <description xmlns= \"http://www.w3.org/ns/wsdl\" xmlns:tns= \"http://www.tmsws.com/wsdl20sample\" xmlns:whttp= \"http://schemas.xmlsoap.org/wsdl/http/\" xmlns:wsoap= \"http://schemas.xmlsoap.org/wsdl/soap/\" targetNamespace= \"http://www.tmsws.com/wsdl20sample\" > <!-- Tipos Abstractos --> <types> <xs:schema xmlns:xs= \"http://www.w3.org/2001/XMLSchema\" xmlns= \"http://www.tmsws.com/wsdl20sample\" targetNamespace= \"http://www.example.com/wsdl20sample\" > <xs:element name= \"request\" > ... </xs:element> <xs:element name= \"response\" > ... </xs:element> </xs:schema> </types> <!-- Interfaces abstractas --> <interface name= \"Interface1\" > <fault name= \"Error1\" element= \"tns:response\" /> <operation name= \"Opp1\" pattern= \"http://www.w3.org/ns/wsdl/in-out\" > <input messageLabel= \"In\" element= \"tns:request\" /> <output messageLabel= \"Out\" element= \"tns:response\" /> </operation> </interface> <!-- Interface concreta sobre HTTP --> <binding name= \"HttpBinding\" interface= \"tns:Interface1\" type= \"http://www.w3.org/ns/wsdl/http\" > <operation ref= \"tns:Get\" whttp:method= \"GET\" /> </binding> <!-- Interface concreta sobre SOAP --> <binding name= \"SoapBinding\" interface= \"tns:Interface1\" type= \"http://www.w3.org/ns/wsdl/soap\" wsoap:protocol= \"http://www.w3.org/2003/05/soap/bindings/HTTP/\" wsoap:mepDefault= \"http://www.w3.org/2003/05/soap/mep/request-response\" > <operation ref= \"tns:Ge99t\" /> </binding> <!-- Endpoints que ofrecen el servicio --> <service name= \"Service1\" interface= \"tns:Interface1\" > <endpoint name= \"HttpEndpoint\" binding= \"tns:HttpBinding\" address= \"http://www.example.com/rest/\" /> <endpoint name= \"SoapEndpoint\" binding= \"tns:SoapBinding\" address= \"http://www.example.com/soap/\" /> </service> </description> La sección types describe los tipos de dato a los que da soporte el servicio web que se está describiendo. Las interfaces , definen un servicio como tal, es decir, las operaciones que pueden ser realizadas y los mensajes que son soportados para realizar cada operación. Los bindings especifican la interface y cómo deben ser pasados los mensajes e incluso el protocolo que debe ser utilizado para el transporte. Finalmente, los endpoints , definen los puntos de conexión con el servicio web. Por otra parte, un mensaje SOAP debería verse de la siguiente manera: POST /InStock HTTP/1.1 Host: www.example.org Content-Type: application/soap+xml; charset=utf-8 Content-Length: 299 SOAPAction: \"http://www.w3.org/2003/05/soap-envelope\" <?xml version=\"1.0\"?> <soap:Envelope xmlns:soap= \"http://www.w3.org/2003/05/soap-envelope\" > <soap:Header> </soap:Header> <soap:Body> <m:GetStockPrice xmlns:m= \"http://www.example.org/stock\" > <m:StockName> IBM </m:StockName> </m:GetStockPrice> </soap:Body> </soap:Envelope> En un mensaje, el envelope es lo que identifica el XML como un mensaje SOAP, el header contiene información de encabezado, como por ejemplo, llaves de autenticación o tokens de acceso. Finalmente, el body o cuerpo del mensaje, es el que contiene el mensaje como tal que se está enviando, ya sea en solicitud o respuesta del servicio. En este caso, se está invocando una función remota GetStockPrice definida en un namespace m del wsdl que describe este servicio. A esta función remota se le está enviando un argumento llamado StockName y el valor de este argumento es IBM , el servicio debería retornar el precio del producto cuyo StockName sea IBM Para que pueda darse el intercambio de información entre un cliente y un servidor SOAP, ambos deben tener conocimiento de lo que está definido en el descriptor del servicio, es decir, ambos deben tener acceso al WSDL, es por ello que lo usual es que el proveedor del servicio web exponga el documento en un URL accesible. Para este tutorial, usaremos este servicio web: http://www.webservicex.com/globalweather.asmx?WSDL , que es un servicio web de clima. Acá: http://www.service-repository.com/operation/operations?id=4 podemos observar las operaciones y sus parámetros en un formato amigable al humano :-). Lo primero es, en nuestro caso, construir una instancia de suds.client.Client que tenga conocimiento del WSDL que describe el servicio que vamos a usar: from suds.client import Client client = Client ( url = 'http://www.webservicex.com/globalweather.asmx?WSDL' ) Listo, ya tenemos un cliente SOAP listo para consumir el servicio desde Python. Lo que nos queda es revisar la documentación del servicio o, si no la hay, el WSDL para ver cuáles objetos pueden ser pasados como mensajes, construir el request e invocar el método remoto, para ello nos interesan: Client.factory y Client.service. Por ejemplo, obtengamos el tiempo para Caracas - Venezuela: request = client . factory . create ( 'tns:GetWeather' ) request . CityName = 'Caracas' request . CountryName = 'Venezuela' response = client . service . GetWeather ( request ) Listo, así de fácil, explorando la documentación o el WSDL veremos que hay un objeto llamado GetWeather definido en el namespace tns , este objeto tiene dos campos string : CityName y CountryName , también, si vemos la definición de la respuesta en el WSDL, podremos observar que es un texto plano (es decir, viene un objeto primitivo string como SOAPResponse). Vamos a ver cómo maneja suds ambos casos: type ( request ) instance print request ( GetWeather ){ CityName = \"Caracas\" CountryName = \"Venezuela\" } type ( response ) suds . sax . text . Text print response < ? xml version = \"1.0\" encoding = \"utf-16\" ? > < CurrentWeather > < Location > Caracas / Maiquetia Aerop . Intl . Simon Bolivar , Venezuela ( SVMI ) 10 - 36 N 066 - 59 W 48 M </ Location > < Time > Aug 18 , 2013 - 09 : 00 PM EDT / 2013.08 . 19 0100 UTC </ Time > < Wind > Calm : 0 </ Wind > < Visibility > greater than 7 mile ( s ): 0 </ Visibility > < SkyConditions > partly cloudy </ SkyConditions > < Temperature > 82 F ( 28 C ) </ Temperature > < DewPoint > 80 F ( 27 C ) </ DewPoint > < RelativeHumidity > 94 %</ RelativeHumidity > < Pressure > 29.88 in . Hg ( 1012 hPa ) </ Pressure > < Status > Success </ Status > </ CurrentWeather > Como veremos, suds nos crea un objeto Python a partir de la definición que obtuvo del WSDL en el caso del request que se construye a partir de la fábrica del cliente usando el objeto remoto tns:GetWeather como plantilla. En el caso del response, que está declarada como string, nos envía un objeto suds.sax.text.Text, que puede ser tratado como un objeto string o unicode Python normalmente. Suds, no sólo nos hace más fácil la interacción con servicios SOAP, sino que también nos abstrae del hecho de que tratamos con objetos remotos, convirtiendo todo a objetos Python por nosotros. En algunos casos es necesario autenticarse contra un servicio web para poder utilizar sus métodos remotos, usualmente eso se hace a través de un método público de autenticación que revisa los permisos y retorna un token de acceso encapsulado en un objeto, este objeto debe colocarse en el header de los requests que van dirigidos a los métodos privados. Debido a que no conseguí ningún servicio web que me permitiera hacer un ejemplo de esto, simplemente haré un ejemplo dummy de cómo sería en código: from suds.client import Client auth_client = Client ( 'http://www.servicio.com/authservice.wsdl' ) request = auth_client . factory . create ( 'ns:AuthObjectRequest' ) request . login = 'MiUsuarioParaElServicio' request . password = 'MiClaveSuperSegura' auth_object = auth_client . service . GetAccessToken ( request ) client = Client ( 'https://www.servicio.com/otras_cosas.wsdl' ) client . set_options ( soapheaders = auth_object ) Algunas veces, basta sólo con un objeto que contenga el usuario y el password para el servicio (como el request de este ejemplo) en el soapheaders del client y listo. La única desventaja que vi al trabajar con suds es que no viene con soporte nativo para attachments, sin embargo, es relativamente fácil añadir esta funcionalidad en este gist podemos ver el código para hacerlo. La manera de utilizarlo es la siguiente: from suds.client import Client from soap_attachments import with_soap_attachment client = Client ( url = 'http://www.servicio.com/wsdl/servicio.wsdl' ) f = open ( '/home/user/music/panama.mp3' , 'rb' ) data = f . read () mime_type = 'audio/mpeg' bin_param = ( data , mime_type ) request = client . factory . create ( 'ns0:RequestConAttachment' ) request . usuario = 'iferminm' request . nombre_audio = f . name response = with_soap_attachment ( client . subir_pista , bin_param , endpoint , request ) Básicamente lo que se hace es leer los bytes que conforman el archivo y colocarlos en el cuerpo del mensaje SOAP (eso hace with_soap_attachment), lo único que hay que saber acá es que el endpoint (que se ve como parámetro en la llamada a with_soap_attachment) es el punto de conexión al servicio web especificado en el WSDL. De esta manera, colocamos un archivo adjunto al mensaje SOAP para que sea subido al servidor vía SOAP. Para más información recomiendo revisar la documentación de la librería acá , sin embargo, para hacer clientes para servicios SOAP básicos, con este tutorial debería ser suficiente.","tags":"Blog","loc":"http://localhost:8000/clientes-soap-en-python.html","title":"Clientes SOAP en Python"},{"text":"Bueno, esto ya es tema viejo, pero no había tenido tiempo de escribir al respecto. Desde que organicé el PyConVE2012 había tenido la idea de probar cómo me iba dando alguna ponencia o algún tutorial, ya en la Universidad era preparador y miembro del Sun Team University , una de las iniciativas académicas de Sun Microsystems que Oracle mató luego de la compra. En el Sun Team daba charlas y también como preparador hablaba en público, pero es muy diferente el ámbito académico de hablar en una conferencia ante otros especialistas quizás con más experiencia o mejor preparados que yo. Desafortunadamente, en el PyCon sabía lo que me esperaba pues éramos pocos organizando e iba a tener que estar corriendo de un lado a otro de la sede (la UCAB) resolviendo problemas de última hora, así que decidí no postular ninguna charla. Este año, mi buen amigo Jin Kadaba estaba organizando el FLISOL 2013 , y me invitó a dar una charla. Como es una conferencia de Software Libre y se acepta cualquier tema relacionado, decidí iniciarme con una charla no-técnica, hablé sobre Comunidades de Software Libre y mi experiencia en PyVE y organizando el PyCon . Al parecer a la gente le gustó. Luego de un par de meses, Mimia Lo, una buena amiga de la Universidad, estaba de nuevo organizando las JOINCIC y me invitó a proponer alguna charla, confieso que tengo un poco de miedo a hablar en público, así que decidí no pararme en la tarima del Aula Magna, sino más bien dar un taller práctico, propuse un par de mesas de trabajo a ver si aprobaban al menos una, para mi sorpresa me pidieron dar las dos :-) y estaba muy contento. Tanto el FLISOL como las JOINCIC fueron muy gratas experiencias para mi, tuve la oportunidad de compartir y conocer a otras personas entusiastas del Software Libre en el FLISOL y de compartir con viejos amigos de la Universidad en las JOINCIC, sin mencionar que pude dar a conocer algo de Python en ambos eventos. Acá les dejo los slides de las tres presentaciones, espero sean de su agrado: FLISOL Comunidad: orden dentro del caos, caos dentro del orden http://www.slideshare.net/iferminm/comunidad-caos-dentro-del-orden-orden-dentro-del-caos JOINCIC Testing: la etapa olvidada http://www.slideshare.net/iferminm/testing-etapa-olvidada Iniciación a las artes marciales con Python http://www.slideshare.net/iferminm/iniciacin-a-las-artes-marciales-con-python","tags":"Blog","loc":"http://localhost:8000/y-al-fin-me-estrene-como-ponente.html","title":"Y al fin!, me estrené como ponente"},{"text":"Quienes me conocen saben que llevo un buen rato alejado del oscuro mundo de la política o, más bien, politiquería venezolana. Las razones son muy diversas, pero luego de ver el video que coloco a continuación, simplemente no pude sino estallar en furia por motivos que expondré a lo largo de este artículo: Les ruego que ven al video anterior antes de continuar la lectura Ahora bien, antes de continuar, quiero explicar un poco mi posición en cuando a la política. Todo aquel que me pregunta recibirá la misma respuesta: me criaron con muchos valores como para ser chavista, pero tengo demasiada autoestima como para llamarme de oposición , declaraciones como esta, no hacen más que reafirmar mi postura aunque, todos los que me conocen, saben que mis votos siempre van a alguno de los dos lados. Para mi, el problema de Venezuela no es de forma, sino de fondo. ¿Qué quiero decir con esto?, no importa la forma que tenga el gobierno, si el pueblo que está de fondo no cambia, no iremos a ningún lado ni progresaremos jamás. Pero este es otra historia, ahora sí, a lo que vine, decidí publicar esto por acá pues, a pesar de que busqué algún correo electrónico por el cual comunicarme con la persona en cuestión, no hay ninguno publicado, a pesar de que hay una ficha de contacto en el portal de la Asamblea Nacional. Señor Leomagno Flores, Diputado a la Asamblea Nacional y, además, Presidente de la Comisión Permanente de Ciencia, Tecnología e Innovación , permítame decirle que es usted un tremendo idiota, un inepto y que luego de esa intervención debería renunciar por lo menos a la comisión que preside porque dejó en evidencia el poco conocimiento que tiene en el área, por no decir inexistente. Esto lo digo con todo el respeto del mundo hacia su posición de Diputado ante la Asamblea Nacional de la República Bolivariana de Venezuela, pero no hacia su ignorancia como persona que, además, para tener el cargo que tiene debería al menos haber leído un par de libros referentes a tecnología y sus modelos de negocio y distribución, por no decir cosas más técnicas como Ingeniería del Software, Protocolos de Comunicación y Sistemas Operativos que no tiene, ciertamente, por qué conocer a profundidad. Ahora bien, mis palabras iniciales se que fueron algo fuertes, pero no me cabe en la cabeza cómo alguien puede llamar dictadura al Software Libre , y mucho menos, cómo puede decir que \"uno pensaría que software libre pudiera ser mucho software que la gente pudiera a su libre albedrío tomar uno y no...\". Pero bueno vamos por partes. El software libre es una dictadura Señor Diputado, ¿sabía usted que existen licencias de software que prohíben al licenciado hacer públicos los errores de programación que encuentre en el producto?, es decir, te vendo una licencia, cara además, para que uses algo que está mal hecho (porque esta programado por humanos y los humanos nos equivocamos), pero además, si le dices a alguien que tiene un error (que es de las cosas más normales en el mundo de la computación), puedo demandarte . Si quisiera tener el derecho a reportar bugs (o errores de programación), debo pagar un contrato de soporte y reportarlo directamente a ellos y rogarle a Dios que lo reparen para la versión que uso, sino, debo comprar la actualización. Señor Diputado, ¿sabía usted que hay licencias de software que prohíben que el licenciado ejerza alguna actividad de negocio en la que pudiera competir con la compañía dueña del producto?, es decir, si yo compro un programa de la empresa A, y el programa sirve para hacer pastelitos y la empresa A, además de fabricar el programa, también hace pastelitos , esa empresa podría demandarme por competir por ellos y usar su producto. Señor Diputado, ¿sabía usted que ninguna empresa que le venda un programa bajo el esquema privativo va a permitirle a usted o a algún especialista de su empresa/estado que lea, estudie o audite el código fuente del software por el cual pagó?, eso es el equivalente a que usted compre un carro y en el contrato que usted firma con el concesionario diga que es ilegal que usted abra el capot y observe el motor, aún cuando el automóvil deje de funcionar en plena autopista y usted quiera intentar repararlo para seguir su camino, podrían demandarlo por ello. Sí, todo esto ocurre, han cerrado portales web y demandado a sus dueños por publicar errores de seguridad (graves) en Java , por ejemplo. Hay personas a las que las han hecho pagar $5 para reportar un bug en el X sistema operativo que no voy a mencionar, hay noticias en todo internet de casos de errores graves de seguridad que las compañías han dicho \"está solucionado en la próxima versión\" y todo esto ocurre en el mundo del Software Privativo . Si todo lo anterior no le suena a dictadura , entonces puede dejar de leer aquí, sino, siga: Entonces, ¿qué es el Software Libre? Gratis no es libre, es una limosna - Ernesto Hernández-Nóvich El Software Libre es aquel que permite tres libertades fundamentales que enumeraré a continuación: Libertad 0: libertad de uso, es decir, debo poder utilizar el software para lo que yo quiera, sin importar si voy a competir o no. Puedo utilizarlo en mi casa, en mi empresa, vender una instalación o soporte sobre ese software, no importa, simplemente la licencia libre me permite hacer lo que desee con el software. Libertad 1: libertad de estudiar cómo funciona por dentro el software, es decir, revisar el código fuente y, además, adaptarlo a mis necesidades particulares. De nada me sirve tener libertad de uso si al final el programa como viene out of the box no me sirve, por ello, debo poder modificarlo a mi gusto o según lo que me haga falta. Libertad 2: libertad de hacer copias sin ningún problema , es decir, instalarlo en cuantos equipos quiera, sin necesidad de pagar licencias extra por hacerlo, esto, además, me permite distribuir copias del software sin incurrir en delito alguno . Si algo es bueno, queremos que más gente lo utilice. Libertad 3: libertad para modificar/mejorar el software y distribuir las mejoras a la comunidad, si me beneficio de un desarrollo de la comunidad, estoy en la obligación moral de retribuirle con algo de mi trabajo y, de esta manera, ayudo a que el software evolucione y mejore cada día. Respecto a esta última libertad, ¿sabía usted, señor Diputado, que Apple basó el núcleo de su MacOS X en FreeBSD , un Sistema Operativo libre , y no han liberado ni una sola línea de lo que hicieron con Darwin (el núcleo de MacOS X)?. ¿Le parece esto justo?, ¿le parecen estas libertades los preceptos de una dictadura tecnológica ?. Cuando hablo de Software Libre y las 4 libertades, me gusta muchísimo incluir una quinta libertad, es quizás la más importante de todas: la Libertad de Elegir , nadie me obliga a usar cierta herramienta, puedo probarlas todas y quedarme con la que más me guste. Eso me lleva a mi segundo punto. Hay poco Software Libre Acá no puedo más que remitirme a la realidad. Si alguna vez ha visitado una página web, ha usado Software Libre indirectamente. Muchas de las páginas son servidas gracias a Apache o NGinx, dos de los servidores web más populares de hoy. Una gran cantidad de las páginas dinámicas están programadas en PHP, Python o Ruby, algunas en Perl, todos lenguajes libres . Es también bastante probable que todo esto corra sobre un servidor con sistema operativo Linux, también libre . Sin ir muy lejos, este blog llega a ustedes gracias a Pelican y Python, una herramienta y un lenguaje, ambos Software Libre . Es poco lo que tengo que agregar acá, simplemente invitarles a colocar Linux distro list o alternativas de software libre en Google y evaluar ustedes mismos si hay poco Software Libre . Ahora, mi reflexión La política es uno de los campos más sucios que existen entre todas las actividades del ser humano, por ello, todo lo que se politiza generará discordia. Para mi, el gobierno cometió un error al politizar acerca del Software Libre . La dinámica de la Asamblea Nacional Venezolana puede resumirse en: Si eres de mi partido, aplaudo todo lo que digas, sin importar que sea la idiotez más grande que haya escuchado, debo apoyarte. Pero si eres del contrario, debo llevarte la contraria y decir que lo que dices está mal, sin importar que sea la mejor idea de los últimos 20 años . Así se maneja el debate político en Venezuela y así se manejará cualquier cosa que se politice, las leyes de infogobierno deberían ser discutidas con Ingenieros, Programadores y Especialistas en tecnología o, al menos, deberían ser consultados pues como hemos visto en la discusión intervienen entes que no saben de informática y, por lo que han demostrado en los últimos años, mucho menos saben gobernar. Los dejo ahora con una charla que dio Ernesto Hernández-Nóvich acerca del Estado y el Software Libre , La libertad no admite grises","tags":"Blog","loc":"http://localhost:8000/carta-abierta-al-diputado-leomagno-flores.html","title":"Carta abierta al DIPUTADO Leomagno Flores"},{"text":"En algunas carreras me llama muchísimo la atención el hecho de que todos tus amigos, familiares, vecinos e incluso gente que acaba de conocerte piensan que estudiaste para proveerles servicio gratis y que, además, debes saberlo todo de todo o no sirves. Si eres médico, nunca falta salga con cosas como sabes que tengo un dolorcito aquí en el brazo desde hace días, ¿qué será que puedo tomar? , o el típico ¿qué le puedo dar al chamo para que se le pase el malestar? , si eres fotógrafo, nunca falta el que te diga chamo, tomame una foto ahí pal' féijbu . Si eres computista, la cosa es realmente difícil. Sí, soy Ingeniero en Informática , al igual que muchos otros colegas por ahí, pero eso no me convierte automáticamente en tu soporte técnico personal para repararte el Güindows cada ves que le entra un virus, configurarte la impresora cada ves que compras una nueva o colocarle clave a tu wifi . Claro que me gusta hablar de tecnología, pero no conozco todos los modelos de smartphone ni mucho menos se cómo arreglarte el blackberry . Pero, sin lugar a dudas, los peores son los que llegan diciendo mira, necesito hackear esta cuenta de correo, ¿será que me puedes hacer el favor? . Bueno, yo necesito dinero, ¿robarías un banco por mi?, creo que no. Estos últimos no aceptan un educado no se por respuesta, sino que luego de eso te dicen ay, pero tú deberías saber, ¿no les enseñan en la universidad? . Querido amigo, familiar, vecino, en fin, usuarios todos, no , no me lo enseñan en la universidad , vi muchísimas materias entre Cálculos, Físicas, algunas Matemáticas Discretas, muchos Algoritmos y materias de Programación, Sistemas Operativos y Redes de Computadoras, pero ninguna de Hackear Hotmail I, II o II ni ninguna electiva de Configuraciones Avanzadas de Impresoras , mucho menos Detección y reparación de Virus en Windows , y ni hablar de Gestión avanzada de equipos BlackBerry . Claro, me agrada ayudar a la gente, no tengo problema en ayudarte a solventar tus necesidades tecnológicas de vez en cuando, pero no abuses . Con cariño Israel.","tags":"Blog","loc":"http://localhost:8000/querido-amigo-usuario.html","title":"Querido amigo usuario"},{"text":"Bueno, ya se nos fue otro año, un año en el que supuestamente se acababa el mundo pero no fue así (lo siento mayas y adventistas). Lo que realmente querían decir los mayas era que se completaba un ciclo, una era del universo, una etapa de la raza humana, en ese sentido, quiero hacer un resumen personal de las cosas buenas que me dejó este 2012 y una propuesta personal, pero pública de lo que quiero hacer en 2013. Mi 2012 Este año empezó con varios altibajos en materia personal, luego de que a finales de 2011 me comporté como un patán y ciertamente rompí varias veces el corazón de una persona especial, me di cuenta de todo lo que hice mal y de que no todo era malo, caí en cuenta de lo bien que me sentía con esa persona y decidí volver, y ella me aceptó de vuelta. Digo que empecé con varios altibajos pues todo enero y febrero fue un período largo de adaptación el uno al otro, asimilando cambios de ella y míos que se dieron en un período de ocho meses que estuvimos separados. Muchas cosas mejoraron de parte y parte y creo que fue el inicio de una nueva etapa para ambos, estábamos redescubriendo cómo convivir, entre discusiones y peleas ocasionales y períodos en los que todo era lindo y color de rosas. A inicios de año también defendí mi tesis de grado, obteniendo mención honorífica, con esto iniciaba mi año con balance positivo en el área académica/profesional. Tuve que tomar un par de decisiones en el área profesional, la más notable fue no volver a Vauxoo por motivos de metas personales. Luego de varias entrevistas, terminé trabajando junto a un equipo de excelentes programadores en Zava, terminé asociándome con ellos e involucrándolos un poco en uno de mis proyectos (PyConVE). Creo que el evento que marcó mi 2012 fueron las elecciones presidenciales. La victoria de Hugo Chávez por n-ésima vez me hizo ver que, quizás, al pueblo le gusta y no hay nada que se pueda hacer al respecto, fue cuando tomé la decisión de dejar todo y empezar a buscar mi camino, dejé mi trabajo en Zava por una oferta bastante buena en Metamax, buscando poder ahorrar un poco más. Cosas que (siento que) logré este año: Mejorar mis habilidades de programación. Obtener una buena calificación en mi tesis de grado. Conseguir un buen trabajo (de hecho conseguí dos). Mejorar mi relación con mi novia (la clave acá fue el entendimiento mútuo). PyConVE2012: algo de lo que me siento orgulloso (gracias a PyVE, a Giselle por su apoyo y a todos quienes asistieron) Mejorar mi relación de familia (ya hablo más :-) ). Enfocarme en lo que realmente me importa (tuve que dejar mi banda, fue difícil, pero no me arrepiento). Recuperar contacto con viejos amigos: Luis y Henoc acá, también mi pana Juan Hernández. Mejorar un poco mi capacidad de concentración. En el camino conocí gente muy valiosa: Carlos Zager, Mauricio Reyes Keny Vivas y Horacio Gouveia en Zava, Jin Kadaba y Sebastián Magrí en PyVE (gracias al PyCon), Érico Andrei y Facundo Batista (ponentes del PyCon), Moisés Fernández, Camila Pacheco, José P. Bruno y Manuel Ferrer en mi ex-banda Teorema y, hacia el final del año en mi nuevo trabajo, a Alexander Cabezas, Clareana Colina y Oscar Mata en Metamax. Cosas que (espero) lograré en 2013: Acá puedo dividirlo en dos campos: En lo personal Me gustaría continuar profundizando en mi relación familiar y terminar de formalizar mi relación con mi novia, algo de lo que venimos hablando desde hace ya algún tiempo. Me gustaría mejorar también ciertos aspectos de mi personalidad y autoestima, creo que debo valorar más lo que hago en todo sentido, también, quiero seguir enfocándome. Parecieran pocas metas personales pero se que son cosas que me llevarán algún tiempo. En lo profesional Lograr convertirme en pieza clave del equipo del que formo parte actualmente y continuar mejorando mis habilidades como desarrollador e ingeniero. Quizás aprender un nuevo lenguaje, podría ser Ruby o capaz continúe con Perl. Finalmente, terminar de lanzar alguno de mis proyectos personales pero, como siempre, debo enfocarme en uno a la vez.","tags":"Blog","loc":"http://localhost:8000/resumen-del-2012-y-propuestas-para-el-2013.html","title":"Resumen del 2012 (y propuestas para el 2013)"},{"text":"Bueno, ya ha pasado una semana y alguito desde que terminó la primera Conferencia del Lenguaje Python de Venezuela (PyConVE), he tenido algo de tiempo para reflexionar y pensar acerca de varias cosas que me ocurrieron antes del evento, es decir, mientras se estaba organizando, durante el evento y después del mismo, es decir, los días siguientes a que la conferencia finalizó. ¿Cómo comenzó? Creo que es justo echar el cuento de cómo surgió la idea de organizar un PyCon en Venezuela, algo que para muchos, dentro de la comunidad incluso, resultaba una locura hace un par de años. Todo comenzó por allá en febrero de 2011, yo empezaba mis pasantías cortas de la Universidad en Vauxoo , me iniciaba en Python con aquel trabajo, era toda una nueva manera de programar y me encantaba, por referencia de Nhomar Hernández terminé metido en la lista python-caracas y, posteriormente, en la de Python Venezuela en coactivate. Recuerdo algunos mensajes en la lista de python-caracas se estaba hablando de que sería una buena idea organizar un Día Python para vernos las caras, yo era joven e ingenuo, me ofrecí para organizarlo y en marzo de 2011 tuvimos nuestro primer PyDay Caracas , en el auditorio de la biblioteca de la Universidad Católica Andrés Bello. Luego de ese primer PyDay , que se repitió en Mérida unos días después, Francisco Palm decía por la lista que se debería aprovechar el impulso para organizar algo más grande: un PyCon . La idea, por esos días, no caló mucho entre la gente de la comunidad, las cosas se fueron enfriando poco a poco y con el tiempo, sólo había uno que otro mensaje ocasional en la lista y nos veíamos una vez cada alineación planetaria. Luego, por allá en diciembre de 2012, conversando con Francisco Palm, la idea de un PyCon no me pareció tan descabellada, había posibles patrocinantes, la sede podría ser la UCAB, se asomaba la idea de invitar ponentes internacionales, yo por mi parte, acababa de renunciar en Vauxoo para dedicarme a mi tesis de grado, entonces, también trabajaba en mi tesis, seguía siendo joven e ingenuo y acepté lanzarme de frente con la organización del evento. El comienzo Justo empezando, nos dividimos un poco las tareas, decidimos que el evento sería en Caracas y que la sede sería la Universidad Católica Andrés Bello, al ser casi egresado de allí, ya se cómo se mueven las cosas dentro, conozco a varias autoridades y se también con quién hablar o dónde dirigirme. Había algo que para mi resultaba vital, tener apoyo de mi Escuela, la Escuela de Ingeniería Informática de la UCAB. Lamentablemente, aunque el Prof. Ricardo Casanova tenía instrucciones de apoyarme en lo que pidiera, no hizo más que decirme que \"los auditorios y los laboratorios no pueden reservarse con tanta antelación\", de resto, resolví escribiéndole a las unidades funcionales correspondientes y reservando laboratorios y el auditorio \"con mucha antelación\". Me hubiera gustado contar con un mayor apoyo por parte de mi Escuela, pero supongo que aquello de \"nadie es profeta en su tierra\" es cierto. Una vez asegurados los espacios para alojar el evento, me dediqué a buscar ponentes, ya había unos nacionales más que confirmados a quienes no había siquiera que preguntarles: Francisco Palm, Nhomar Hernández, Carlos Gustavo Ruíz, Carlos Zager y Juan Hernández, pero para atraer más personas al evento, hacían falta ponentes internacionales, me dediqué a escribirle a Guido Van Rossum y a Wesley Chun a ver si estarían interesados en participar, eso sí, teniendo presente que tocar la puerta no es entrar. De parte de Guido, obtuve una respuesta negativa, él dice que prefiere no viajar porque es malo para su familia y es totalmente entendible, ya tiene su agenda y va al PyConUS y al EuroPython casi exclusivamente. Por su parte Wesley también me dijo que no, sin embargo me facilitó una larga lista de contactos, me puso en contacto con José Montes de Oca (venezolano en Google) y me pidió que lo mantuviera al tanto del evento. Gracias a Wesley Chun, pude contactar con Facundo Batista y Érico Andrei, los dos ponentes internacionales del primer PyConVE , la invitación incluía pasaje y hospedaje en Caracas, ambos aceptaron y yo, en ese momento, no tenía patrocinantes. Tomando forma y sintiendo la presión Bien, en enero ya tenía cuatro cosas: una fecha para el PyConVE , dos invitados internacionales confirmados (Facundo y Érico), un invitado internacional por confirmar (José Montes de Oca) y la preocupación de conseguir el dinero para cumplir la promesa del pasaje y el alojamiento en Caracas para los invitados, bastante ¿no? Empecé a escribir a mediados de enero a la Escuela de Ingeniería Informática (EII) para pedirles apoyo en la logística interna, especialmente la reserva de los auditorios, la Prof. Susana García, directora de la EII, designó al Prof. Ricardo Casanova para que me ayudara en lo que fuera necesario. Procedí entonces a contactarlo para la reserva del auditorio y los laboratorios, su respuesta fue, en resumen, \"no puedes reservar con tanta antelación en este momento estoy muy ocupado y no puedo\", este personaje y yo tenemos en el pasado un problema originado por una discusión de esos temas religiosos Mac vs Linux del que, aparentemente, no ha podido sobreponerse. Dada la negativa de apoyo o, más bien, intento de retrasarme las cosas, decidí contactar directamente a la Dirección del Cultura y a la Dirección de Tecnologías de Información (DTI) para reservar los espacios. Como era de esperarse, todo fluyó con normalidad y ya a finales de enero tenía algo mas: el Auditorio Hermano Lanz y los laboratorios A613 y A553 de la UCAB reservados para albergar el PyConVE Las cosas se durmieron un poco hasta finales de febrero, que los organizadores de PyConAR lanzaron su página web con el llamado a charlas, inscripciones, información del evento, invitados internacionales y demás información del evento. Acá no teníamos siquiera un En Construcción y, en pocas palabras, me asusté (sintiendo la presión). Corrí a la lista Conferences de python.org para pedir ayuda con el dominio oficial ve.pycon.org y, mientras, compré el dominio pyconve.com a través de GoDaddy . Aprovecho acá para agradecerle a M.A. Lemburg por su ayuda configurando el dominio. Ya que las cosas no fluían con la velocidad que quería con la página web, pedí ayuda en la oficina, en ese momento trabajaba en Zava , nos dedicamos 4 desarrolladores a sacar la página y en una tarde ya teníamos algo visual y semi-funcional, al final de la semana ya teníamos una página bastante completa y apta para el público , la hospedamos en el VPS de la empresa y listo. Posteriormente la empresa me dejaría tiempo para atender bugs y añadir características nuevas, esto fue en abril. Empezando a tranquilizarme Conversando con Francisco, me di cuenta de que las cosas no iban tan atrasadas como pensé, él había conseguido patrocinio para afiches, agua y almuerzos para los organizadores y ponentes durante el evento, yo había conseguido ponentes internacionales, sede y página web así que lo demás, iría llegando poco a poco. Todavía tenía una preocupación más: LOS PASAJES , me dispuse a escribirle a Nhomar Hernández a ver si desde Vauxoo o algún cliente/socio de negocios podrían patrocinar los pasajes. La respuesta fue afirmativa y, ya a mediados de septiembre, estaba enviándole a Érico y a Facundo sus tickets electrónicos, en cuanto a José, el ponente de Google, tenía tiempo sin noticias hasta que confirmó, pero para cuando confirmó los pasajes habían subido de precio de manera astronómica y, difícilmente, un patrocinante iba a querer pagarlo, así que llegamos al acuerdo de que sería por videoconferencia a través de un Google HangOut , escribí al DTI para que realizaran las configuraciones pertinentes. Mientras tanto, teníamos unas 35 ponencias inscritas y alrededor de 150 personas registradas para asistir al evento, esto me tenía súper contento, sinceramente no esperaba tanta receptividad. Francisco consiguió organizar un evento en el CIDA en Mérida y logró que un patrocinante pagara pasaje Caracas - Mérida para que Facundo participara en ese evento, el PyTatuy . Todo parecía ir viento en popa. Imprevistos, imprevistos, IMPREVISTOS!!! Bueno, nada es perfecto, los imprevistos en este tipo de cosas están a la orden del día, recordemos que Murphy existe. Previendo que, quizás, no llegara el agua a tiempo el primer día. Facundo decidió venir con su familia, ahora debía buscarle una habitación en un Hotel cerca de la Universidad, tienen un hijo pequeño, así que debía ser un buen hotel y, además, debía buscar un patrocinante para eso, la habitación no se concretó sino hasta tres días antes de que llegaran el patrocinante fue EchandoCódigo (Gracias Osledy Bazó!!!). En la madrugada del 27 de octubre recibo una llamada a mi celular, era un número internacional y atendí. Del otro lado decían \"Ché ¿Israel?, Facundo Batista aquí, estoy en el aeropuerto y no me dejan abordar acá\" , había un problema con el nombre, para enterarse del cuento completo, click acá . Inmediatamente llamé a Nhomar a ver si estaba despierto (y si no, pues que se despertara), estuvimos conversando un rato y luego Facundo me informó que ya le habían liberado los boletos, pero que era necesario corregir los boletos para el regreso. El 27 de octubre en la noche, voy con Giselle, mi novia, al aeropuerto a buscar a Facundo y familia, pero al llegar, me consigo únicamente a Facundo, la familia se había quedado varada en Lima, les habían cancelado el segundo tramo del viaje. Bueno, subimos a Caracas y lo dejé en el Hotel para que pudiera descansar y al día siguiente ya se resolvería lo del vuelo de la familia, afortunadamente llegaron en domingo 28 al mediodía. Francisco Palm había quedado en traer los afiches para pegarlos por la universidad cuando viniera a Caracas con Facundo luego del PyTatuy , pero los dejó en el carro y el carro lo dejó en Mérida (sorry!, tenía que contarlo, no lo tomes a descarga, jajajajaja). Con respecto a Érico, todo fluyó de maravilla, se quedó en mi casa, comió arepas, aprendió a moverse en Metro, andaba solo por la ciudad!!!, eso me preocupaba enormemente, pero luego entendí que él es muy independiente cuando viaja. Hubo cancelaciones tardías: Ernesto Crespo sufrió una caída que le imposibilitó viajar (espero se encuentre bien ya), Roldan Vargas tampoco podría venir a Caracas, Edwind Ocando iba a ser operado y tuvo que cancelar también, Efraín Valles no pudo venir por razones laborales. Hubo otras más, pero no recuerdo, afortunadamente varios miembros saltaron al rescate, Gerardo Curiel cubrió varias charlas canceladas con temas interesantísimos de desarrollo web y vim para pythonistas, Leonardo Caballero cubrió una de las charlas de Plone que fueron canceladas y Érico Andrei también dió una charla adicional muy orientada al público estudiantil. Bien, llegó el primer día del PyConVE y, como era de esperarse, fue un desastre, había una cola insoportable en la Av. Páez, ergo, llegué tarde con Érico, Gigi (bueno, Giselle, mi novia) ya había llegado y me ayudó a ir organizando todo, ya estaban Sebastián Magrí y Leonardo Caballero en la UCAB, Rafael Andara (del DTI) me había estado esperando para darme los datos de configuración para poder realizar la videoconferencia con José Montes de Oca, muchísimas gracias a Gigi y a los muchachos por ir alistando todo, el evento arrancó casi una hora y media tarde (perdonen todos el retraso). Las aguas llegaron tarde (menos mal fui precavido), los almuerzos también así que se convirtieron en la cena de varias personas (incluyéndome). Vale acotar que pasé toda la semana del PyCon enfermo del estómago y sobreviviendo a base de Loperán y Alcaseltzer. El último día del evento, el DTI no me abrió los laboratorios porque no tenían la llave y la oficina donde están no abre los sábados (mal!) y, supuestamente, hay una persona los sábados que tiene las llaves pero ese día no fue (terrible!!), por lo que todos los talleres de ese día (o la mayoría) hubo que darlos como charlas relámpago en el Auditorio (una manera de resolver y no quedar tan mal). Conclusiones Bueno, luego del PyConVE , aprendí muchísimas cosas en cuanto a gestión de eventos y otras tantas de comunidad, sobre todo aprendí a delegar, es imposible que una sola persona pueda hacerlo todo. Descubrí que hay mucha gente valiosa dentro de la comunidad en quien se pueden delegar cosas de manera muy confiable, Jin Kadaba , Luis Alberto Santana , Carlos Gustavo Ruíz , Leonardo Caballero , Sebastián Magrí , Nhomar Hernández (pero por supuesto!), Juan Hernández (no faltaba más), Francisco Palm . y si olvido a alguien, pido disculpas. Hay aún mucho trabajo por hacer, es necesaria una figura legal para poder recibir donaciones en calidad de patrocinio de una manera más formal, actualmente estamos en eso en la comunidad, creo que el PyCon, aunque bien fue algo arriesgado, fue un catalizador y un activador para muchas personas dentro de la comunidad, está en nosotros no dejar que la ola muera y continuar trabajando para llevar adelante nuestra comunidad, muchas personas de otros estados quieren organizar PyDays , personas que antes no intervenían en la lista de la comunidad ahora son más activas y sólo leí buenos comentarios del evento. Todo esto y, sobre todo las dos primeras, con cosas que me hacen decir que valió la pena el esfuerzo, y lo volvería a hacer . Perdonen si me extendí, creo que este es el artículo más largo que he escrito en muchísimo tiempo, pero eran demasiadas experiencias que quería compartir, finalmente, muchísimas gracias a Facundo Batista y Érico Andrei por participar, gracias a todos los ponentes nacionales por apartar esos tres días en sus agendas y movilizarse a la UCAB para nuestro primer PyCon , a mi novia por apoyarme en mis locuras y a todos quienes asistieron de Caracas y, sobre todo, del interior del país, GRACIAS TOTALES!.","tags":"Blog","loc":"http://localhost:8000/mi-experiencia-en-el-pyconve-2012-y-otros-cuentos.html","title":"Mi experiencia en el PyConVE 2012 y otros cuentos"},{"text":"Saludos a todos, había estado perdido de por estos lados. Todo tiene una razón de ser, en este caso, fueron varias: Por un lado, mi blog viejo, hecho en Wordpress, fue hackeado en repetidas oportunidades y, para ser sincero, me fastidié de que eso me ocurriera. Por otro lado, hace ya unos tres meses que tengo un VPS para tener respado de algunas cosas y hacer experimentos. ¿Qué quiero decir con esto?, simplemente, decidí cambiar mi motor de Blog y, además, hospedarlo en mi VPS, para aprovechar lo que tengo. Notarán, quizás, que esta página se comporta diferente a mi blog viejo, esto es, principalmente, porque esta es una pagina estática... ... Sí!, así es, 100% estática, lo cual quiere decir que no tengo base de datos, no me preocupo por una interfaz de administración, mucho menos debo ocuparme en mantener la seguridad de mi Blog a nivel de aplicación (un dolor de cabeza menos) y, lo mejor de todo, tampoco debo editar HTML cada vez que quiero publicar . Pero, un momento, es una página estática, entonces: ¿Cómo funciona? Fácil, quienes me conocen saben que estoy muy metido desarrollando en Python por ello, no tenía sentido para mi aprender a mejorar una herramienta basada en php como lo es Wordpress. Por mi mente pasaron varios CMS basados en Python, como Mezzanine django-cms e incluso Plone para generar mi Blog, pero ninguno cubrió mis expectativas, unos por ser muy difíciles de modificar y otros por ser muy complejos de utilizar. Entonces luego pensé: \"hey!, soy programador!, programaré mi blog\", pensé en usar CherryPy + Mako + Algún ORM, pero me iba a tardar demasiado, hasta que mi buen amigo Carlos Gustavo Ruíz me llegó con la solución definitiva: Pelican . Pelican es un generador de páginas estáticas, además, basado en Python. Simplemente se le indica un tema que debe estar desarrollado en el sistema de plantillas Jinja2 , también Python. El contenido HTML lo genera a partir de archivos formateados en reStructuredText (.rst), que es un lenguaje de marcado para dar formato a texto (como LaTeX), asociando el texto y las distintas marcas rst con etiquetas HTML o clases css. Y, ¿cuáles son las ventajas? Bueno, para mi, las ventajas las enumero a continuación. Quizás todo lo que diré acá no represente problema para otros, pero tal vez yo sea demasiado flojo: Ya no debo pagar el servicio de hospedaje que tenía en NetQuatro, únicamente pago $9/mes por mi VPS, que no sólo corre este blog, sino también varias instancias de Trac para llevar control de algunos proyectos personales, así que correr todo esto por $9/mes, creo que es una ganga. No dependo de que alguien arregle bugs en un CMS para estar tranquilo de que no me lo van a hackear No debo estar pendiente de bugs en mi aplicación que, seguramente, no tendré tiempo de solucionar Mi base de datos está basada en archivos rst, que puedo almacenar en mi computadora personal, mi disco duro externo, un pen drive, dropbox, google drive, la PC de mi novia y no pesará absolutamente nada pues son archivos de texto plano. Aprendo un nuevo lenguaje (reStructuredText) que, además, me servirá para documentar mis proyectos Python utilizando Sphinx Si quiero migrar mi sitio web a otro servicio de hospedaje, basta con copiar los archivos HTML a la nueva ubicación y listo, sin complicarme haciendo migraciones fastidiosas de base de datos. Si quiero activar comentarios, pues agrego un plugin de Disqus y ellos se preocupan por el tema de la seguridad y el almacenamiento de esos comentarios, mientras que mi VPS sigue con la misma carga y espacio disponible en disco. El tema por defecto es bastante decente y, creo, que no lo cambiaré en un buen tiempo. Creo que es todo, realmente gracias Carlos por tu recomendación","tags":"Blog","loc":"http://localhost:8000/ehm-hola-de-nuevo.html","title":"Ehm, Hola de nuevo!"},{"text":"En esta oportunidad, vengo a hablarles de una etapa del desarrollo que suele ser olvidada y marginada por la mayoría de los desarrolladores que conozco: las pruebas. En Zava , la compañía en la que trabajo actualmente, llevamos un tiempo hablando acerca de usar TDD (Test Driven Development o Desarrollo Guiado por Pruebas) como metodología de desarrollo, en esta metodología, las pruebas unitarias juegan un papel principal, incluso hasta protagónico, pues son el motor del desarrollo del proyecto. Aún cuando no es oficial el hecho de que desarrollaremos utilizando esta metodología, personalmente me tomé en serio el hecho de probar suerte ejecutando mis tareas de programación guiadas por pruebas. En general, el flujo de trabajo en TDD es el siguiente: Elegir un requerimiento: dependiendo de la metodología de gestión de proyecto, será distinto este proceso, en nuestro caso, implementamos una versión modificada de SCRUM, por lo que lo primero que se hace es tomar uno de los requerimientos seleccionados para el sprint que está en desarrollo. Escribir las pruebas unitarias: normalmente, el requerimiento tiene unas características que deben ser cumplidas, estas pruebas deben asegurarse de que dichas condiciones sean cumplidas. Es decir, una pieza de código lleva el programa de un estado A, a un estado B, la prueba deba asegurarse de que el estado B sea alcanzado completamente. Escribir la implementación: lógicamente, si ejecutamos las pruebas sin la implementación, todas van a fallar. En este paso \"se le pone carne al esqueleto\", es decir, de le agrega cuerpo a las funcionalidades cuyas pruebas fueron escritas. Ejecutar las pruebas automatizadas: una vez codificado, se corren las pruebas y se realizan ajustas hasta asegurarse de que todas las pruebas pasan de manera satisfactoria. Refactor: se realizan ajustes para eliminar la duplicación, reducir el acoplamiento y aumentar la cohesión. Actualizar la lista de requerimientos: se marca el requerimiento como terminado. Usualmente el proceso de desarrollo se lleva a cabo al revés, es decir, primero se escribe la funcionalidad y luego se prueba. El problema de este enfoque es el siguiente: Muchas veces por cuestiones de tiempo y prisa por entregar, simplemente se codifica la funcionalidad y se prueba de manera empírica y no se deja alguna garantía de que esa pieza de software funciona de manera correcta. No se validan todos los casos de prueba, ya sea que se pruebe utilizando la funcionalidad o escribiendo pruebas unitarias una vez codificada la pieza que se desea probar. Quien codifica la funcionalidad sabe lo que está bien y lo que está mal y, por la prisa de entregar, no validará los casos en los que sabe que falla pues, dependiendo de la metodología, cuando algo falle puede retomarse por mantenimiento y bug-fixing. En equipos de desarrollo pequeños, es el mismo desarrollador quien escribe las pruebas y si la carga de trabajo es muy alta, no se prueba de manera correcta. Personalmente me ha ocurrido que al desarrollar primero y escribir las pruebas después, termino validando únicamente mis casos base, que es lo que debería ocurrir la mayor parte del tiempo, pero los casos borde quedan sin ser validados y, cuando llega el momento en que algún usuario cae dentro de estos casos y el software falla, debo volver sobre esa funcionalidad que, usualmente, está poco documentada (la documentación es otra de las etapas olvidadas por nosotros los desarrolladores), la escribí hace algún tiempo y no recuerdo bien cuál fue la lógica o, peor aún, la escribió otro desarrollador y no tengo ni la más remota idea de qué fue lo que hizo y, además, tengo otras cosas que hacer en el momento, por lo que simplemente terminaba escribiendo un parche específico para validar lo que estaba ocurriendo en el momento y solventar el problema particular. Si existía más de un caso borde sin validar, este proceso se podía repetir N veces. En el poco tiempo que tengo probando seguir el esquema que propone TDD, mi manera de enfrentarme a los problemas de desarrollo ha experimentado varios cambios y he visto las siguientes ventajas: El escribir las pruebas primero, requiere que tenga muy claro el requerimiento y las condiciones que deben ser satisfechas, por lo tanto, empiezo a codificar la funcionalidad con una idea más clara de lo que debo hacer. A medida que voy escribiendo las pruebas unitarias y validando los casos de prueba, surgen casos borde que, quizás, al principio no había considerado. Al final, tengo una validación completa de mi código y una mayor seguridad en que lo que hice está bien y funciona. Al desarrollar la funcionalidad como tal con una idea más clara de lo que cubre el requerimiento, puedo separar el código en módulos que ejecuten cada uno de los pasos necesarios para cubrirlo de manera satisfactoria. Al tener todos los casos de prueba definidos y, con ello, el requerimiento bien claro y definido, no escribo código de más, simplemente me concentro en cubrir la funcionalidad y todo el código que escribí se utiliza para ello. La cantidad de bugs en el código que produzco ha reducido considerablemente. A la hora de alguna falla, las mismas pruebas me ayudan a cercar el error. Si agrego código que rompe una funcionalidad previa, las mismas pruebas me indican qué está fallando y dónde, por lo que puedo hacer refactor inmediatamente y hacer mis módulos más ortogonales entre sí. Si otro desarrollador debe utilizar lo que yo desarrollé, el código lo entrego con una garantía de que lo que hace, lo hace bien. Cumplo con todas las etapas del desarrollo de software y ninguna queda incompleta. En lo personal, la manera de trabajar que propone TDD me ha funcionado bastante bien, la única desventaja fue que al inicio de mi experimento no tenía mucha experiencia con frameworks o librerías para el desarrollo de pruebas, más allá de algunas pruebas unitarias que hice durante la universidad en los cursos de Ingeniería del Software utilizando JUnit en Java, por lo que debí cubrir una curva de aprendizaje. Una vez hecho esto, todo fluyó mucho más rápido y siento que soy más productivo. Trataré de publicar un par de tutoriales de las herramientas que he usado recientemente para ver si motivo a alguien más a utilizarlas y a tomar un poco más en serio las pruebas de software pues, aunque en la universidad las mencionan como una etapa importante en algunos cursos, muy pocas personas en la calle toman realmente en serio este recurso tan útil.","tags":"Blog","loc":"http://localhost:8000/testing-la-etapa-olvidada.html","title":"Testing: la etapa olvidada."},{"text":"Mini entrada de desahogo pues estoy realmente molesto por lo que acá contaré. Lo siento, debía compartirlo. Hoy, viajando en el metro, una señora cuya mejor descripción es, por sus maneras es, de barrio (sin ánimos de sonar clasista o racista o algo parecido), iba con su hija, sentadas en los asientos del vagon, la niña iba comiendo una de esas bolsas que venden de mango con adobo y otras cosas cuyo olor es, para mi, repugnante (pero entre gustos y colores...), la cosa es que, no importa si iba comiendo caviar, el hecho es que comer en el metro está prohibido. No conforme con eso, a la jóven en cuestión se le cae la bolsa y bota todo el contenido en el piso del vagón y, para colmo, cuando la niña hace el ademán de agacharse a recogerlo, la madre la toma del brazo y le dice \"no mija, deje eso ahí...\". Realmente estoy sin palabras, no conforme con que comes en el metro, que no está permitido, ¿botas basura y no la recoges?, definitivamente el rancho se lleva en la cabeza.","tags":"Blog","loc":"http://localhost:8000/del-comportamiento-en-publico-y-otros-males.html","title":"Del comportamiento en público y otros males"},{"text":"Bueno, vengo con otra reflexión respecto a qué ocurre al culminar la carrera a nivel universitario, quiero empezar aclarando que acá expondré mi (¿poca?) experiencia personal y este artículo estará marcado por mi manera particular de ver las cosas que no necesariamente resulta ser la de todos. Realmente no hace mucho que salí de la Universidad al campo laboral formalmente, aunque durante mis años de estudiante trabajé en un par de cosas. Parte de mi filosofía y experiencia durante la carrera ya la he escrito en un artículo anterior, y en otro bastante reciente, sin embargo, muchas cosas van cambiando a lo largo del tiempo, no es que sea un profesional muy experimentado, pero, espero que estas líneas le sirvan a alguien para guiarse, eso si, sin echarme la culpa. Particularmente, mientras estuve estudiando y trabajando, tuve un pequeño complejo de inferioridad por no estar aún graduado, aquí en Venezuela, como se dice en criollo, \"la gente come mucho título\", es decir, sin el título no eres nadie, sin el certificado, no sabes. Ahora, acabando de salir, el complejo es el mismo, pero por estar \"recién graduado\". Esas dos etiquetas son temas sociales muy graves, he conseguido TSU que saben mucho más que muchos Ingenieros que conozco y estudiantes que pueden resolver un problema mejor que un profesional ya graduado, por ello, no hay que acomplejarse por estar en alguna de esas situaciones, al final, lo que le interesa a la empresa es alguien que haga el trabajo y que pueda hacerlo bien, mientras, tanto las empresas como los profesionales, no entiendan esto, el mundo laboral estará plagado de piratas con título y gente brillante que, o bien está por obtenerlo o, por alguna razón no les fue posible, la etiqueta de \"recién graduado\", debería significar \"soy joven y puedo aprender rápido, contrátame\" y no \"no tengo experiencia, explótame\". Esos mismos complejos, me llevaron a aceptar trabajos con poca paga y muchas responsabilidades, cobrar poco por desarrollar proyectos para algunos clientes y no decir nada, ante esto, no me queda más que decir, no se dejen explotar, sean pasantes o profesionales recién graduados, su trabajo vale, no trabajen tiempo extra gratis, a menos que sea realmente necesario o sea su culpa, respeten su horario de trabajo, sean los primeros en llegar, pero también salgan a la hora, tienen familias, amigos, novias con quienes compartir, quizás puedan dedicar parte de ese tiempo, también, a algún pasatiempos o a desarrollar algún proyecto personal o para algún cliente bajo la figura de \"freelancer\", utilicen su trabajo como un gimnasio para poner el forma el músculo de programación, para agarrar experiencia y conocimiento, pero no lo apliquen sólo allí, citando a mi amigo Nhomar Hernández, \"hay que trabajar cada día como si fuera el último\", pero no sólo en una cosa, hay que diversificar. Una vez graduados, pensamos que dejaremos de estudiar pero, en realidad, apenas empezamos, cada proyecto puede enviarnos varios meses a wikipedia o hacernos sumergir en una serie de libros y conceptos que, si bien puede que no sean técnicos de computación, forman parte del contexto del sistema y debemos manejarlos, por ejemplo, durante mi breve paso por el mundo de los ERP cuando trabajé en Vauxoo , tuve que aprender conceptos de contabilidad e inventarios, incluso características de equipos de refrigeración para un proyecto, además de estudiar e investigar muchísimo sobre las herramientas usadas en la empresa pues eran nuevas para mi (Python y OpenObject, la plataforma de OpenERP). En esta carrera, básicamente, nunca dejamos de estudiar y aprender, actualmente, en mi actual trabajo en Zava , me toca investigar sobre la cultura italiana alrededor del mundo y las tendencias actuales de la misma, además del framework utilizado para el desarrollo del proyecto (Django). Finalmente, recuerdo algo que me dijo un buen amigo, Tomás Henríquez: \"los primeros empleos te definen, mosca con lo que eliges\", ciertamente, los primeros empleos definen quien serás profesionalmente, por ello, si en los primeros tres trabajos programaste en Java o en PHP, o administraste servidores, muy probablemente para el cuarto te busquen para hacer eso mismo. Ciertamente, en el mismo orden de ideas de Tomás, \"es preferible pasar 3 o 4 meses desempleado que trabajar en algo que no te gusta\". El proceso de hacer tu \"plan de carrera\" debe comenzar antes de graduarte, debes pensar qué quieres hacer, en mi caso, quiero especializarme en Desarrollo de Software, un campo muy competitivo, por ello, seleccioné herramientas que no fueran muy comunes en el área, de esta manera te diferencias del resto, claro que se programar en PHP y Java (en .NET no por un tema de principios) pero todo el mundo programa en PHP, .NET y Java, por lo que en un primer momento seleccioné Perl como el lenguaje en el que me especializaría, empecé a hacer tutoriales, leer libros y hacer algunos programas utilizando las librerías del CPAN, esto cambió cuando entré en Vauxoo y aprendí Python, mi actual hacha de batalla, por ahora, mi plan de carrera es especializarme en Desarrollo Web, en todos sus campos, Back-End y Front-End: desde servicios web y web semántica, hasta RIA, un buen programador debe ser versátil y adaptarse a cualquier parte del proyecto. Para cerrar, quiero aclarar que con esto último no estoy diciendo que se casen con una tecnología o un lenguaje en particular, aprendan de todo un poco, sean buenos, pero hay que especializarse y ser excepcionalmente bueno en algo, yo elegí Desarrollo en Python, y estoy trabajando en ello, también programo en PHP, Java, Perl y C/C++ si es necesario, pero mi principal herramienta es Python y, aún así, tengo intenciones de aprender Ruby.","tags":"Blog","loc":"http://localhost:8000/graduado-y-ahora.html","title":"Graduado, ¿y ahora?"},{"text":"He tenido un poco abandonado el blog debido a mi trabajo especial de grado (TEG) y a mi nuevo trabajo en Zava, pero poco a poco he ido adelantando cosas y hoy conseguí algo de tiempo para escribir las últimas cosas sobre las que he estado reflexionando las últimas semanas (o meses). Bien, tengo la satisfacción personal de haber desarrollado una buena tesis, obtuve una calificación de 19 puntos con mención honorífica, al jurado pareció haberle gustado mucho el trabajo que hice, mi tutor, el Prof. Wilmer Pereira, también quedó muy satisfecho con el resultado, igual que mi colaborador/asesor/amigo, el Prof. Carlos Pérez Díaz, digamos que estoy cerrando otra etapa de mi vida con broche de oro, a pesar de tardar más de 5 años en culminar mis estudios de Ingeniería en Informática, estoy muy feliz con todo lo que aprendí y compartí con mis profesores, algunos, verdaderos maestros, con mis compañeros y amigos, especialmente con Ronald Oribio, Khaterine Castellano, Viviana Trujillo, Gerardo Barcia y Jhonatan Trujillo. También con todos los que les dí clases en mis días de preparador y asistente docente: Ayleen Posadas, Karen Barreto, Héctor Sam, Juan Perozo, Alfredo Nava, Oswaldo Bracho, muchísima gente hizo mi paso por la universidad, una etapa muy especial, sobre todo mi novia, Giselle Bracamonte, en mi último semestre, puede que quien esté leyendo esto no conozca a quienes menciono, pero realmente no me importa. Ahora que cierro este ciclo, hay muchas cosas sobre las que reflexionar, sobre todo ahora cuando tengo ya un poco más de un año trabajando, desarrollando software, programando, diseñando/arquitectando soluciones, investigando y, a veces, sufriendo por la falta de sueño, pero eso será en otro artículo, en este me gustaría reconocer a aquellos profesores que se ganaron mi respeto dentro del aula y tuve el gusto de ganarme su amistad fuera de ella. Salimos de la universidad creyendo que lo sabemos todo y, en realidad, lo sabemos, pero al mismo tiempo no. Permítanme explicarme, conocemos la teoría, sabemos lo que es una clase, un objeto, sabemos lo que son pruebas unitarias, podemos diseñar e implementar un modelo de datos relacional, podemos, literalmente, \"echar código\", pero la habilidad de \"programar\", se va adquiriendo con el tiempo, de la misma manera que la habilidad de \"entonar\" un servidor o una red. Acabados de salir de la universidad, únicamente, tenemos las bases, queda de nuestra parte terminar de construir el edificio. Para mi, los profesores quienes, realmente, me ayudaron a afianzar esas bases fueron: Lúcia Cardoso (en Sistemas de Base de Datos I y II), con ella aprendí que ser un Ingeniero en Informática, no es sólo programar, esas líneas y secuencias de instrucciones, normalmente, tienen el objetivo de satisfacer las necesidades de información de \"alguien\", por ello, debemos preocuparnos por cada aspecto de nuestra solución, desde el modelo de datos hasta la manera de presentarlos para que se conviertan en información. Un buen modelo de datos da un buen soporte a la información que manejará nuestro programa y nos facilitará la vida en capas superiores. Es además, una profesora muy exigente y tiene fama en los pasillos de ser uno de los filtros de la carrera, una fama muy bien ganada. Hoy, agradezco enormemente su nivel de exigencia. Carlos Barroeta (en Ingeniería y Desarrollo del Software), con él aprendí principios vitales para cualquier programador: especialmente \"No reinventar la rueda\", si hay algo ya probado y funciona, ¿por qué lo usarlo y ahorrarnos trabajo?. Temas como Patrones de Diseño, Programación Orientada a Objetos, Pruebas de Software, Separación por Capas y Metodologías Ágiles fueron el día a día en estas asignaturas. Es famoso en la Escuela por ser un entusiasta de las nuevas tecnologías y los Stack-Frameworks que facilitan la vida del desarrollador, hoy agradezco que haya puesto tanto empeño en explicar esos conceptos y en asegurarse de que los entendiera (a través de proyectos prácticos y complejas preguntas en los exámenes), de no haber sido así, hoy probablemente sería un programador terrible y sin ganas de superarse. Darío León (en Sistemas de Operación), aprendí cómo funciona a bajo nivel un sistema operativo. Los conceptos de Cambio de Contexto, Planificación de Procesos, qué hace el Kernel y cuáles son los componentes y servicios de un Sistema Operativo, aprendí de administración básica de sistemas Un*x y, creo que una de las cosas que hoy me quedan, aprendí a utilizar la herramienta que uso hoy para escribir cada línea de código que produzco: el editor vim. Rodolfo Campos (en Sistemas Distribuidos), aprendí varios conceptos macro en cuanto a coordinación de sistemas paralelos (como un clúster) y distribuidos (como un grid): algoritmos de reloj, sincronización, elección del líder, protocolos de comunicación, redundancia y tolerancia a fallos. Fue una de las materias que más disfruté de la carrera, es realmente increíble cómo puede uno, como ingeniero, hacer posible que dos dispositivos en lugares geográficamente distintos puedan coordinar acciones para lograr una tarea en común y, además, que todo sea transparente para el usuario. Wilmer Pereira , aunque nunca me dio clases formalmente, fue mi tutor de tesis y mentor en el área de investigación, siempre lo he considerado un modelo a seguir por todo el conocimiento que tiene y por su humildad y sencillez a la hora de hablar con un alumno o con cualquier otra persona, es realmente una persona brillante que a veces pareciera vivir en su propio mundo. Sus lecciones académicas y personales son muy valiosas, no puedo más que decirles: MUCHAS GRACIAS!, espero llegar a ser al menos la mitad de buenos de lo que ustedes son.","tags":"Blog","loc":"http://localhost:8000/una-nueva-etapa-se-cierra.html","title":"Una nueva etapa se cierra"},{"text":"Todo el tiempo escuchamos a los fanáticos de Android (entre los que me incluyo) diciendo lo bueno que es el sistema operativo, todo lo que permite, las libertades y potencialidades que ofrece, todo un conjunto de benefinios y cosas \"chéveres\" que pueden hacerse con Android, entonces, ¿por qué cambiar el sistema operativo de tu celular? Bueno, existen varias razones, voy a listar las que yo, particularmente, siempre doy a quienes me preguntan: Funcionalidades bloqueadas: muchas veces, los fabricantes bloquean ciertas funcionalidades propias de Android, ya sea por seguridad o por cuestiones de marketing. En el caso de Captivate, la posibilidad de instalar aplicaciones fuera de Android Market (Fuentes Desconocidas), no sólo viene bloqueada, sino que no aparece en el menú. Aplicaciones inservibles: cuando compramos un celular que fue configurado para alguna operadora, como AT&T, T-Mobile o Vodaphone, normalmente viene con varias aplicaciones propias de esa operadora que, si somos de un país del 3er mundo, al liberarlo no nos servirán. Algunas corren como servicios y, sean o no servicios, siempre estarán ocupando un espacio en nuestro teléfono, espacio que podría ser invertido en otro programa que sí utilicemos pues es normal queel ROM no permita la desinstalación de esas aplicaciones propias de la operadora. Mejorar el rendimiento: todos los fabricantes producen sus propios ROM, con características particulares y personalizables según sea el caso, por ejemplo, la experiencia entre un dispositivo Samsung, unoHTC y otro Motorola va a variar un poco, aún cuando los tres dispositivos sean Andoid. Cada ROM es construido para ser compatible con un número de dispositivos o con todos los dispositivos de una serie, por ello, hay controladores (drivers) o aplicativos de backend que nuestro equipo probablemente no esté usando, un ROM, es específico para un dispositivo. Podemos verlo como que Android es un Linux recién instalado mientras que el ROM que instalemos es el mismo Linux, pero una vez que recompilamos el Kernel para que se adapte a nuestrohardware. Pueden hacer la siguiente prueba: descarguen la aplicación Quadrant[1] a través del Android Market y corran el benchmark antes y después de instalar el ROM alternativo, verán una diferencia radical en los resultados. Tener un sistema totalmente personalizable: esto va un poco alineado con la razón anterior, si bien es cierto que el mismo nivel de personalización puede lograrse con el ROM de fábrica, es cierto también que mientras más aplicaciones y temas tengamos instalados y corriendo al mismo tiempo, se consumirán más recursos en el teléfono, es por ello que cobra importancia tener un ROM optimizado y que mejore el rendimiento del equipo, de esa manera, podemos tener cientos de efectos configurados, modificar el manejador de ventanas y configurar varias animaciones sin que nuestro telefono se cuelgue. Además, muchos ROM ya vienen con acceso root activo, lo que nos permite un mayor control sobre el dispositivo. Porque se puede: si ninguna de las razones anteriores te convencieron, esta quizás tampoco lo haga, es seguramente la más banal de todas, ¿por qué hacer las cosas en linux por línea de comandos cuando existe un frontend gráfico?, simplemente porque puedo!, existen muchos ROM alternativos para cientos de dispositivos, consigue uno para el tuyo, pruebalo, si no te gusta o note convence, simplemente busca otra o regresa al ROM original, es lo hermoso del mundo Android, te permite hacer esas cosas que en \"otras plataformas\" no deja de ser simplemente unsueño. [1] Quadrant es una aplicación que corre pruebas de estrés sobre nuestro equipo, mide los resultados y nos muestra un gráfico posicionando el dispositivo en comparación con otros.","tags":"Blog","loc":"http://localhost:8000/por-que-flashear-un-telefono-android.html","title":"¿Por qué flashear un teléfono Android?"},{"text":"Ya en la entrada anterior expliqué cómo hice para, \"inocentemente\", poner la torta mientras instalaba Cyanogenmod, ahora explicaré paso a paso cómo lo reparé, luego de eso, explicaré cómo procedí a instalar Cyanogenmod 7 en mi Samsung Captivate (AT&T Galaxy S). El escenario era este: 2:00am, mucho sueño y ganas de dormir, un poco frustrado porque mi flamante Captivate no era más que un pisapapeles muy costoso, la \"pantalla negra de la muerte\" era una perturbación en la fuerza realmente fuerte, era hora de invertir las próximas horas en averiguar cómo solucionar el problema y, además, en Linux: Unbricking Lo primero que debía hacer era regresar mi teléfono a su estado de fábrica, por lo que busqué (como un loco) algún sitio web que tuviera para descargas el ROM original del Captivate, por fortuna lo conseguí y lo respaldé en mi carpeta pública de Dropbox (junto con otras cosas que menciono acá, si a alguien le hace falta, puede pedirmelas y se las mando por mail). El primer reto era \"romper el ladrillo\", por fortuna existe una aplicación, desarrollada en java, que se llama OneClick Unbricker , simplemente conecté el teléfono a la computadora, activé la aplicación y automáticamente el teléfono estaba en su estado anterior, es decir, no respondía, pero al menos iniciaba y me permitía entrar a modo de descarga, lo cual me permitió pasar al siguiente paso. Instalando el ROM de fábrica Luego de descargar el ROM, hay que flashearlo en el dispositivo, para ello existe un aplicativo llamado Odín, que sólo corre en Windows pero que no cunda el pánico, Heimdall, un aplicativo similar, corre perfecto en linux, es un programa similar a Odín, cuenta con interfaces para línea de comandos y un frontend gráfico que no da problemas. Al descomprimir el firmware, debemos conseguir los siguientes archivos: boot.bin: que lo colocamos en el campo Primary Bootloader Sbl.bin: que corresponde con el campo Secondary Bootloader factoryfs.rfs: que es el sistema de archivos original zImage: que corresponde con la imagen del kernel param.lfs, dbdata.rfs, cache.rfs y modem.bin que van en los campos del mismo nombre en el Heimdall firmware.xml: que va en el campo recovery Esto puede cambiar dependiendo de la versión del Heimdall, tengo entendido que en la última versión se coloca el rar completo y él mismo extrae los archivos que necesita. Una vez que tenemos todo listo, iniciamos nuestro Galaxy S Cativate en modo Descarga, para ello retiramos la batería, conectamos el equipo via USB, presionamos los dos botones de volúmen y el de encendido mientras colocamos la batería y luego liberamos el botón de encendido, cuando veamos una pantalla negra con una señal en amarillo que dice Download, presionamos Start en el Heimdall para flashear el firmware, una vez que la barra de progreso llegue al final, el teléfono reiniciará y tendrá el firmware de fábrica. Instalando Cyanogenmod 7 Antes de seguir, es recomendable que hagan un respaldo completo del sistema, para que no les ocurra lo mismo que a mi en caso de desastre, dicho esto, el procedimiento para instalar Cyanogenmod 7 es súper sencillo: Descargamos la versión para nuestro dispositivo, junto con la versión de google apps pues Cyanogen no las incluye debido a una exigencia de Google de no incluir sus aplicaciones directamente en el ROM, sino distribuirlas aparte. Descargamos el zImage de ClockWork Recovery y lo flasheamos con Heimdall en el teléfono (también lo tengo en Dropbox). Colocamos ambos zip (si descargamos los dos) en el internal_sd del teléfono y reiniciamos en modo Recovery, para ello apagamos el teléfono y presionamos los botones de power, y losdos de volúmen al mismo tiempo hasta que nos aparezca un menú. Hacemos un wipe de la data y del caché con las opciones correspondientes (utilizamos los botones de volúmen para desplazarnos por el menú y el botón de encendido para seleccionar). Luego, seleccionamos install zip from SD. Después, choose zip from SD. Seleccionamos el zip a instalar. Debemos repetir los pasos 5, 6 y 7 para el zip de Google Apps si deseamos instalarlo. Al reiniciar el teléfono, empezará a arrancar Cyanogen, es importante que el teléfono no se apague durante este proceso, lo digo por experiencia ;-), el primer arranque siempre tardará un poco así que hay que tener algo de paciencia.","tags":"Blog","loc":"http://localhost:8000/limpiando-la-torta-e-instalando-cyanogenmod-7.html","title":"Limpiando la torta e instalando Cyanogenmod 7"},{"text":"Bien, en este post pretendo resumir mi primera metida de pata flasheando mi Samsung Captivate (Galaxy S versión AT&T) con Cyanogenmod 7. Vale destacar, que este es el primero de una serie de tres artículos sobre qué hacer y qué no hacer al flashear tu teléfono celular con un mod basado en Android. He metido la pata muchas veces haciendo tareas de administración con sistemas operativos, sobre todo en Linux, he puesto la torta múltiples veces recompilando el Kernel, resolviendo dependencias, instalando paquetes inestables o experimentales, \"limpiando\" directorios del sistema, haciendo exec rm {} sin probar primero que el find me retorna el conjunto de datos correcto, reconfigurando particiones, en fin, muchas novatadas de las que uno aprende, o quizás no, pero son golpes que te dicen que has hecho algo terriblemente mal y vas a pagarlo caro en horas nalga[1], pero esta es la primera vez que me ocurre con un teléfono celular. Les enumero las cosas que hice mal: NO hice Backup: todos los foros en los que consulté antes de embarcarme en esta aventura empezaban con un texto en letras rojas y con un tamaño de fuente cuyo tamaño si estuviera definido por una función, el límite tendería a infinito que rezaba lo siguiente: \"ANTES DE EMPEZAR A HACER ALGO RECUERDA HACER BACKUP\", un NAndroid no quita mucho tiempo y es una muy buena práctica en caso de que ocurra un desastre. Respaldar el ROM original del teléfono, además, es una garantía de que puedes regresarlo a su estado de fábrica en caso que quieras venderlo después o no te guste ningún ROM alternativo. En fin, ya el desastre ocurrió y no tengo manera de regresar de inmediato a mi configuración anterior. Apagué el teléfono durante el primer arranque, si te dicen que no lo hagas, es porque no debes hacerlo, durante el primer arranque luego de instalar un ROM, el sistema operativo realiza ciertos ajustes y revisa que todo esté OK antes de levantar, es por ello que siempre el primer arranque tarda un poco más. Realmente no lo apagué, lo dejé desconectado y con poca batería y, simplemente, se descargó, cuando lo encendí de nuevo, me apareció el \"Samsung Black Screen of Death\" que aparece en la cabecera de este artículo, mi Captivate no reaccionaba, no entraba en modo descarga ni en modo de recuperación, estaba muerto. Wipe: como no iniciaba, le hice un wipe a todo e intenté nuevamente, esto no funciona, si antes no cargaba, ahora mucho menos, medidas desesperadas ante situaciones desesperantes en las que, no cabe duda, se aprende mucho. Todo se resume en \"si lo dicen, es por algo\" [1] Horas nalga: término acuñado por el Prof. Jesús Darío León (con quien cursé Sistemas de Operación en la Universidad) para hacer referencia al tiempo que se invierte en investigar \"cómo hacer...\" para luego \"hacer\", ese tiempo no se es productivo como tal, por lo que no pueden llamarse \"horas hombre\", y como uno pasa mucho tiempo sentado leyendo y probando diversas maneras de resolver el problema, quienes sufren son las posaderas.","tags":"Blog","loc":"http://localhost:8000/como-no-instalar-un-nuevo-rom-brickeando-tu-cel.html","title":"Cómo NO instalar un nuevo ROM (Brickeando tu cel)"},{"text":"Si, resistirse es inútil, donde sea que estés tendrás Python a la mano, menos en Windows que debes instalarlo, pero lo interesante es que puedes tenerlo de igual manera. Escogí el número 6 romano (VI) de manera intencional para esta entrada ya que, con Python, pasa igual que con el editor VI (\"vi ai\"), lo consigues en todos los ambientes Linux, UNIX y GNU/Linux, desde Slackware hasta Linux Mint y desde FreeBSD hasta Solaris, pasando obviamente por el no-tan-libre , MacOS X que al tomar ciertas cosas de FreeBSD es un sistema UNIX-Like, por lo que contiente el editor VI y Python. No se resistan, programar en Python no puede ser más fácil, si usas algún sistema *UN*X , simplemente abre VI y programa en Python, luego ejecúta tu código utlizando el intérprete en un terminal. Espero que estas publicaciones acerca de Python básico les hayan parecido interesantes, hay muchas otras cosas que AMO de Python, pero es mejor dejar este tópico hasta aquí y que cada quien continúe, si así lo desea, con su investigación y aprendizaje particular, para convencerlos creo que 6 es perfecto (chiste geek). Más adelante espero tener nivel suficiente como para publicarles acerca de tópicos más avanzados del lenguaje.","tags":"Blog","loc":"http://localhost:8000/cosas-que-amo-de-python-vi-esta-en-todas-partes.html","title":"Cosas que AMO de Python VI: Está en TODAS partes"},{"text":"Python, hace trivial lo que en otros lenguajes resulta complejo: la introspección o reflexión de objetos. La reflexión o introspección de objetos, es una técnica que permite a un programa cargar objetos que no conoce, examinarlos y determinar sus variables de instancia y métodos para trabajar con ellos. Python nos ofrece ciertas funciones para examinar objetos y conocer las variables y métodos que contiene. Una de ellas ya la he mencionado en un artículo anterior, la función dir() que nos devuelve todo lo que tiene expuesto el objeto que le demos como argumento. Recordemos también que, en Python, todo, absolutamente todo, es un objeto, por lo que el argumento de la función puede ser, literalmente, cualquier cosa. Adicionalmente, Python cuenta con funciones para conocer de qué tipo es un objeto y si un objeto es \"llamable\" o no, mediante las funciones type() y callable(), también con el atributo __class__ podemos conocer a cuál clase pertenece, de manera que podemos llevar a cabo ciertas acciones si un objeto es de cierto tipo, si contiene una función con cierto nombre o incluso si alguna variable de instancia contiene cierto valor, podemos llegar a tal nivel de detalle que podríamos evaluar si el objeto contiene un método de nombre \"x\", es del tipo \"y\" y tiene una variable de instancia llamada \"z\" y tiene el valor \"casa\" y, en base a eso, llevar a cabo cierta secuencia de acciones con ese objeto particular. Ahora bien, hasta ahora, con Python, hemos visto que la manera de acceder a los atributos y métodos de un objeto es, al igual que en muchos lenguajes, de la forma objeto.atributo u objeto.función(), entonces, ¿cómo puedo llamar métodos o evaluar variables de instancia si no las conozco previamente?, que no cunda el pánico, Python me ofrece una función para extraer atributos de un objeto, simplemente conociendo el nombre e indicándolo como una cadena de caracteres, la función getattr() a través de la función dir() puedo obtener esa cadena de caracteres y utilizarla. Pero, ¿qué ocurre con los métodos?, pues repito lo de siempre: en Python, todo es un objeto , así que puedo utilizar getattr() para obtener métodos también y llamarlos, tal como hicimos en un artículo anterior. Obviamente, no puede ser todo tan caótico, usualmente se establecen acuerdos de implementación para, posteriormente, hacer que el programa sea capaz de manejar un dominio acotado de objetos que pueden ser cargados de manera aleatoria, cada uno, con características previamente conocidas pero con comportamientos totalmente diferentes, expliquemos todo esto con un ejemplo simple, tal como hemos venido haciendo en entradas anteriores. Hagamos un ejemplo, programemos un dispatcher (despachador) sencillo, supongamos que tengo una serie de objetos que me interesa que, al ser recibidos, realicen cierta acción determinada, por ejemplo, recibo un objeto y, si puede correr, que corra sino, reviso si puede caminar y, si puede, que camine, caso contrario, simplemente imprimo el dir() del objeto para ver qué puedo hacer con él. En el ejemplo, creamos tres clases muy sencillas, obviamente, en el mundo real, las clases serán mucho más complejas. Mi clase Dispatcher , será la encargada de revisar los objetos y \"si pueden correr\", entonces ponerlos a correr, sino, simplemente informarme qué puedo hacer con ese objeto. Fíjense en la línea 26, que incluso puedo asegurarme de que el atributo al que se hace referencia sea una función, lo cual me permite evitar errores en tiempo de ejecusión al intentar invocar una cadena de caracteres, por ejemplo, como si fuera un objeto \"llamable\". Todo esto es especialmente útil si estamos desarrollando herramientas que trabajan bajo el principio de \"Convention over Configuration\".","tags":"Blog","loc":"http://localhost:8000/cosas-que-amo-de-python-v-introspeccion-de-objetos.html","title":"Cosas que AMO de Python V: Introspección de objetos"},{"text":"Muchas veces, por alguna razón, hacemos desde la capa de aplicación cientos de validaciones y procesos que, si sabemos cómo, podríamos delegar en el manejador de base de datos. Las validaciones de reglas de negocio son un ejemplo muy frecuente de ello, tendemos, por ejemplo, a implementar validaciones redundantes (en el caso de entornos web) del lado del cliente, utilizando AJAX, y del lado del servidor, utilizando el lenguaje de programación que más nos agrade. Esto, añade un nivel de complejidad a nuestro sistema, cuando, muy tranquilamente, podríamos delegar esa validación en nuestro manejador de base de datos a través de un Trigger, con la ventaja de que si algún día, otro sistema necesita conectarse a la base de datos, las reglas de negocio están implementadas directamente en el manejador y, como ya estamos acostumbrados, todo corre más rápido en el nivel más bajo. Ahora bien, ¿por qué empiezo diciendo todo eso?, simplemente por hacer referencia a un ejemplo bastante común, en el que nosotros, programadores, desarrolladores, ingenieros, o como quieran llamarnos, hacemos uso (o quizás sub-uso) de un software muy sofisticado, como lo es un Manejador de Base de Datos y, tendemos a pensar, que es sólo un pote para guardar datos que, además, habla un lenguaje extraño llamado SQL. Otra de las cosas que, algunas veces, hacemos y nos hacen parecer novatos es actualizar dos servidores de base de datos distintos disparando sentencias hacia los dos, o tres, o cuantos sean. Esto añade un nivel de complejidad innecesario a nuestra aplicación, además de estar fuertemente acoplado con la arquitectura física (hardware) del sistema implementado, si el número de servidores a sincronizar cambia, será necesario también realizar modificaciones a nivel de código o de configuración del programa y, además, desaprovechamos la potencia que nos ofrece un manejador de base de datos. PostgresSQL nos ofrece la posibilidad de sincronizar dos servidores de base de datos mediante Replicación. Existen distintos tipos de replicación de servidores, en este caso, configuraremos un esquema Maestro-Esclavo, en el que mi servidor Maestro, recibe y ejecuta todas las transacciones y, además, actualiza a mi servidor Esclavo, que, únicamente, realiza consultas. Empezamos por instalar la última versión disponible de Postgres, utilizando el gestor de paquetes de nuestra distribución de Linux favorita, para este ejemplo, utilicé Debian Wheezy (Testing) y Postgres 9.1. Configurando el Maestro El maestro, es el nodo que ejecuta todas las transacciones de base de datos, digamos que puede realizar todas las operaciones CRUD. Empecemos por establecer ciertos valores de configuración para el manejador en el archivo /etc/postgresql/9.1/main/postgresql.conf. Debemos configurar los siguientes valores: `` listen_addresses = '*' wal_level = hot_standby wal_sync_method = fsync max_wal_senders = 2 wal_keep_segments = 8`` El parámetro listen_addresses establece las direcciones IP de donde mi servidor va a aceptar peticiones, este parámetro acepta valores separados por coma o el caracter asterisco, como en este caso, para especificar que va a aceptar peticiones de cualquier host, de no ser así, sólo las IP listadas podrían sincronizar la base de datos. El valor de wal_level , donde \"wal\" quiere decir \"Write Ahead Log\" y es una estrategia que implementan los manejadores para cumplir con las propiedades de Atomicidad y Durabilidad de las transacciones (¿recuerdan la regla ACID?) y consiste en escribir en un archivo de bitácora todas las modificaciones realizadas a la base de datos. En Postgres existen tres: minimal , que omite algunas operaciones de escritura para hacer las operacionas más rápido, pero no guarda información suficiente para reconstruir la base de datos a partir de un archivo inicial y logs de este tipo, hot_standby y archive , almacenan toda la información necesaria para hacer la reconstrucción completa de los datos, pero únicamente hot_standby permite implementar replicación de base de datos hacia servidores remotos. La opción wal_sync_method es el método que utilizará el manejador para forzar las actualizaciones utilizando WAL. En este caso, utilizamos fsync que se asegura de que los cambios sean escritos físicamente en la base de datos copia, más información sobre los métodos de sincronización disponibles puede conseguirse en [1]. El parámetro max_wal_senders establece el número de sincronizaciones concurrentes que puede ejecutar el servidor. Finalmente, wal_keep_segments , establece el número de WAL LOGS que el servidor guardará en el directorio pg_xlog, estos logs son utilizados para realizar el las actualizaciones vía streaming. Una vez hecho lo anterior, tenemos la configuración básica de Postgres para hacer replicación Maestro-Esclavo vía streaming. Ahora, debemos agregar una regla más de acceso al pg_hba.conf, para permitir a los esclavos conectarse al servidor maestro: `` host replication all 10.1.1.8/32 trust`` Con esa línea, estamos configurando el servidor para que permita conexiones a todos los usuarios con permiso de replicación desde la sub-red 10.1.1.8/32. Ahora, generamos los WAL, para ello, ejecutamos lo siguiente: `` postgres# SELECT pg_start_backup('1')`` Mientras eso esté ocurriendo, en otro terminal, hacemos lo siguiente: `` # cd /var/lib/postgresql/9.1 # tar czvf backup.tgz main`` Con esto, estamos comprimiendo el directorio de datos de Postgres. Una vez hecho esto, detenemos la generación de WAL: `` postgres# SELECT pg_stop_backup()`` El asunto general se resume con la siguiente ecuación: backup inconsistente + WAL = restauración a estado consistente. Estos WAL, se generan en el directorio pg_xlog, y debemos tomar el último que fue escrito. Configurando el Esclavo Lo primero que debemos hacer es sustituir el directorio de datos de esta instancia de Postgres por el directorio de datos del Maestro. Luego, creamos un directorio recovery , donde copiaremos el último WAL del directorio pg_xlog. Adicionalmente, debemos modificar el postgresql.conf con las siguientes variables: `` hot_standby = on wal_level = hot_standby`` Ahora, creamos un archivo de configuración en la raíz del directorio de datos establecer las siguientes opciones: `` standby_mode = 'on' primary_conninfo = 'host=[host_ip] port=5432 user=root password=[some_password]' restore_command = 'cp /var/lib/postgresql/9.1/main/recovery/%f %p'`` Con esto le decimos al servidor que va a esperar réplicas de primary_conninfo , además, el restore_command indica dónde se encuentra el respaldo inicial inconsistente. Finalmente, nos aseguramos de que los roles tengan permiso de replicación: `` postgres# SELECT * FROM pg_roles`` y, de no tener permisos de replicación, alteramos los roles necesarios para ello: `` postgres# ALTER ROLE nombre WITH REPLICATION`` Una vez hecho todo esto, ya hemos configurado un sistema de replicación Maestro-Esclavo utilizando Postgres como sistema manejador de base de datos, y no hizo falta una toalla para eso. Fácil ¿no?. [1] http://developer.postgresql.org/pgdocs/postgres/runtime-config-wal.html [2]`http://developer.postgresql.org/pgdocs/postgres/runtime-config-replication.html#GUC-HOT-STANDBY`_","tags":"Blog","loc":"http://localhost:8000/configurando-replicas-maestro-esclavo-con-postgres.html","title":"Configurando réplicas Maestro-Esclavo con Postgres"},{"text":"Quizás no sepas de quien se trata, es probable que hayas escuchado su nombre alguna vez si (¿y sólo si?) estudias o estudiaste computación, informática o alguna carrera similar. Aún así, si no eres computista, seguramente utilizas algo basado en alguno de sus trabajos, sin importar que utilices Windows, Linux o Mac OS, estás aprovechando algo del legado de este genio. Dennis Ritchie falleció este 12 de octubre, a la edad de 70 años. Una semana despues de que perdiéramos a otra mente brillante, pero del mundo de los negocios: el Sr. Steve Jobs. Ritchie, quien era PhD en Ciencias de la Computación, fue uno de los desarrolladores principales del sistema operativo UNIX y el diseñador del Lenguaje de Programación C, co-autor del libro \"The C Programming Language\" junto con Brian Kernighan, mejor conocido como \"The K&R Book\", uno de los mejores textos de referencia acerca del lenguaje. Si eres usuario de UNIX, Linux o Mac OS, estás utilizando algo que se basa en uno de sus trabajos, de hecho, en ambos. Galardonado en 1999 con el Premio Nacional de Tecnología en los Estados Unidos, ganador del Turing de 1983, autor de múltiples publicaciones en el campo de los Lenguajes de Programación y las Ciencias de la Computación en general, investigador como forma de vida, realmente hemos perdido a una de las mentes más brillantes del siglo XX.","tags":"Blog","loc":"http://localhost:8000/algo-sobre-dennis-ritchie.html","title":"Algo sobre Dennis Ritchie"},{"text":"Confieso, confiésense, confesemos todos, todos somos adictos a Internet, hasta un punto casi enfermizo. No se ustedes, pero si estoy en un lugar sin Internet, o conexión de datos vía 3G, es como si me faltara el aire, incluso, cuando se cae el servicio en mi casa o en la oficina, se me quitan las ganas de trabajar. Y es que, sin Internet, ¿dónde rayos voy a buscar información si me bloqueo?, tengo que usar un módulo nuevo y no se qué objetos me ofrece, ¿cómo reviso el API en la página?, peor aún, ¿cómo busco en google?. Con Python, se acaba esa frustración de no poder trabajar si no tengo una conexión a Internet, y la que es peor aún, la frustración que produce tener una mala conexión, de esas lentas a las que a veces nos acostumbramos. ¿Cómo?, gracias a las funciones dir() y help() , una complementa a la otra, de hecho, una no tiene sentido sin la otra. Ahora bien, ¿para qué sirven?, fácil, me dan acceso a la documentación interna de Python, y por \"documentación interna\" me refiero a la que está escrita en el código fuente de los módulos que importo o en los objetos del core del lenguaje. Voy a detenerme un buen rato explicando cómo es eso de la Autodocumentación Pythonica. dir(): retorna una lista de cadenas de caracteres, que vienen siendo los nombres de las variables y métodos que son visibles o invocables, respectivamente, desde el objeto que le pase como argumento. help(): viene siendo el equivalente al man en la línea de comandos de Linux (*sh). Me muestra la información acerca del objeto función que le proporcione como argumento, recordemos que, para Python, todo es un objeto. En combinación, estas dos herramientas, junto con el terminal interactivo de Python, son muy poderosas y de mucha ayuda, sobre todo en el escenario que dibujé al principio, un lugar con una conexión pobre (o ninguna) a Internet. Permítanme explicarles cómo: Supongamos que estamos comenzando a dar nuestros primeros pasos con Python y queremos ver qué podemos hacer con los tipos básicos en Python, específicamente, uno de los más útiles: el diccionario. Simplemente, declaramos una variable de tipo diccionario y le aplicamos dir(), todo esto a través del terminal interactivo de Python: >> dict = {} >> dir(dict) O simplemente, vamos directo al grano: >> dir({}) Lo anterior debería devolverme por pantalla lo siguiente: ['__class__', '__cmp__', '__contains__', '__delattr__', '__delitem__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'has_key', 'items', 'iteritems', 'iterkeys', 'itervalues', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values'] Esa es la lista de los nombres de todos los atributos y métodos que contiene mi clase Dict. Si quiero leer la documentación de uno en particular, basta con aplicarle help(), por ejemplo: >> help({}.fromkeys) Va a mostrarme la documentación del método fromkeys() de la clase Dict del core de Python: Help on built-in function fromkeys: fromkeys(...) dict.fromkeys(S[,v]) -> New dict with keys from S and values equal to v. v defaults to None. Normalmente es corta y concisa. Puedo hacer esto no sólo para clases de la librería estándar de Python, sino también para módulos completos (incluso un módulo es un objeto, recuerden todo en Python es un objeto), por ejemplo: >> import pygame >> dir(pygame) Va a mostrarme una lista con todo lo que contiene el módulo PyGame, utilizado para desarrollo de videojuegos con Python: ['ACTIVEEVENT', 'ANYFORMAT', 'ASYNCBLIT', 'AUDIO_S16', 'AUDIO_S16LSB', 'AUDIO_S16MSB', 'AUDIO_S16SYS', 'AUDIO_S8', 'AUDIO_U16', 'AUDIO_U16LSB', 'AUDIO_U16MSB', 'AUDIO_U16SYS', 'AUDIO_U8', 'BIG_ENDIAN', 'BLEND_ADD', 'BLEND_MAX', 'BLEND_MIN', 'BLEND_MULT', 'BLEND_RGBA_ADD', 'BLEND_RGBA_MAX', 'BLEND_RGBA_MIN', 'BLEND_RGBA_MULT', 'BLEND_RGBA_SUB', 'BLEND_RGB_ADD', 'BLEND_RGB_MAX', 'BLEND_RGB_MIN', 'BLEND_RGB_MULT', 'BLEND_RGB_SUB', 'BLEND_SUB', 'BUTTON_X1', 'BUTTON_X2', 'Color', 'DOUBLEBUF', 'FULLSCREEN', 'GL_ACCELERATED_VISUAL', 'GL_ACCUM_ALPHA_SIZE', 'GL_ACCUM_BLUE_SIZE', 'GL_ACCUM_GREEN_SIZE', 'GL_ACCUM_RED_SIZE', 'GL_ALPHA_SIZE', 'GL_BLUE_SIZE', 'GL_BUFFER_SIZE', 'GL_DEPTH_SIZE', 'GL_DOUBLEBUFFER', 'GL_GREEN_SIZE', 'GL_MULTISAMPLEBUFFERS', 'GL_MULTISAMPLESAMPLES', 'GL_RED_SIZE', 'GL_STENCIL_SIZE', 'GL_STEREO', 'GL_SWAP_CONTROL', 'HAT_CENTERED', 'HAT_DOWN', 'HAT_LEFT', 'HAT_LEFTDOWN', 'HAT_LEFTUP', 'HAT_RIGHT', 'HAT_RIGHTDOWN', 'HAT_RIGHTUP', 'HAT_UP', 'HWACCEL', 'HWPALETTE', 'HWSURFACE', 'IYUV_OVERLAY', 'JOYAXISMOTION', 'JOYBALLMOTION', 'JOYBUTTONDOWN', 'JOYBUTTONUP', 'JOYHATMOTION', 'KEYDOWN', 'KEYUP', 'KMOD_ALT', 'KMOD_CAPS', 'KMOD_CTRL', 'KMOD_LALT', 'KMOD_LCTRL', 'KMOD_LMETA', 'KMOD_LSHIFT', 'KMOD_META', 'KMOD_MODE', 'KMOD_NONE', 'KMOD_NUM', 'KMOD_RALT', 'KMOD_RCTRL', 'KMOD_RMETA', 'KMOD_RSHIFT', 'KMOD_SHIFT', 'K_0', 'K_1', 'K_2', 'K_3', 'K_4', 'K_5', 'K_6', 'K_7', 'K_8', 'K_9', 'K_AMPERSAND', 'K_ASTERISK', 'K_AT', 'K_BACKQUOTE', 'K_BACKSLASH', 'K_BACKSPACE', 'K_BREAK', 'K_CAPSLOCK', 'K_CARET', 'K_CLEAR', 'K_COLON', 'K_COMMA', 'K_DELETE', 'K_DOLLAR', 'K_DOWN', 'K_END', 'K_EQUALS', 'K_ESCAPE', 'K_EURO', 'K_EXCLAIM', 'K_F1', 'K_F10', 'K_F11', 'K_F12', 'K_F13', 'K_F14', 'K_F15', 'K_F2', 'K_F3', 'K_F4', 'K_F5', 'K_F6', 'K_F7', 'K_F8', 'K_F9', 'K_FIRST', 'K_GREATER', 'K_HASH', 'K_HELP', 'K_HOME', 'K_INSERT', 'K_KP0', 'K_KP1', 'K_KP2', 'K_KP3', 'K_KP4', 'K_KP5', 'K_KP6', 'K_KP7', 'K_KP8', 'K_KP9', 'K_KP_DIVIDE', 'K_KP_ENTER', 'K_KP_EQUALS', 'K_KP_MINUS', 'K_KP_MULTIPLY', 'K_KP_PERIOD', 'K_KP_PLUS', 'K_LALT', 'K_LAST', 'K_LCTRL', 'K_LEFT', 'K_LEFTBRACKET', 'K_LEFTPAREN', 'K_LESS', 'K_LMETA', 'K_LSHIFT', 'K_LSUPER', 'K_MENU', 'K_MINUS', 'K_MODE', 'K_NUMLOCK', 'K_PAGEDOWN', 'K_PAGEUP', 'K_PAUSE', 'K_PERIOD', 'K_PLUS', 'K_POWER', 'K_PRINT', 'K_QUESTION', 'K_QUOTE', 'K_QUOTEDBL', 'K_RALT', 'K_RCTRL', 'K_RETURN', 'K_RIGHT', 'K_RIGHTBRACKET', 'K_RIGHTPAREN', 'K_RMETA', 'K_RSHIFT', 'K_RSUPER', 'K_SCROLLOCK', 'K_SEMICOLON', 'K_SLASH', 'K_SPACE', 'K_SYSREQ', 'K_TAB', 'K_UNDERSCORE', 'K_UNKNOWN', 'K_UP', 'K_a', 'K_b', 'K_c', 'K_d', 'K_e', 'K_f', 'K_g', 'K_h', 'K_i', 'K_j', 'K_k', 'K_l', 'K_m', 'K_n', 'K_o', 'K_p', 'K_q', 'K_r', 'K_s', 'K_t', 'K_u', 'K_v', 'K_w', 'K_x', 'K_y', 'K_z', 'LIL_ENDIAN', 'MOUSEBUTTONDOWN', 'MOUSEBUTTONUP', 'MOUSEMOTION', 'Mask', 'NOEVENT', 'NOFRAME', 'NUMEVENTS', 'OPENGL', 'OPENGLBLIT', 'Overlay', 'PREALLOC', 'PixelArray', 'QUIT', 'RESIZABLE', 'RLEACCEL', 'RLEACCELOK', 'Rect', 'SCRAP_BMP', 'SCRAP_CLIPBOARD', 'SCRAP_PBM', 'SCRAP_PPM', 'SCRAP_SELECTION', 'SCRAP_TEXT', 'SRCALPHA', 'SRCCOLORKEY', 'SWSURFACE', 'SYSWMEVENT', 'Surface', 'SurfaceType', 'TIMER_RESOLUTION', 'USEREVENT', 'UYVY_OVERLAY', 'VIDEOEXPOSE', 'VIDEORESIZE', 'YUY2_OVERLAY', 'YV12_OVERLAY', 'YVYU_OVERLAY', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', '__rect_constructor', '__rect_reduce', '__version__', '_check_darwin', '_numericsndarray', '_numpysndarray', '_numpysurfarray', 'base', 'bufferproxy', 'cdrom', 'color', 'colordict', 'constants', 'cursors', 'display', 'draw', 'error', 'event', 'fastevent', 'font', 'get_error', 'get_sdl_byteorder', 'get_sdl_version', 'image', 'init', 'joystick', 'key', 'mask', 'mixer', 'mouse', 'movie', 'msg', 'numpyarray', 'overlay', 'packager_imports', 'pixelarray', 'quit', 'rect', 'register_quit', 'scrap', 'segfault', 'sndarray', 'sprite', 'string', 'surface', 'surfarray', 'sysfont', 'threads', 'time', 'transform', 'ver', 'vernum', 'version'] Incluso, Python me provée facilidades de documentar el código que escribo bajo este formato mediante docstrings , estos strings de documentación son almacenados en el atributo __doc__, presente en todo objeto Python, los docstrings de Python, son análogos al Javadoc de Java, con la diferencia que no necesito \"compilar\"[1] mi programa para generarlo, basta con importar mi objeto en algún programa Python o en el terminal interactivo. Hagamos un ejemplo sencillo para incluir contenido de documentación en mis objetos. Definamos una clase básica: Ahora, simplemente hagamos: >> a = calculadora() >> dir(a) >> help(a.eleva) y veamos los resultados. Todo esto es muy útil, sobre todo cuando se desarrolla en equipos o en comunidades de espíritu colaborativo, además, evita pasar horas buscando a otro programador para que nos explique qué rayos hizo o cómo funciona su algoritmo. ---- [1] Todo el que conoce Java, sabe que en realidad el código no se compila como tal, es decir, no produzco un código objeto ejecutable directamente, sino un bytecode que es interpretado por la máquina virtual. Por ello, se dice que Java es un lenguaje Precompilado/Semi-interpretado . Python funciona de manera similar, cada archivo .py, al invocar el intérprete genera un archivo .pyc, que contiene un bytecode que es lo que realmente ejecuta el intérprete.","tags":"Blog","loc":"http://localhost:8000/cosas-que-amo-de-python-iv-es-autodocumentado.html","title":"Cosas que AMO de Python IV: es autodocumentado"},{"text":"Python, al igual que Java, es un lenguaje que soporta Orientación a Objetos. Con la diferencia de que en Java, aún tenemos tipos primitivos (bool, int, float, double) y sus respectivas clases envoltorio (Integer, Float...). En Python, no existe tal cosa como \"clases envoltorio\", Python todo lo ve como un objeto, cualquier variable que uno inicialice, es un objeto, sin importar si es una cadena de caracteres, un número, una instancia de una clase, todo es un objeto, incluso una función o un método de una clase pueden ser asignados a una variable pues, al fin y al cabo, también son objetos. Esto me permite hacer cosas como lo siguiente: En el código anterior, escribí una función con la definición recursiva de la sucesión de fibonacci (por ser un algoritmo ya bien conocido por la mayoría de quienes estudiamos algún curso de programación en la universidad). Posteriormente, asigno esa función a una variable (nótese que no utilicé los paréntesis cuando hice referencia a la función) y, simplemente, para llamar a mi función fibo , le paso los parámetros al objeto función , referenciado por la variable f . Una vez que internalizamos el hecho de que, para Python, todo es un objeto, ganamos un poder increíble a la hora de escribir nuestros programas y tratamos de darle a las cosas un enfoque diferente. ¿Para qué puede servir eso?, en otro artículo les cuento ;-)","tags":"Blog","loc":"http://localhost:8000/cosas-que-amo-de-python-iii-todo-es-un-objeto.html","title":"Cosas que AMO de Python III: todo es un objeto"},{"text":"Cada lenguaje y cada herramienta vienen con una filosofía y, al parecer, con una manera de pensar. Los que usamos Linux pensamos de una manera, por ejemplo, estamos muy orientados al software libre. Quienes usan Windows piensan de otra manera muy distinta y quienes son usuarios de las herramientas de Apple (Mac OS, siguiendo con los Sistemas Operativos), tienen su propia manera especial de pensar y ver la vida. Lo mismo ocurre con los lenguajes de programación, cada programador, dependiendo del lenguaje, desarrolla una manera de ver las cosas diferente, adaptada, quizás, a cómo implementa los conceptos su herramienta de trabajo diario (y a veces de entretenimiento ocasional). La filosofía de Python, está resumida en el Zen de Python . Para leerlo, sólo basta abrir un Terminal de Python y escribir: import this. Al presionar \"enter\" parecerá el siguiente texto: The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! Lo que traducido al español, para quienes no hablan inglés, rezaría de la siguiente manera: El Zen de Python, por Tim Peters Hermoso es mejor que feo. Explícito es mejor que implícito. Simple es mejor que complejo. Complejo es mejor que complicado. Plano es mejor que anidado. Disperso es mejor que denso. La legibilidad es importante. Los casos especiales no son lo suficientemente especiales como para romper las reglas. Sin embargo, la practicidad prevalece ante el purismo. Los errores no deben pasar silenciosamente. A no ser que sean explícitamente silenciados. En caso de ambigüedad, evita la tentación de adivinar. Debería haber una-- y preferiblemente una --manera obvia de hacer las cosas. Sin embargo, esa manera puede no ser tan obvia, a menos que seas holandés. Ahora es mejor que nunca. Sin embargo, nunca puede ser mejor que *ahora mismo*. Si la implementación es difícil de explicar, entonces es mala idea. Si la implementación es fácil de explicar, puede ser una buena idea. Los namespaces son una excelente idea -- hagamos más de esos! Realmente es una filosofía excelente y, una vez que la internalizas, tu código cambia de manera radical. Mi recomendación es: tómenla como forma de vida y traten de aplicarlo en todo y piensen en eso mientras programan. Háganlo su propio mantra y ténganlo siempre en cuenta, no sólo a la hora de \"echar código\".","tags":"Blog","loc":"http://localhost:8000/cosas-que-amo-de-python-ii-su-filosofia.html","title":"Cosas que amo de Python II: Su Filosofía"},{"text":"Bueno, ya que estoy trabajando con Python, he podido ir, poco a poco, explorando las capacidades de ese lenguaje, es realmente poderoso y, tal como una droga, su uso excesivo produce adicción. No pretendo convertirlo en el único lenguaje que usaré pero si me enfocaré en explorarlo y explotarlo por un tiempo -- creo -- bastante largo. Haré una serie de artículos explicando algunas de las características que más me gustan de Python utilizando algunos ejemplos básicos. Una de las cosas que descubrí que existía cuando empecé a programar en Python, fue el concepto de List Comprehension que nunca lo llegué a ver y aunque puede llegar a implementarse, resulta un poco rebuscado y complicado. y nunca tan intuitivo como en Python. El concepto de Comprensión de Listas (Lists Comprehension en inglés) viene de la Programación Funcional y consiste en generar una lista a partir de filtros y una expresión generadora, tal cual como se definen, en Matemáticas, los Conjuntos por Comprensión. Empecemos con un ejemplo sencillo, supongamos que quiero generar una lista que contenga los números hasta el número 300.000. En Java o en C, necesitaría iterar con un for, revisar si el número es par (número % 2 == 0) e incluirlo en la lista resultado para luego retornar, unas 5 o 6 líneas de código, podría hacerlo así también en Python, pero teniendo una característica tan poderosa como la comprensión de listas, no tiene mucho sentido. El mismo ejercicio en Python, utilizando Comprensión de listas, quedaría de la siguiente manera: No hace falta ser un experto en Programación Funcional, ni mucho menos haber programado en Haskell o Erlang para darse cuenta de lo que ocurre en esa simple línea de código. Simplemente generamos una lista de valores desde el 0 hasta el 300.000 e incluímos el valor en nuestra nueva lista sólo si es par. Ahora bien, en la Programación Funcional, un algoritmo deja de verse como una sucesión de pasos y empieza a verse como una transformación sucesiva de datos , es decir, las funciones hacen mapping de los los datos que manipula mi programa hacia otros, derivados de la manipulación de la información del programa a través de ciertas operaciones de cómputo. Lo que quiero decir con esto es que, a través de comprensión de listas, puedo también tomar los elementos de la lista que voy a generar y aplicarles una función antes de retornarlos. La función map en Python, aplica una función pasada como argumento a un conjunto de datos, pasado también como argumento: En este ejemplo, la lista a contendrá una nueva lista con las longitudes de las cadenas contenidas en words , mientras que la lista b contendrá las mismas cadenas pero con todos los caracteres en mayúscula sostenida. La manera de realizar ese ejercicio utilizando Comprensión de Listas, es la siguiente: Es el mismo resultado, pero aplicando una función a una Comprensión de Listas. Finalmente, podemos generar Listas por Comprensión tan complejas como queramos, la imaginación es el límite, veamos este último ejemplo sencillo, utilizando todos los elementos que me permite una comprensión de listas (también puedo anidarlas): aplicar una función al retorno, una expresión generadora y una expresión filtro: A manera de ejercicio, hagan lo mismo pero utilizando ciclos, verán que es mucho más complicado una vez que conocen ya la magia de la Comprensión de Listas.","tags":"Blog","loc":"http://localhost:8000/cosas-que-amo-de-python-i-lists-comprehensions.html","title":"Cosas que amo de Python I: Lists Comprehensions"},{"text":"Java, C, C#, ,C++, PHP, Perl, Ruby, SQL, SmallTalk, Erlang, Python, Haskell... Existen muchísimos lenguajes de programación, cada uno con sus fortalezas y debilidades, ya aprendí Java en la Universidad, también C, he hecho uno que otro proyecto web en PHP, \"¡con JQuery y todo!\". ¿Por qué debería aprender un lenguaje nuevo?, todos hacen lo mismo al final, ¿o no?. Ciertamente, lo que puedes hacer en Java, puedes hacerlo en C# o C++, por ejemplo. De igual manera, lo que puedes hacer utilizando PHP, puedes hacerlo programando en Ruby o en Perl o en Python. El detalle está en que al pasar mucho tiempo programando en un mismo lenguaje, dejamos de ser programadores y empezamos a convertirnos en \"usuarios de un lenguaje\", y pretendemos solucionar todo utilizándolo, aún cuando, quizás, existe una herramienta que nos permitiría hacer exactamente lo mismo, pero con la mitad del esfuerzo y la cuarta parte de las líneas de código. Debo dejar claro que \"Qué tan buén programador eres\" no es algo que se mida por la cantidad de lenguajes que sabes o, al menos, conoces y en los que puedes defenderte, sino en la capacidad que tengas de seleccionar el que más se adapte a la solución del problema que tienes en frente actualmente y en tu habilidad de llevar conceptos de un lenguaje a otro sin mucho problema. Siempre he dicho que sólo hay una cosa peor que un mal programador, y es un programador que sólo conoce un lenguaje y no es capaz de adaptarse a nuevas herramientas. A la hora de desarrollar un sistema, siempre es deseable tener un repertorio amplio de opciones para seleccionar la herramienta que más nos guste para atacarlo y empezar a programar. Muchas veces, las mismas características del problema nos obligan a trabajar con una herramienta, por ejemplo, si vamos a desarrollar un driver para una impresora o una tarjeta de sonido, no hay más opción que C. Pero si el problema es más flexible, tenemos una gama más ámplia de pinturas para empezar a colorear nuestra obra de arte. Si es web, puede que salga bien con PHP, ¿por qué no usar un Framework para hacernos la vida más fácil?: PHP + Symfony o Python + Django o Web2py, Perl + Catalyst (¿alguien?), si es una aplicación de escritorio, ¿por qué no utilizar Java?, o quizás Python + PyGTK o PyQt. Nuevas herramientas y nuevas maneras de hacer las cosas, si las entendemos y las asimilamos de manera correcta, nos hacen mejores programadores, uno como desarrollador, debe ser curioso y no sólo aprender a utilizar la herramienta, también explorarla y ver realmente cómo funciona por dentro. Sólo así, sabremos cuán óptima y realmente qué tan buena es dicha herramienta.","tags":"Blog","loc":"http://localhost:8000/por-que-aprender-un-nuevo-lenguaje.html","title":"¿Por qué aprender un nuevo lenguaje?"},{"text":"Bien, Oracle compró Sun hace un tiempo ya; todos los sabemos. Oracle tiene un esquema de negocios del tipo \"si no me genera ingresos, no lo hago\", mientras que Sun tenía un esquema de negocios un poco más abierto: desarrollaban y mantenían, en colaboración con las comunidades de usuarios, muchos proyectos enfocados al Software Libre (MySQL, NetBeans IDE y Open Solaris son algunos de los ejemplos más conocidos, así como también el popular servidor de aplicaciones Glassfish para Java). Todos esperábamos que ocurriera lo que ha venido ocurriendo poco a poco entre Oracle y los proyectos libres que mantenía Sun Microsystems: los proyectos que aún son mantenidos por Oracle son el producto de acuerdos y compromisos adquiridos previamente por Sun; los demás fueron cerrados, como el caso de OpenSolaris, un Sistema Operativo que brindaba todas las bondades de Solaris al mundo libre: fue convertido en Solaris Express, también gratuito ---pero con una licencia más restrictiva, pues---. Mientras Open Solaris podía ser utilizado \"como uno quisiera\", las ediciones Express de Oracle vienen con funcionalidad reducida y no pueden ser usadas en ambientes de producción. Desde el inicio, Oracle llegó \"cortando cabezas\". A pocas semanas de concretarse la compra, todos los que seguíamos Java y éramos fieles programadores y usuarios de ese lenguaje, nos enteramos de la renuncia de James Gosling, su creador. Uno de los primeros indicios de que el futuro de Java era incierto. El JDK de Java tenía una licencia que permitía que cualquier empresa que desarrollara un Sistema Operativo pudiera empaquetarlo para el mismo sin ningún problema. Por ello, vemos implementaciones distintas de la máquina virtual y del JDK, como el OpenJDK y Dalvik (la máquina virtual de Java optimizada para móviles desarrollará para Android). Hace unos días, Oracle eliminó esa licencia, por lo que sistemas como Linux, tendrán ahora que utilizar únicamente el OpenJDK, que aún tiene algunos problemas con tipografías y Applets. Al paso que vamos, Oracle seguirá cerrando cada vez más las puertas al mundo libre, y quién sabe si algún día empiece a cobrar una tarifa por el uso de su Máquina Virtual. Muchos programadores Java, hemos migrado ya a otros lenguajes, en mi caso debido al futuro incierto del lenguaje y las herramientas. Todo parece estar dibujando un futuro no muy bueno para este lenguaje (que era uno de mis favoritos): si Oracle continúa cerrándolo cada vez más, parece estar destinado a desaparecer. Una verdadera lástima.","tags":"Blog","loc":"http://localhost:8000/java-cronica-de-una-muerte-anunciada.html","title":"Java: crónica de una muerte anunciada"},{"text":"Bien, si estás en los últimos semestres de Ingeniería Informática, eso significa que has sobrevivido al ataque de los cálculos, lograste controlar la rebelión de las físicas, dominaste con experticia el asedio de los algoritmos, batallaste arduamente y, ahora, sólo quedan un par de ciclos por cerrar al culminar la carga académica: Servicio Comunitario, Tesis y Pasantía. Mucha gente (incluyéndome) suele sentir algo de miedo al llegar al 9no semestre de la carrera, pues significa que debes empezar a pensar en ciertas cosas: ¿en qué área te ves trabajando? ¿de qué vas a hacer tu trabajo especial de grado? Más aun: ¿tesis o pasantía larga? ¿dónde voy a hacer mi pasantía corta? Muchas cosas en mente y muy poco tiempo si son como yo, que dejé todo eso para última hora. Pero no desesperen, todo tiene una solución, es sólo cuestión de actitud, por lo que me tomaré la libertad de ser un poco informal en este artículo. Voy a tratar de darles algunos consejos basándome en mi experiencia personal en esa etapa (reciente, por cierto) de mi vida: A lo largo de la carrera, deben preocuparse por no ser \"sólo estudiantes\". Está bien dedicarse a la carrera ---y, si son \"Eficiencia 1\", pues, mucho mejor---, pero la magia de todo está en tratar de compaginar esa excelencia académica con otras actividades en las que puedan desarrollar otras aptitudes y aprender nuevas herramientas. Por ejemplo, yo soy una persona sumamente tímida, bastante callado a decir verdad; a veces me cuesta interactuar con otras personas (puede ser un mal de carrera). Eso, en el campo profesional, no es muy deseable que digamos, sobre todo porque hay una entrevista de trabajo en la que deben desenvolverse bien si quieren obtener el empleo, muchas veces nos tocará trabajar en equipo con otros desarrolladores y líderes de proyecto o, quizás, interactuar con clientes (miedo, terror, ¿pánico?). ¿Cómo hice para sobrellevar eso? Pues la respuesta es simple: enfrentándolo. Me inscribí para ser preparador de mi escuela, en la cátedra de Algoritmos y Programación II, ya que allí se estudian estructuras de datos en Lenguage C, uno de mis favoritos, por lo que pensé que podría hacerlo bien. Al final del semestre, no me fue tan mal en las encuestas y recibí muy buenos comentarios, además, me empecé a sentir más cómodo hablando en público, así que empecé a inscribirme en otras actividades: Centros de Estudiantes y Representación Estudiantil: en la temporada de campañas, uno habla con mucha gente y debe debatir con otros candidatos, eso me ayudó a desarrollar un poco de coherencia en el discurso y a mejorar la capacidad de acercarme a la gente. Fui Consejero de Escuela y Consejero de Facultad, eso también me ayudó con mi problema para hablar con la gente. Sun Team University e IEEE-UCAB: como miembro de esas sociedades técnicas estudiantiles, debía dar charlas, lo que implicaba hablar en público. Pertenecer a estas organizaciones me permitió desarrollar aptitudes para exponer y explicar temas técnicos de mi elección a un público. Muy parecido a ser preparador, pero, esta vez, el contenido y todo el esquema lo seleccionaba YO. Participar en actividades de este tipo también te acerca un poco a las autoridades de tu escuela y de tu facultad, de quienes puedes aprender muchísimo y a quienes puedes acudir en caso de necesitar orientación académica de algún tipo o un consejo. Cuando digo que traten de no ser \"sólo estudiantes\", también hago referencia a que no está mal conseguir un trabajo de medio tiempo o a distancia. Tuve la suerte de trabajar en Es|Noticia.com , un concentrador de noticias donde aprendí un enfoque distinto de los desarrollos web, también en el IAMJ (Instituto Autónomo Metropolitano para la Juventud), un organismo gubernamental adscrito a la Alcaldía Mayor (cuando existía) en el que aprendí que si te dicen que serás el Web Master y además, eres el único en la parte de IT, debes tener cuidado. Terminarás configurando servidores y redes, montando la intranet, instalando Windows, lidiando con todos los virus y \"errores de capa 8\" del lugar y trabajando en la página web en sus ratos libres en la Universidad o en casa. Todas estas cosas les darán la experiencia que no tendrán simplemente asistiendo a sus clases programadas, estudiando para los exámenes previstos y desarrollando los proyectos asignados, pero todo lo anterior les dará los conocimientos y las aptitudes para poder salir a ganar experiencia en la calle así que siempre una cosa viene a complementar a la otra. Finalmente, las temidas obligaciones de final carrera: Tesis, Pasantía y Servicio Comunitario: Para el Servicio Comunitario, piden 120 horas. Traten de hacer algo que no les consuma mucho tiempo y en lo que no vayan a ganarse un \"contrato vitalicio de mantenimiento gratis\" ciertamente hay muchas organizaciones sin fines de lucro que necesitan urgentemente una página web, un sistema de gestión de <inserte aquí cualquier cosa gestionable>, pero muchas veces no saben lo que eso implica y se aprovechan de la necesidad del estudiante por terminar el servicio comunitario así que, si se embarcan en uno de estos proyectos, asegúrense de dejar todos los puntos claros y un alcance bien definido desde el principio. La pregunta eterna: ¿Tesis o Pasantía Larga?. Considero que es una decisión muy personal. Particularmente pienso que como estudiantes de una carrera de corte científico, como lo es la Ingeniería Informática, un Trabajo Especial de Grado (Tesis o TEG) debería ser la única opción, existen demasiados temas de investigación poco explorados, muchas tecnologías que no estudiamos durante la carrera y la tesis es una oportunidad excelente para explorarlos. Algunos consejos para seleccionar un tema de tesis: No tienen que descubrir el agua tibia: recuerden que es una tesis de pre-grado, si bien hay que ser innovadores, no se trata de poner un satélite en órbita o volverse un experto en derivación de forlayos para tener un buen trabajo de grado. Los temas de Inteligencia Artificial Bioinspirada son muy buscados y, además, ya existen muchos trabajos en esa área, incluso en pre-grado. Traten de buscar otros temas interesantes: Social Media, Web Semántica, Data Mining, Web Mining, Orquestación de Servicios Web, Procesamiento de Lenguaje Natural. Alguna manera de acercar el conocimiento académico al mundo real, por ejemplo. No tengan miedo en desarrollarla solos, si no consiguen pareja para desarrollar su tesis, no se ajusten a lo que quiera hacer otra persona, al final la gran satisfacción radica en trabajar en los que nos gusta o nos apasiona. En mi caso, mi tesis la desarrollo de manera individual, en el área de Web Semántica pues me parece un tema súper interesante y no hay antecedentes de trabajos en esa área en mi universidad (UCAB Caracas). Finalmente, la pasantía, para muchos, será su primer acercamiento al mundo laboral, otros quizás tuvieron algunos empleos o desarrollaron algún sistema por su cuenta durante la carrera (Metodología del Software en la UCAB, ¿alguien?). Lo importante de la pasantía es conseguir un lugar donde puedan crecer profesionalmente y donde puedan tener la oportunidad de quedarse trabajando. Muchas empresas buscan pasantes para terminar desarrollos internos o para realizar trabajos que más nadie quiere hacer y luego, simplemente, olvidarse de ellos. Obviamente, si lo que quieren es aprender y crecer en el proceso, esta no es una opción. Algunos consejos para la pasantía: Busquen más que una pasantía, traten de conseguir un lugar donde puedan quedarse trabajando y déjenlo claro en la entrevista. En mi caso, siempre dije que en realidad estaba buscando trabajo, mi visión de la pasantía es la puerta de entrada al mundo laboral. Si dicen que sólo quieren hacer pasantía, pueden pasar por conformistas. Durante la pasantía, hagan su trabajo lo mejor posible. No tengan miedo de preguntar algo si no saben, y tómense su tiempo para entender las cosas y desarrollarlas lo mejor posible. Es mejor calidad que cantidad. Además, lo más seguro es que en realidad manejen el concepto, pero no sepan aplicarlo correctamente de manera práctica lo cual, usualmente para los jefes, es comprensible en alguien que está empezando en el mundo laboral. Siempre es bueno aprender cosas nuevas, pero soy de los que piensa que, primero, debemos perfeccionar nuestras habilidades con las herramientas con que trabajamos a diario. Si trabajan con un lenguaje de programación determinado, investiguen y exploren qué otras posibilidades ofrece; enfóquense primero en lo que utilizan en la oficina, esto les permitirá completar sus obligaciones de manera más rápida y les dejará más tiempo libre para aprender nuestas herramientas (desarrollo de videojuegos, otros frameworks para desarrollo web o quizás algún proyecto personal). Envíen su hoja de vida a varias empresas, sin importar cual sea, muchas veces la vida da sorpresas y el lugar que menos se imaginan es el que les ofrece su trabajo ideal. En mi caso, cuando estuve buscando pasantía, envié mis papeles a Microsoft, IBM y Vauxoo. En Microsoft me ofrecían participar, como pasante, en un desarrollo interno, básicamente el proyecto era automatizar la organización del material corporativo y académico de Microsoft de Venezuela, más allá de eso, me ofrecían la figura de \"Pasantía Corporativa\", que, en pocas palabras es \"El pasante eterno\", por otra parte, Vauxoo me ofrecía una oportunidad real de trabajo y el apoyo para introducir mi primer proyecto como pasantía en la Universidad. Hoy resulta obvio que decidí trabajar en Vauxoo, la razón principal es que es una empresa que trabaja 100% son Software de Código Abierto. Al trabajar con herramientas OpenSource y aprovecharse de ese ecosistema, no hace falta tener mucho sentido común para darse cuenta de que lo moralmente correcto es retribuir de la misma manera, por lo que cada línea de código que se escribe en Vauxoo, es liberada a través de Launchpad . Además, me ofrecían trabajar con un lenguaje de programación distinto (Python) y al que siempre le había tenido el ojo puesto y nunca, en la universidad, tuve la oportunidad de dedicarme aprender. Esta oportunidad se adaptaba más a mi perfil y fue por ello que, al final, decidí rechazar la oportunidad en Microsoft. Al final, lo que importa es que se sientan cómodos en el lugar donde estén haciendo la pasantía y, si esto es así, que la empresa pueda ofrecerles la oportunidad de quedarse trabajando si consideran que su trabajo es de calidad y siempre llevar una toalla, uno no sabe si el mundo se acaba antes que la carrera.","tags":"Blog","loc":"http://localhost:8000/sobreviviendo-a-la-carrera-algunos-consejos.html","title":"Sobreviviendo a la Carrera: algunos consejos"},{"text":"Parecieran estar de moda las demandas por \"violación de patentes\" en el mundo de la tecnología. Corres el riesgo de ser demandado por las cosas más inverosímiles, como por ejemplo \"la manera de hacer click en tu producto es muy parecida a como es en el mío\", por temas de diseño, entre otras cosas. Escribo sobre patentes en el mundo de la tecnología, no porque sea un experto en el tema, o porque me apasionen, mucho menos pretendo dar una clase magistral sobre qué son patentes y para qué sirven pues creo que el nombre habla por sí solo, simplemente, para que estemos claros de qué estamos hablando, daré una breve definición: Una patente es un derecho negativo que otorga un Estado a un inventor o a su causa habiente durante un tiempo limitado. Pues bien, esa es una definición bastante básica, pero para el objetivo de este artículo, me basta. Una patente, permite al titular impedir a terceros hacer uso de la tecnología que él ha patentado. Bajo esos términos, el único que puede hacer uso o beneficiarse de la tecnología es el titular de la patente u utros entes que él autorice mediante contratos de licenciamiento hasta la caducidad de la patente en cuestión (actualmente las patentes duran alrededor de 20 años). Todo pinta muy bonito, las patentes entonces, deberían servir como una recompensa al investigador o al inventor por invertir su tiempo en desarrollar \"algo\" que nos hará la vida más fácil, pero desde que la mayoría de las patentes están en manos de grandes empresas, se han convertido en una estrategia corporativa para frenar, no sólo a la competencia, sino también el avance tecnológico en el campo en que se está registrada la patente pues, usualmente, los costos de licenciamiento son enormes y no resulta rentable normalmente, a menos que seas otra gran empresa. Vemos casos como el reciente Apple-Samsung, en que la juguetería de Cupertino demanda a la empresa coreana, puntualizando que el diseño del modelo Samsung Galaxy S es muy parecido al del iPhone y el diseño del Samsung Galaxy Tab 10.1 es muy parecido al del iPad. ¿Puede patentarse algo tan burdo como la apariencia de algo?, ¿qué hubiera pasado si Jimmi Hendix hubiera patentado el afro?. Esta demanda, por ridícula que parezca, logro hacer que se prohibiera la venta de los Galaxy Tab 10.1 en los Estados Unidos, Australia y Europa (a excepción de Holanda, allí la marihuana es legal así que son especiales). Otro caso, las múltiples demandas del gigante ORACLE a, otro gigante quizás más grande: Google, por violaciones a las licencias del Java Virtual Machine en su sistema operativo Android. Ambos casos se están resolviendo, por un lado, ya fue aprobada la venta de las Tablet PC de Samsung en Europa y no debe faltar mucho para que sea así en el resto de los países que la prohibieron, sin lugar a duda, Apple logró su objetivo: frenar el avance implacable de la competencia que le ha desplazado del 2do lugar en el mercado de dispositivos móviles. Por otro lado Google parece estar trabajando en migrar la plataforma Android a Python, un lenguaje que ellos mismos están desarrollando junto a Güido Van Rossum (creador del lenguaje a inicios de los 90). Claramente, las patentes, lejos de estimular el desarrollo, lo que logran es frenarlo e, incluso, condenar a la muerte tecnologías realmente potentes, como Java, pues ante tantas trabas producto de las patentes y licencias, muchas empresas e individuales buscarán otra alternativa, si bien no de un día para otro, si se ve en un futuro a mediano plazo. Quiero terminar, citando un escrito de TechDirt , en el que se hacen la pregunta: ¿Qué pasaría si Tim Berners-Lee hubiera patentado la web?: Además de que su nombre sería más conocido, la Web, no sería lo que conocemos hoy día, sólo grandes corporaciones tendrían acceso a ella y no las grandes que conocemos hoy día, sino los potentados de aquella época como AOL, Compuserve y Delphi. ¿Google?, ¿qué es eso?, la búsqueda en Internet sería a través de uno o varios sistemas privativos de búsqueda y el acceso depende de quién te provea el servicio y de la compatibilidad entre él y el site al que pretendes entrar, además, tecnologías como AJAX e información en tiempo real estarían en pañales hoy día o, simplemente, no existirían, de igual manera los populares SmartPhones de hoy día, no tendrían acceso a internet lo cual, no tendría sentido y, si hoy son caros, bajo esas condiciones un teléfono celular con acceso a la web costaría \"algún órgano vital del cuerpo\". Entonces, ¿qué tanto nos benefician las patentes?, ¿qué tanto se benefician las empresas de las patentes?, claramente mucho pero, en igual medida, estas patentes perjudican a investigadores en el área y el avance en materia tecnológica, dentro de poco veremos demandas \"porque tu producto también tiene botones y usa una pantalla táctil\", así que... FUCK OFF patent trolls.","tags":"Blog","loc":"http://localhost:8000/patentes-hasta-cuando.html","title":"Patentes... ¿hasta cuándo?"},{"text":"Bueno, llevaba tiempo formándome una imagen mental de cómo sería un buen programador, pensé en estupideces como paciencia, constancia, perseverancia, espíritu de equipo, empatía. Lo cierto es que ninguno de los buenos programadores que conozco son así. En fin, en estos días, Francisco Palm (@mapologo en Twitter) me iluminó enunciando las tres virtudes del buen programador de Larry Wall : Flojera: es una virtud que te estimula a reutilizar la mayor cantidad de código posible (propio y de otros), programar de manera modular de manera de no escribir lo mismo dos veces y no reinventar la rueda (a menos que quieras saber cómo funciona por mera curiosidad académica ;-) ). Si ya está hecho y funciona, ¿para qué volverlo a hacer? Impaciencia: si hay algo peor que un programa que no corre, es un programa que corre lento, hay que, siempre, buscar la manera más óptima de hacer las cosas, no podemos perder el tiempo escribiendo, probando (y que corra lento) y corrigiendo (y que corra aún más lento porque el código es parche tras parche), tenemos que escribir buen código y hacerlo rápido. Soberbia: si, orgullo desmedido, escribimos buenos programas, utilizando las mejores prácticas y las mejores herramientas para que no puedan ser criticados, y más aún si desarrollamos bajo un esquema OpenSource, nuestro código es nuestra carta de presentación hacia el mundo y no podemos permitir que nos haga una mala imagen. Definitivamente todos tenemos un poco de esto, Flojera, si, muchas veces ¿para qué ir al sitio si podemos hacerlo remoto gracias a la magia del ssh? o ¿para qué hacerlo si ya está hecho y funciona bien?, Impaciencia, programa rápido y que funcione pronto. Soberbia, hazlo bien para que, lejos de criticarte, te elogien. Parece funcionar bien en el ámbito profesional, en el ámbito personal, existimos mortales que, a veces, no sabemos controlar estas virtudes. ;-)","tags":"Blog","loc":"http://localhost:8000/virtudes-del-buen-programador.html","title":"Virtudes del buen programador"},{"text":"Esta entrada será corta. En el artículo anterior, nombré las 4 libertades fundamentales de las que gozamos los felices usuarios del Software Libre, desde la libertad 0 hasta ha libertad 3. Pero olvidé una muy importante que, si bien no es oficial, siempre la agrego cuando hablo de este tema. Hablo de la quinta libertad, la libertad 4 (recuerden que empezamos desde 0), la Libertad de Elegir, libertad de seleccionar qué queremos utilizar, ok, tenemos un sistema operativo: Linux, pero tenemos además cientos de distros disponibles para escoger cuál queremos, gestor de paquetes dpkg o basados en rpm, ok, pero ahora quiero algo listo \"out of the box\" o algo que pueda configurar y adaptar, bueno, ahora, ¿qué interface gráfica quiero?: ¿KDE?, ¿Gnome?, ¿XFCE?, ¿Fluxbox?, ¿realmente quiero utilizar una GUI?. Esta historia se repite desde para seleccionar un reproductor multimedia (Rythmbox, VLC, MPlayer, Amarok), hasta para seleccionar algo tan simple como un editor de texto plano (gedit, kate, emacs, vim), tenemos cientos de opciones de donde poder escoger, eso es Software Libre.","tags":"Blog","loc":"http://localhost:8000/software-libre-la-quinta-libertad.html","title":"Software Libre: La Quinta Libertad"},{"text":"Muchas veces, hablando de computación y tecnología, mis amigos y familiares me preguntan qué tengo yo en contra de Windows específicamente, y siempre respondo \"nada\", y es verdad, no tengo nada en contra de Windows o Microsoft, sino del esquema de negocios basado en Software Privativo, y esto suena medio comunistoide pero no me importa porque quienes me conocen saben que no lo soy. Y es que la razón por la que los detractores del software libre defienden y promueven al software privativo, aún sin trabajar para alguna compañía que lo produzca, son realmente absurdas. La principal de ellas, y la que más me molesta en ocasiones, es el típico mito: ¿software libre?, ¿gratis?, yo quiero hacer plata con software y con algo gratis no se puede , si, creanlo o no, me lo han dicho bastante. Para comenzar, permítanme decirles que quien piense y esté seguro de que Software Libre es igual a Software Gratis, está equivocado. Ciertamente, gran cantidad de Software Libre está disponible en la web de manera gratuita, pero también lo está una gran cantidad de Software Privativo, a los programas que son liberados de manera gratuita, se les conoce como freeware. Entonces, si Libre <> Gratis, entonces ¿qué es Software Libre?. Software Libre, en su definición más purista es aquel que cumple con las cuatro libertades: Libertad 0: libertad de usar el programa para cualquier propósito. Realmente no importa si vas a utilizarlo en tu casa, en tu oficina, vas a vender una instalación, puedes utilizarlo sin ningún problema. Libertad 1: libertad de estudiar como funciona el programa, modificarlo y adaptarlo a tus necesidades. Si vas a utilizar un software, y más aún si pagas por él, debes poder conocerlo a fondo y si eres usuario técnico, deberías poderlo modificar y adaptarlo a lo que realmente quieres que haga, si no puedes adaptarlo a tus necesidades entonces mejor no usarlo. Libertad 2 : libertad de hacer copias del programa y distribuirlas a tus amigos. Si algo es bueno, obviamente quieres que otras personas lo usen y se beneficien de él. Libertad 3: libertad de hacer públicas las modificaciones que hagas para que toda la comunidad se beneficie. Si eres usuario técnico de un software del que te beneficias en tu día a día personal o laboral, te conviene que mejore para incrementar tu productividad. Por ello, si descargo de internet un programa gratis y no tengo acceso al código fuente, no estamos hablando de Software Libre, aún cuando sea de distribución gratuita. Entonces, si desarrollas software libre y vendes tus aplicaciones, debes, al menos, incluir el código fuente y no restringir su uso. Entonces, ¿cómo se hace dinero con software libre?, no es el programa, sino el soporte que le das, cualquiera puede desarrollar \"el programa del siglo\", pero si el soporte y la documentación no sirven, entonces ¿quién querría usarlo?. Cualquier persona puede descargarlo, estudiarlo y utilizarlo si lo desea, pero para configuraciones más avanzadas (igual que con el software privativo) tendrá que llamar a un especialista. De la misma manera si se desea una modificación sobre el programa original, si tienes el tiempo y el personal para hacerlo, puedes descargar las fuentes, estudiarlo y modificarlo, sino, igual tendrás que llamar a un especialista que ya haya hecho este trabajo. Si trabajas con software libre, no vendes un programa, vendes una solución completa con un acuerdo de soporte, ahorrándole al cliente y a tu compañía los costes de licenciamiento. Otro de los mitos urbanos sobre el software libre es que si no tiene una súper compañía por detrás, no puede ser bueno . Históricamente, existen muchas compañías que desarrollan Software Libre, por ejemplo IBM y Novell son dos de las que más han contribuido con el kernel de Linux, si bien es cierto que el software libre se desarrolla de manera comunitaria, muchas de las empresas que venden soluciones basadas en software libre, tienen un staff de programadores dedicados a liberar código fuente a la comunidad, entonces, no es una súper compañía , son muchas grandes, pequeñas y mediadas empresas dedicadas al desarrollo de la herramienta alrededor del mundo. Finalmente, el más grande de los mitos, ya un poco más de usuario final: es más difícil de usar , esto es totalmente falso, pongamos el ejemplo típico: Windows vs Linux, nadie nació sabiendo utilizar Windows, sin embargo, todos lo usan porque es lo que viene preinstalado en la mayoría de las computadoras de marca (en nuestro país, lo venden \"como tu película\" en los clones que usualmente uno compra), en algún momento de nuestras vidas, tuvimos que haber invertido unos días aprendiendo, poco a poco, a utilizarlo. Exactamente lo mismo ocurre con Linux, si bien existen distros para usuarios técnicos (como Gentoo, Slackware y CentOS), también existen muchas enfocadas al usuario final (como la familia *buntu, Fedora y Simplis), simplemente es cuestión de decidirse, probarlo y usarlo sin miedo.","tags":"Blog","loc":"http://localhost:8000/software-libre-teoria-y-practica.html","title":"Software Libre: Teoría y Práctica"},{"text":"No me considero un experto en el área de Sistemas Operativos, mucho menos en el área de Sistemas Operativos para dispositivos móviles, es por ello que titulo y aclaro que este post expresa mi humilde opinión acerca de un tópico que pareciera estar en boga últimamente, en este caso, para quienes me conocen, creo que es obvio hacia dónde se inclina mi balanza personal. No suelo entrar mucho en polémicas acerca de cuál herramienta es mejor que otra, a excepción de casos muy especiales como este, en el que leí una reseña de Clayton Morris a la que llegué gracias a Slashdot , pueden conseguir la reseña aquí en caso de que quieran leerla. Haré el intento de ser lo más objetivo posible. Realmente no se quién le dijo a este señor que era un experto en materia de tecnología, de hecho no sabía quién era antes de leer su \"reseña\", la cual, como pueden ver, despertó en mi cierto sentimiento de profunda molestia (por no decir ARRECH...). Muy mal por Fox News al publicar escritos de este tipo y, además, redactados por personas no especialistas en el tema. Es como si Andrew Tanenbaum criticara un libro de recetas de Sumito Estévez, pero bien, basta de descarga y pasemos a hablar de lo que nos importa. Comencemos por lo básico, los sistemas operativos que corren ambos dispositivos, podemos tener una súper computadora en la que invertimos $3000 para hacerla correr como un Jet, pero no será lo mismo instalarle Windows Vista que algún Linux, el Sistema Operativo influye mucho en el rendimiento y en la experiencia de usuario con un dispositivo, así que es una métrica importante para esta comparación. Por un lado el iPad con iOS, un desarrollo privativo de Apple , el cual sólo corre en dispositivos que, además, ellos mismos fabrican, esto garantiza que el software y el hardware se integren de manera mágica y casi orgásmica pues es prácticamente un Sistema Operativo custom , hecho a la medida para los dispositivos que lo corren, muy al estilo de la empresa de Cupertino. Por otro lado, tenemos el Samsung Galaxy Tab corriendo Android, un sistema operativo libre y de código abierto desarrollado en principio por Android INC que, posteriormente, fue adquirido por el gigante Google, pero no para destruirlo e imponer su ChromeOS , sino para desarrollar uno de los sistemas operativos móviles más potentes del mercado actual, especial para Teléfonos Celulares y Tablet PCs, Chrome OS será optimizado para NetBooks. Android es liberado bajo licencias Apache y GPL 2.0, que permiten que cualquier persona pueda descargarlo, modificarlo y utilizarlo como desée, siiii!, la belleza del mundo del Software Libre , más adelante, veremos otras bondades de este esquema que aplican a usuarios de dispositivos móviles. En este caso notamos que el fabricante del Tablet y el desarrollador del Sistema Operativo, son dos empresas distintas, Android es compatible con varios dispositivos de distintas marcas como Samsung (obvio), HTC, Huawei, Motorola y LG, un punto para Android ya que es multiplataforma. Vamos al aspecto técnico de cada sistema operativo. iOS usa un kernel , privativo en su mayoría, llamado XNU . Curiosamente iOS no soportó MultiTasking sino hasta su versión 4 y, a mi parecer, su enfoque multi-tareas no es más que un \"parche\", pues lo que hacen es congelar la aplicación que no está en uso para darle paso a otra, con ciertas excepciones, por ejemplo, la música puede seguirse reproduciendo en background mientras que un navegador web se ejecuta en foreground. Esto, claramente le resta puntos al iOS, pues no puedo dejar cargando una página web mientras edito una nota de texto, ya que el sistema operativo va a congelar el proceso que corre el navegador web hasta que vuelva a su ventana, por lo tanto, también se congelará el proceso de carga del portal que desée visitar (ojo, no se si esto ya fue corregido). Por su parte, Android , utiliza un flamante kernel basado en Linux , está de más decir que soporta multitasking de manera nativa. Debido a limitaciones obvias del hardware, es necesario \"limitar\" el número de procesos en ejecución de manera concurrente, por ello, aunque Android permite hasta cuatro aplicaciones corriendo simultáneamente, esto no significa que el usuario sólo puede abrir cuatro programas al mismo tiempo. Supongamos que tenemos 4 procesos corriendo en nuestro dispositivo Android: P0, P1, P2 y P3 y queremos empezar a ejecutar P4, al solicitar la ejecución del proceso, el sistema operativo revisa cuál es el proceso menos usado y lo \"congela\" en una pila para ser invocado nuevamente al cerrar alguno de los procesos activos. Este procedimiento, Android , lo repite por cada aplicación que queramos abrir sobre las 4 por defecto que permite. De igual manera, si queremos \"resucitar\" alguna de las que se encuentra en la pila, Android revisa cuál de los procesos activos es el menos usado, lo pone a \"dormir\" y coloca el otro en la lista de procesos con permiso de ejecución. Todas estas rutinas son transparentes para el usuario y las transiciones y cambios de contexto son imperceptibles al despertar un proceso dormido. Personalmente, he abierto hasta 10 aplicaciones al mismo tiempo en mi Galaxy y lo soporta como si fueran sólo 4. Técnicamente, creo que Android gana esta otra partida, a nivel técnico, en cuanto al Software, claramente el Galaxy Tab es superior al iPad. Veamos en cuanto a aplicaciones disponibles, para el iPad , debo descargar todo del Apple APP Store , y una enorme cantidad de aplicaciones son pagas . La contraparte Android , es el Android Market , y es tan \"contra\" que una enorme cantidad de aplicaciones son Gratis , incluso el popular juego Angry Birds que en el App Store de Apple creo que cuesta $0,99 o $3, esto para el mercado venezolano representa un inconveniente dada nuestra peculiar política económica, por lo que si quiero tener juegos y \"aplicaciones chéveres\" en mi iPad , debo hacerle Jailbreak . En mi Galaxy Tab , como corre Android , tengo un total de 60 aplicaciones (llevo poco tiempo con ella), todas han sido gratis y ninguna es un trial de 90 días, además, si quieres instalar aplicaciones fuera del Android Market no hace falta rootearla , que es un procedimiento parecido al Jailbreak, simplemente configuras los permisos para instalar apps fuera del market, descargas el apk y lo instalas, como si fuera un programa más. Otro punto más para el Galaxy Tab y otra de las bondades del modelo del Software Libre. Finalmente, evaluemos el aspecto de diseño . Obviamente, la gente de Apple se esmera mucho en que sus productos sean lo más estilizados posible, por ello, no es de extrañarse que el iPad sea ultra-delgado y su tamaño sea perfecto para ser llevado dentro de un estuche tipo carpeta o en un bolso tipo mensajero. Por su parte, el Galaxy Tab , debo reconocer que, aunque tiene una pantalla de alta resolución , es más pequeño que el iPad , un poco más grueso y ligeramente más pesado , aunque todo esto no le resta portabilidad pues de igual manera puede llevarse como el iPad , debo darle los puntos de diseño al producto de nuestros amigos de Cupertino. En conclusión, sobre Clayton Morris , creo que no es más que un Apple FanBoy ciego, que, seguramente, piensa que el iCloud es la gran obra de innovación tecnológica del siglo XXI y otra muestra de la creatividad e inventiva de Apple. Ahora, ¿cuál Tablet PC debería comprarme? , es cuestión de gustos y necesidades: para mi, si quieres una herramienta poderosa de trabajo, con cientos de aplicaciones gratis , portátil totalmente customizable y configurable, te recomiendo un dispositivo basado en Android , ¿por qué no?, un Galaxy Tab . Pero si quieres un dispositivo para farandulear y presumir con tus amigos de que tienes un jueguete costoso , poderoso eso sí, pero juguete al fin, el iPad es tu opción. ;-) Nota: Opinión basada en mi experiencia con mi Galaxy Tab y el iPad de mi pana Ricardo Casanova.","tags":"Blog","loc":"http://localhost:8000/ipad-vs-galaxy-tab-mi-humilde-opinion.html","title":"iPad vs Galaxy Tab: Mi humilde opinión"},{"text":"Hace un tiempo, publiqué el primero de una serie de artículos acerca de La Web Semántica, en el que daba una introducción y exponía la visión de la W3C sobre el rumbo que debería tomar la Web en su \"versión 3.0\", si aún no lo has leido, aún estás a tiempo . En esta segunda entrega, expondré algunos conceptos que es necesario tener claros si deseas adentrarte en este nuevo mundo, así como también, daré una visión, un poco futurista (casi sacada de una película de Ciencia Ficción), de las cosas que serán posibles una vez se alcance a estandarizar todos los conceptos y tecnologías de la Web Semántica a lo ancho, largo y profundo de la World Wide Web. El primero de los conceptos que debemos tener claro es el de URI (Universal Resource Identifier) y URL (Universal Resource Locator), y las diferencias y similitudes que existen entre ellos pues, es de intuirse, que nos servirán más adelante. Luego de entender eso, podemos avanzar y adentrarnos en el mundo de las Ontologías, un concepto del campo de la Inteligencia Artificial adaptado a la Web Semántica. Una vez asimilado todo lo referente a las Ontologías, podemos irnos a estudiar algo de lógica y consultas sobre dichas ontologías para, después, ver algo acerca de Motores de Inferencia, que serán nuestro más grande aliado al desarrollar aplicaciones que implementen tecnologías de la Web Semántica. En este artículo, me concentraré en los dos primeros, es decir, URL, URI y Ontologías. Algo que parece causar mucha confusión en estudiantes, son los URI y los URL. Espero despejar cualquier duda en el siguiente párrafo: Un Identificador Universal de Recurso o URI, por sus siglas en inglés, es un elemento que nos permite simplemente saber \"quién\" es ese recurso. Si me permite identificar el recurso de manera inequívoca, quiere decir que debe ser único para cada uno. Por su parte, el Localizador Universal de Recurso, o URL por sus siglas en inglés, me permite saber la ubicación de ese recurso, debe resultar obvio que también debe ser único para cada uno pues dos recursos no pueden tener la misma ubicación. Si exportamos estos conceptos al mundo real y los aplicamos a personas, un URI podría ser su Cédula de Identidad, que no me da acceso al recurso, pero me permite saber quién es, un URL, podría ser su dirección postal + habitación en la que se encuentra (asumiendo que en Venezuela la gente vive tan cómoda que no necesita compartir cuarto con nadie) o, incluso, su número telefónico, ambos me dan acceso al recurso y, de alguna u otra manera, también me permiten conocer quién es. En pocas palabras, un URL es un URI que, además, me permite conocer la ubicación del sujeto. Es necesario tener claro todo lo anterior ya que en la Web Semántica no se habla de Páginas o Sitios Web, se busca generalizar un poco más ya que, en la Web, no sólo existen documentos HTML que dan forma a los Portales Web, sino también Videos, Fotos, documentos PDF, Música, Servicios Web, en fin, sería mucho más fácil decir qué es lo que no se encuentra en la Internet. Es por ello que la Web Semántica habla de Recursos, más allá de su tipo. Ahora bien, la Web Semántica se basa en modelos de conocimiento bien estructurado, estos modelos de conocimiento se conocen en el mundo de la Inteligencia Artificial como Ontologías. Una Ontología no es más que una representación estructurada del conocimiento de un área específica, de allí que muchos buscadores que implementan 100% tecnología de Web Semántica sean específicos para un tema dado. Estos modelos, en el ámbito que nos compete, se utilizan para describir recursos, a los cuales nos referimos mediante URI's, y, en cierta forma, darle al computador la capacidad de \"entender\" de qué habla dicho recurso y cuáles son sus recursos relacionados, de esta manera, comenzamos a construir nuestra infraestructura de meta-datos para realizar búsquedas contextualizadas y con más sentido para el usuario. La manera como una Ontología organiza el conocimiento, es a través de una estructura de meta-conocimiento. Esta estructura se construye a partir de un concepto con el cual la mayoría de los programadores estamos famimliarizados desde tempranos años de la carrera, las Clases, todo meta-conocimiento es modelable a través de Clases. Es de intuirse que se mantienen los conceptos de Herencia y Polimorfismo también dentro de las Ontologías. Por ejemplo, imaginemos una MICRO-Ontología de la Vida Salvaje de África[1]. Empezando a pensar al respecto, nos percatamos de que la sabia madre naturaleza ya nos facilitó con dos clases bien diferenciadas: \"Animales\" y \"Plantas\". Una Ontología, también me permite crear relaciones entre clases, con propócitos didácticos, imaginemos las clases \"Tallo\", \"Rama\" y \"Hoja\" que \"son parte\" de una \"Planta\", creo que la relación es bastante obvia, nuestra estructura de composición para la clase \"Planta\" sería: \"Hoja\", es parte de: \"Rama\", es parte de: \"Tallo\", es parte de: \"Planta\". Podemos complicarlo aún más, podríamos definir clases de \"Forma\" (triángulo, rombo, etc) y relacionarlas a \"Hoja\" y crear la relación \"tiene forma de\" para describir cómo es la hoja de una Planta dada, pero, por ahora, dejémoslo así. Por otro lado, la clase \"Animal\", tiene dos subclases muy fáciles de inferir: \"Carnívoro\" y \"Herbívoro\", ambas sub-clases son también \"Animales\", esto es una estructura de Herencia pues, una instancia de \"Herbívoro\" o de \"Carnívoro\" es también un \"Animal\". Nuestra estructura de Herencia para \"Animal\" quedaría así: \"Carnívoro\", es un: \"Animal\". \"Herbívoro\", es un: \"Animal\". Pero, ahora, ¿cómo se relacionan todas nuestras clases entre sí?. Bueno, a través de una relación obviamente, pero, ¿Cuál?. Bueno, un animal debe comer ¿no?. Entonces, un \"Herbívoro\" come \"Planta\" y un \"Carnívoro\" come \"Herbívoro\", también podría crear la relación inversa \"es comido por\", por ejemplo. Hasta ahora sólo tenemos el Meta-Conocimiento, es decir, las descripciones de los recursos, ahora debo agregar recursos, por ejemplo, si digo: \"León\" es un \"Carnívoro\"; \"Arbusto\" es una \"Planta\" y \"Zebra\" es un \"Herbívoro\" Automáticamente, podríamos inferir que el \"Arbusto\" está conpuesto por \"Tallo\", \"Rama\" y \"Hoja\", es comido por \"Zebra\", que a su vez es comido por \"León\". Si hacemos una analogía con la Programación Orientada a Objetos, mis clases, seguirían siendo clases, pero los recursos a los que hacen referencia, serían los objetos que son instanciados en una clase determinada. Obviamente, pueden hacerse ontologías muy complejas, lo que aquí muestro a manera de ejemplo es sólo la punta del iceberg pues los lenguajes de ontologías para la Web Semántica son sumamente flexibles y potentes: RDF y OWL[2] (que no es más que una extensión de RDF), posteriormente dedicaré un artículo para profundizar más sobre ellos. Las clases RDF/OWL, definen y describen mis recursos, y las relaciones entre estas clases, definen ciertas reglas básicas de inferencia lógica que pueden ser aprovechadas en un nivel superior por un Motor de Inferencia[3] para resolver consultas sobre una ontología y, a partir de esas premisas básicas, deducir nuevo conocimiento no explícito directamente en el modelo de conocimiento. Imaginemos ahora una WWW totalmente enlazada, totalmente integrada con la Web Semántica, cuando esto ocurra, serán agentes[4] quienes nos ayuden a realizar búsquedas a través de la web, examinando ontologías, extrayendo información que se adapte a nuestra consulta e interpretando, a través de reglas de inferencia bien definidas, cuáles recursos cumplen mejor con nuestra solicitud. Supongamos que Alan, es un empresario muy ocupado y su madre lo llamó anoche porque siente dolor en la zona abdominal desde hace unos días y siente que debería visitar a un médico. Alan, consulta la Internet desde su TabletPC, a través de su agente, solicitando las clínicas que se encuentren en 10km a la redonda de la casa de su madre, organizadas según su reputación. El agente revisa la ubicación de la casa de su madre (almacenada en el Tablet gracias a la tecnología de GPS) y consulta una Ontología con las clínicas de la ciudad y, además, busca en el Servicio Web de la Sociedad Médica Venezolana (bajo las circunstancias descritas en el párrafo anterior, debería existir), la lista de las mejores clínicas para poder cumplir con el patrón de ordenamiento que Alan solicitó. Luego de revisar los resultados, Alan le pregunta al agente de dónde obtuvo la información, este le redirige al portal de la Sociedad Médica Venezolana. Alan revisa las primeras tres clínicas y, finalmente se decide por el Hospital de Clínicas Caracas (HCC), pues no queda muy lejos de la casa de su madre y figura de 3ero en la lista de resultados. El agente del HCC le pregunta qué síntomas presenta, Alan escribe \"Dolor Abdominal\", el agente le recomienda visitar a un Gastroenterólogo y le devuelve una lista de los médicos de esa especialidad del Hospital. Alan se da cuenta de que el 2do en la lista, es un viejo amigo del Colegio y decide solicitar una cita con él lo más pronto posible, el agente del Hospital le informa que la cita más próxima es para dentro de dos días, entre las 14:00 y las 18:00, y su agente le recuerda que tiene un par de reuniones en ese intervalo de tiempo. Alan revisa su agenda y se da cuenta que son dos reuniones de prioridad menor, pide a su agente que las reprograme y solicite la cita médica. El agente de Alan, de manera automática, se comunica con los agentes de las personas involucradas en las reuniones para reprogramar las citas y, posteriormente se comunica con el agente del HCC para colocar la cita para dentro de dos días a la hora mencionada. Todo esto será posible si la información se encuentra totalmente enlazada y disponible en línea, los recursos son descritos de manera bien definida y las reglas de inferencia son bien explícitas, es por ello que es necesario que más personas se interesen en este tema de manera técnica pues, el futuro de la Internet, está tocando a nuestras puertas y, la Web Semántica, no puede quedarse enclaustrada dentro de la academia y ser dominado únicamente por grupos de investigación científica. Espero haber motivado a alguien más a estudiar dentro de este campo. Hasta un próximo artículo. [1] Digo Micro-Ontología porque si hacemos la ontología completa, creo que acabaríamos con todo el espacio disponible en este servidor. [2] Ambos lenguajes están en proceso de definición por el World Wide Web Consorcium (W3C), el avance puede ser seguido a través el sitio web del W3C. [3] JENA y Virtuoso son los que parecieran ser más utilizados. [4] Un agente, en informática, es una pieza de software que realiza una tarea específica de manera automática, es una espécie de \"robot\".","tags":"Blog","loc":"http://localhost:8000/empezando-a-conocer-la-web-30-parte-ii.html","title":"Empezando a conocer la Web 3.0 (Parte II)"},{"text":"Un concepto que nos enseñan desde el inicio en la Universidad y que, muchas veces, el el mundo laboral olvidamos, es el de la Complejidad de un Algoritmo. Este es un concepto que tiene incidencia directa en el tiempo en el cual se ejecutará y los recursos que consumirá dicha serie de instrucciones, todo por la afirmación constante de \"dale que la máquina aguanta\". Si, es cierto, acutualmente la capacidad de procesamiento de las computadoras es impresionante, pero también lo son los requerimientos a los que son sometidos día a día y, si hablamos de un programa que va a atender solicitudes concurrentes y debe funcionar en tiempo real... la complejidad cobra importancia. Traigo todo esto de vuelta desde mis clases de Algoritmos y Programación I pues, nuevamente jugando en ProjectEuler.net , estuve resolviendo uno de los problemas matemáticos que proponen y, como en mi trabajo estoy trabajando con Python, ese fue el lenguaje que seleccioné para resolverlo. Esta vez, el problema a solucionar o el valor a encontrar era: La suma de todos los valores pares de la Secuencia de Fibonacci menores a 4.000.000 Pan comido ¿no?, pero con lo que me conseguí llamó mucho la atención: Luego de leer el enunciado desempolvé la vieja definición recursiva de la Serie de Fibonacci y pensé: bien, esto dentro de in ciclo, con una validación y rompo cuando pase 4.000.000 . Manos a la obra, en Python todo quedó así: Excelente!, ya tengo mi algoritmo, lo pongo a correr desde un terminal y espero mi respuesta. Me impresionó lo mucho que se tardó en darme el resultado, alredecor de 20 segundos lo cual es demasiado tiempo, así que me puse a analizar mi algoritmo. Lo primero que hay que recordar es la notación O (\"o\" grande), nos mide el orden de complejidad de un algoritmo en la medida en que los valores que recibe van creciendo. Es decir, qué tan complejo se hace ejecutar un algoritmo con valores cada vez más grande. En esta función fib , para valores pequeños, el tiempo de respuesta es inmediato, pero conforme el valor fibonacci a calcular va creciendo, el tiempo de ejecusión se va haciendo cada vez más grande. Si nos fijamos, fib , es una función recursiva que, para calcular el k-ésimo valor de la serie, debe calcular los k - 1 valores anteriores, lo cual implica realizar el mismo proceso para los anteriores hasta llegar a los casos base. Esto, no solo no es óptimo, pues estamos dando más vueltas de las necesarias para hallar un simple valor, además, esta función está dentro de un ciclo por lo que, por cada iteración, debe recalcular valores ya obtenidos con anterioridad. Vaya!, mi vieja definición resursiva hace que el orden de mi algoritmo se dispare a O(n!), si mi razonamiento no falla. Investigando un poco en Internet sobre la Serie de Fibonacci, me conseguí con la Fórmula de Binet , que define la serie en una forma cerrada, es decir, me da el k-ésimo valor de manera directa, sin definirlo en función de valores anteriores, luego de modificarlo y reescribir mi Función Fibonacci, la cosa quedó así: Notemos que define cada valor en función de Phy (1,618...), un número irracional, por lo que el resultado habría que truncarlo, obervemos también que el programa principal no fue modificado. Luego de ejecutarlo, la respuesta fue inmediata. Este comportamiento era de esperarse pues, cambiamos la función con llamadas recursivas por operaciones aritméticas cuya complejidad es O(1), es decir, orden constante (a excepción de la potencia que es O(log(n)), pero asumamos que es constante también para no entrar en polémicas), lo que hace que nuestra nueva función tenca complejidad O(1) también. Si este ejemplo lo escalásemos a un sistema concurrente en tiempo real, es necesaria rapidez de procesamiento y de ejecusión y esto debe lograrse con una combinación de Hardware Potente y Software Eficiente con Algortimos Optimizados pues, nada hacemos con un Ferrari si va a manejarlo un niño de 5 años, por hacer una analogía graciosa. La otra parte que hay que tomar en cuenta es la herramienta que utilizamos para desarrollar nuestras soluciones, ya que distintas herramientas se comportan de manera diferente y cada una fue diseñada para llevar a cabo una tarea distinta: por ejemplo, si necesitas procesar grandes cantidades de texto usando Expresiones Regulares, seguramente tendrás que utilizar Perl, si quieres desarrollar una aplicación web estándar, que corra en cualquier servidor Apache sin mucha complicación, PHP es la respuesta (aunque no nos guste mucho), si quieres desarrollar un sistema empresarial que se conecte con 4 sucursales sobre una plataforma con soporte corporativo, Java o .NET, si lo que quieres es aprovechar hasta la última gota de tu procesador, pues programa en Assembler (o bueno, en C para no ser tan cochinos[1]). Siguiendo con el orden de ideas anterior, reescribí el programa con la definición recursiva de la Serie de Fibonacci, pero esta vez en Lenguaje C , sólo para ver lo que ocurría. El resultado fue que el tiempo de ejecusión se redujo a mucho menos de la mitad, respecto al de mismo programa escrito en Python. Aquí está el código en C por si lo quieren probar: Quiero finalizar, diciendo que, a veces, la mejor solución no es necesariamente codificar una aplicación completa utilizando un mismo lenguaje de programación. Por ejemplo, para el videojuego Nerverwinter Nights, todo el core fue escrito en C++, y sobre ese motor, implementaron un lenguaje propio (NWNScripts). Si desarrollas en Python y optimizas tus algoritmos varias veces pero no logras el tiempo de respuesta que quieres, quizás lo mejor sea recodificar toda tu lógica en C, y utilizar Bindings para invocarla desde Python.","tags":"Blog","loc":"http://localhost:8000/tomar-en-cuenta-la-herramienta-y-la-complejidad.html","title":"Tomar en cuenta la Herramienta y la Complejidad"},{"text":"Para muchos, como yo, esto es una total desgracia, sobre todo si somos del mundo del Software Libre. Yo utilizaba muchísimo Skype en el trabajo: para hablar con clientes, para conversar con mi jefe cuando me quedaba trabajando en casa, para hablar con amigos de otras partes del mundo... en fin, para miles de cosas. Sin lugar a dudas que comprar Skype fue una movida de negocios inteligente, estemos claros que el servicio de \"videollamada\" de MSN Messenger es realmente apestoso y uno en Skype puede hacer exactamente lo mismo que en el Messenger, pero con mejor calidad en el servicio VoIP, entonces, desde mi punto de vista, pueden pasar dos cosas: Que Microsoft integre todas las bondades de Skype en su servicio gratuíto de Mensajería Instantánea, es decir, que agarren Skype y lo llenen de publicidad molesta por todas partes. Que todo siga igual, pero que cobren una licencia astronómica por el servicio VoIP de Skype para empresas y mantengan un \"Home Edition\" con ciertas restricciones ridículas. En cualquiera de los dos casos, no será lo mismo y, como no se que vaya a pasar, yo particularmente he ido revisando algunas alternativas libres para utilizar servicio de Voz sobre IP (VoIP), los que parecieran ser las mejores opciones son: Ekiga (disponible para Windows también) y Empathy para Linux y SipDroid si eres usuario de Android.","tags":"Blog","loc":"http://localhost:8000/y-microsoft-compro-skype.html","title":"Y Microsoft compró Skype"},{"text":"Hace un par de días, alguien publicó en la lista de correos venezolana de Python este sitio web que tiene una serie de ejercicios matemáticos y de lógica propuestos para ser resueltos utilizando programación y lógica algorítmica. Me pareció súper interesante pues es una manera de mantener el cerebro activo y de, poco a poco, ir conociendo más a fondo el lenguaje de programación que estoy utilizando para mi trabajo (Python). Lo que me pareció aún más interesante es que puedo comparar las soluciones en Python con los mismos algoritmos escritos en otros lenguajes y, además, al resolver cada ejercicio el sitio web te libera un foro donde otros programadores de otras partes del mundo han publicado sus soluciones, entonces, es una oportunidad de ver otras formas de pensar los algoritmos. Publico acá la solución al primero de los ejercicios que, al ser el primero, no representa mayor dificultad, pero me pareció interesante la diferencia de la solución al mismo problema utilizando dos lenguajes distintos. 1.- Sumar todos los múltiplos de 3 y de 5 que se encuentran por debajo de 1000: En Python , la solución es realmente corta, basta con una comprensión de lista para generar el conjunto y una función estándar para sumarlos, he aquí la solución: El ejercicio sale en sólo una línea, veamos ahora en C , por ejemplo, que si fue necesario ciclar y realizar una validación interna en el loop. Nuevamente, cobra importancia seleccionar la mejor herramienta para realizar una tarea determinada. OJO, con esto no estoy diciendo que Python sea mejor o más rápido que C, estemos claros que, para empezar, un programa compilado siempre correrá más rápido que uno interpretado y además, C es C. Pero si queremos una solución rápida de codificar e intuitiva de leer, quizás lo mejor sea hacerla en Python o en algún lenguaje orientado al Scripting. Poco a poco iré publicando otras soluciones que me parezcan interesantes y contrastantes entre dos lenguajes distintas o dos algoritmos distintos para llegar al mismo resultado. Antes de culminar esta entrada, quiero dejarles, a los entusiastas del \"código que corre rápido\", una solución en Assembler que conseguí en el foro que les mencioné al principio, sólo en caso de que alguien quiera probarla. Hasta la próxima!:","tags":"Blog","loc":"http://localhost:8000/jugando-en-projecteulernet.html","title":"Jugando en ProjectEuler.net"},{"text":"Mucho hablamos hoy día de lo \"dos punto cero\": en internet, en la radio, en la televisión, se habla incluso de programas y empresas \"dos punto cero\" que se apoyan en estas tecnologías de la web para comunicarse con su audiencia o bien para ser transmitidos (podcasts, videocasts, radios por internet). Y es que la Web 2.0 ha revolucionado desde la manera en que vemos la Internet hasta el enfoque de negocios de muchas grandes empresas. Pero, en este mundo cambiante de la tecnología, la Web 2.0 no es más que un estado transitorio a otro más sofisticado: la Web 3.0, conocida en la inmensidad de Internet como la Web Semántica. Resulta conveniente refrescar la memoria con algo de Historia de Internet pues, si actualmente nos encontramos en la Web 2.0, en algún momento debió existir una Web 1.0. Nos remontamos a los inicios de la Autopista de la Información, recordamos aquellas páginas frías, estáticas y en las que únicamente personal altamente capacitado y especializado era capaz de crear contenido y publicarlo, lo que se traducía en que sólo las grandes empresas tenían presencia en la red. Además, el flujo de información era unidireccional, es decir, se generaba un mensaje y otros, los usuarios, eran importantes en la medida en que se convertían en consumidores de dicha información. Poco a poco la tecnología fue evolucionando, aparecieron lenguajes capaces de procesar y pre-procesar hipertexto con los que se puede lograr sitios web más dinámicos y capaces de interactuar con bases de datos, con lo que el contenido pasó de ser de estático a cambiante. Esto trajo consigo que, aún cuando sólo personas con conocimientos de computación y programacion son los capaces de crear sitios y espacios en la web, todos los usuarios son capaces de generar y publicar contenido, con lo que la información ahora fluye de manera multidireccional, apareciendo conceptos como Redes Sociales e Inteligencia Colectiva, de esta manera nace lo que conocemos hoy día como La Web 2.0 en la que, contrario a la Web 1.0, los usuarios son importantes en la medida en que son generadores constantes de contenido. Con esta nueva Web, cargada de contenido que, además, crece exponencialmente segundo a segundo, cobran especial importancia los buscadores. Estos buscadores, en su mayoría, trabajan mediante palabras claves o \"keywords\" en inglés. De esta manera, un documento es relevante según el número de veces que aparece una palabra clave y no por su significado en el contexto de la consulta realizada por el usuario. Este esquema funciona para búsquedas en las que el contexto no es tan importante, por ejemplo \"Internet en Venezuela\", resulta ser una consulta bastante general, podrían interesarme desde Proveedores de Servicio de Internet en Venezuela, hasta estadísticas acerca del uso y páginas más visitadas. Supongamos que estamos planeando un viaje familiar a Los Andes, debemos llegar a Valera, Edo. Trujillo, entonces nos vamos al buscador de nuestra preferencia y consultamos: \"Todos los vuelos a Valera mañana en la mañana\". Esto sería así en un mundo ideal, pero en nuestro mundo los resultados serían un completo desastre, nuestro buscador nos daría páginas de agencias de viajes, sitios de aerolíneas, blogs acerca de \"Valera\" como localidad del Estado Trujillo, sitios turísticos en Valera e incluso noticias sobre personas con el apellido \"Valera\", además de recursos que contienen la palabra clave \"mañana\", estos resultados no son exactos y, por si solos, no satisfacen las necesidades de información del usuario, nuestro desafortunado viajero, tendrá que ir de resultado en resultado extrayendo manualmente la información que resulte relevante a su pregunta. En la Web 3.0, un buscador con capacidad semántica, será capaz de detectar automáticamente la ubicación del usuario (en mi caso, Caracas), por lo que el \"lugar de orígen\" no tendría que ser suministrado, además, el buscador \"entendería\" que el usuario desea aerolíneas que cubran la ruta Caracas - Valera y calcularía el \"mañana\" en función de la fecha actual del sistema, en decir, en función de un \"hoy\" e interpretaría la segunda ocurrencia de \"mañana\" como un momento determinado del día, todo esto sólo con un click!. ¿Cómo es esto posible?, pues dotando la web de mayor significado en los innumerables recursos que pone a nuestra disposición, dotando a nuestra Web 2.0 de una mayor semántica, de manera que los resultados no se procesarían en base a entradas y salidas de datos, sino en base al contexto y significado de la consulta realizada, todo esto apoyándose en una infraestructura de metadatos. Suena simple ¿verdad?. Pero, ¿cómo construimos esa infraestructura?, en los próximos artículos me dedicaré explorar más profundamente las posibilidades de la Web Semántica (que, algunas, parecen sacadas de una película de Ciencia Ficción) y a explicar a mayor detalle varios conceptos que hacen vida dentro del marco de la Web Semántica, así como también ilustrar de manera práctica, mediante tutoriales, el uso de las herramientas y tecnologías necesarias para dar vida a la Web Semántica o, lo que es lo mismo, dar Semántica a nuestra Web en vida, siempre dejando claro que no se trata de Inteligencia Artificial, sino de dar a las máquinas la capacidad de resolver problemas bien definidos, con operaciones bien definidas y sobre datos bien definidos. Lecturas Recomendadas: Cobo, Cristóbal y Pardo, Hugo. (2007) Planeta 2.0: Inteligencia Colectiva o Medios Fast Food. México DF: Grup de Recerca d'Interaccions e Digitals.","tags":"Blog","loc":"http://localhost:8000/empezando-a-conocer-la-web-semantica-parte-i.html","title":"Empezando a conocer la Web Semántica (Parte I)"},{"text":"\"Geek de nacimiento, informático de formación y músico por diversión...\" Hola!, la verdad mientras escribía esto no pensé que alguien llegara a leerlo, por eso lo escribí un poco informal, pero ya que estás aquí, no puedo más que darte las gracias por tomarte el tiempo de leer, no sólo lo que escribo, sino también algo acerca de mi. Me llamo Israel Fermín Montilla y soy de Caracas - Venezuela, soy Ingeniero en Informática egresado de la Universidad Católica Andrés Bello , realicé mi Trabajo Especial de Grado en el área de Web Semántica con el Prof. Wilmer Pereira como tutor de la misma. Actualmente me dedico al desarrollo web, más que todo en Python, y administración de sistemas Linux. En mi tiempo libre me gusta tocar la guitarra y ensayar con mi banda, cuando no estoy frente a la computadora, estoy detrás de mi guitarra. Melómano hasta la muerte, me encanta la música, especialmente los géneros del Blues, Jazz, Rock, Funk, Metal y Fusión. Me encantan *Queen* , *Van Halen* , `The Beatles`_ y *Eric Clapton* , además, soy fiel creyente del Rock Hecho en Venezuela, bandas como *La Vida Boheme* y `The Asbestos`_, y guitarristas como *Pablo Mendoza* y *Hugo Fuguet* , han dejado muy en alto el nombre de la música nacional en todas sus presentaciones. Lector empedernido de cualquier tipo de libros (técnicos y literatura en general), aficionado al cine, filántropo y misántropo a veces... en fin, otro loco más...","tags":"Acerca de...","loc":"http://localhost:8000/acerca-de-mi.html","title":"Acerca de mi"},{"text":"Hay algo muy valioso, mucho más que cualquier cosa en el mundo, y que increiblemente muy poca gente comparte y, debido a ese egoismo, el mundo no avanza más rápido. Ese algo es el conocimiento , el conocimiento en las manos correctas puede producir resultados increíbles. Este sitio es mi pequeña ventana para compartir con el mundo las pocas cosas que he aprendido y que considero saber, esperando que alguien con más imaginación que yo pueda aprovecharlas y, si no es el caso, al menos tener mi conocimiento en un lugar que puedo recordar fácilmente y, si le es útil a alguien más, mucho mejor!.","tags":"Acerca de...","loc":"http://localhost:8000/acerca-de-este-sitio.html","title":"Acerca de este sitio"}]}